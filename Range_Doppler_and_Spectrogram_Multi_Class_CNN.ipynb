{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Range_Doppler_and_Spectrogram_Multi_Class_CNN.ipynb ",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mertege/FMCW-Data-Classification-/blob/main/Range_Doppler_and_Spectrogram_Multi_Class_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kN4ixvH39HW6"
      },
      "source": [
        "# Burada fast, slow ve slow with pocket multi-class olarak karşılaştırıldı.\n",
        "# 5 defa run edildi ve değerler aşağıda paylaşıldı.\n",
        "# Mean test accuracy is 0.57, mean test f1 score is 0.13, max test accuracy is 0.62, max test f1 score is 0.18, \n",
        "# Min test accuracy is 0.51, min test f1 score is 0.09, std of test accuracy is 0.04, std of test f1 score is 0.03\n",
        "# Time elapsed through all process: 5937.29, sec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzJwN6GfkN8Z"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from keras.models import Model\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization, Normalization, Input, Conv2D, MaxPooling2D, Concatenate\n",
        "import tensorflow as tf\n",
        "import scipy.io\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from numpy.random import seed\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "import time\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from keras.callbacks import EarlyStopping\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FERVnWrkrwE",
        "outputId": "5c11cd6e-2a49-4bd0-b8f1-469443204d1f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o19JHieQ81cS"
      },
      "source": [
        "# Get Range-Doppler data from\n",
        "range_doppler_fast_resized = scipy.io.loadmat('/content/drive/MyDrive/range_doppler_fast_resized.mat')\n",
        "range_doppler_fast_resized = range_doppler_fast_resized['range_doppler_fast_resized']\n",
        "range_doppler_fast_resized = np.transpose(range_doppler_fast_resized, (2, 0, 1))\n",
        "range_doppler_fast_resized = np.delete(range_doppler_fast_resized,(49), axis=0) # 50th row is deleted since there is no 50th row in spectrogram fast data.\n",
        "range_doppler_fast_label = scipy.io.loadmat('/content/drive/MyDrive/range_doppler_fast_label.mat')\n",
        "range_doppler_fast_label = range_doppler_fast_label['range_doppler_fast_label']  \n",
        "\n",
        "range_doppler_slow_resized = scipy.io.loadmat('/content/drive/MyDrive/range_doppler_slow_resized.mat')\n",
        "range_doppler_slow_resized = range_doppler_slow_resized['range_doppler_slow_resized']\n",
        "range_doppler_slow_resized = np.transpose(range_doppler_slow_resized, (2, 0, 1))\n",
        "range_doppler_slow_label = scipy.io.loadmat('/content/drive/MyDrive/range_doppler_slow_label.mat')\n",
        "range_doppler_slow_label = range_doppler_slow_label['range_doppler_slow_label']  \n",
        "\n",
        "range_doppler_slow_pocket_resized = scipy.io.loadmat('/content/drive/MyDrive/range_doppler_slow_pocket_resized.mat')\n",
        "range_doppler_slow_pocket_resized = range_doppler_slow_pocket_resized['range_doppler_slow_pocket_resized']\n",
        "range_doppler_slow_pocket_resized = np.transpose(range_doppler_slow_pocket_resized, (2, 0, 1))\n",
        "range_doppler_pocket_label = scipy.io.loadmat('/content/drive/MyDrive/range_doppler_pocket_label.mat')\n",
        "range_doppler_pocket_label = range_doppler_pocket_label['range_doppler_pocket_label']  \n",
        "# Get Range-Doppler data from\n",
        "spectrogram_fast_resized = scipy.io.loadmat('/content/drive/MyDrive/spectrogram_fast_resized.mat')\n",
        "spectrogram_fast_resized = spectrogram_fast_resized['spectrogram_fast_resized']\n",
        "spectrogram_fast_resized = np.transpose(spectrogram_fast_resized, (2, 0, 1))\n",
        "spectrogram_fast_label = scipy.io.loadmat('/content/drive/MyDrive/spectrogram_fast_label.mat')\n",
        "spectrogram_fast_label = spectrogram_fast_label['spectrogram_fast_label']  \n",
        "\n",
        "spectrogram_slow_resized = scipy.io.loadmat('/content/drive/MyDrive/spectrogram_slow_resized.mat')\n",
        "spectrogram_slow_resized = spectrogram_slow_resized['spectrogram_slow_resized']\n",
        "spectrogram_slow_resized = np.transpose(spectrogram_slow_resized, (2, 0, 1))\n",
        "spectrogram_slow_label = scipy.io.loadmat('/content/drive/MyDrive/spectrogram_slow_label.mat')\n",
        "spectrogram_slow_label = spectrogram_slow_label['spectrogram_slow_label']  \n",
        "\n",
        "spectrogram_slow_pocket_resized = scipy.io.loadmat('/content/drive/MyDrive/spectrogram_slow_pocket_resized.mat')\n",
        "spectrogram_slow_pocket_resized = spectrogram_slow_pocket_resized['spectrogram_slow_pocket_resized']\n",
        "spectrogram_slow_pocket_resized = np.transpose(spectrogram_slow_pocket_resized, (2, 0, 1))\n",
        "spectrogram_slow_pocket_label = scipy.io.loadmat('/content/drive/MyDrive/spectrogram_slow_pocket_label.mat')\n",
        "spectrogram_slow_pocket_label = spectrogram_slow_pocket_label['spectrogram_slow_pocket_label']  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_upOlnklMNhD"
      },
      "source": [
        "label_concat = np.concatenate((spectrogram_fast_label,spectrogram_slow_label),axis=0)\n",
        "label_concat = np.concatenate((label_concat,spectrogram_slow_pocket_label),axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yq7lpIJPLnXL"
      },
      "source": [
        "# One-Hot Encode Label\n",
        "# integer encode\n",
        "label_encoder = LabelEncoder()\n",
        "integer_encoded = label_encoder.fit_transform(label_concat)\n",
        "print(integer_encoded)\n",
        "# binary encode\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
        "onehot_encoded_labels = onehot_encoder.fit_transform(integer_encoded)\n",
        "print(onehot_encoded_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFp_PErnMLN2"
      },
      "source": [
        "# Concat range-doppler data\n",
        "range_doppler_concat = np.concatenate((range_doppler_fast_resized,range_doppler_slow_resized),axis=0)\n",
        "range_doppler_concat = np.concatenate((range_doppler_concat,range_doppler_slow_pocket_resized),axis=0)\n",
        "range_doppler_concat = range_doppler_concat[:,:,:,np.newaxis] \n",
        "range_doppler_concat_label = label_concat\n",
        "# Shuffle concat range doppler\n",
        "shuffle_indx = random.sample(range(0, range_doppler_concat.shape[0]), range_doppler_concat.shape[0]) # split validation data\n",
        "range_doppler_concat_shuffle = range_doppler_concat[shuffle_indx,:,:,:]\n",
        "range_doppler_concat_label_shuffle = range_doppler_concat_label[shuffle_indx,:]\n",
        "# Concat range-doppler data\n",
        "spectrogram_concat = np.concatenate((spectrogram_fast_resized,spectrogram_slow_resized),axis=0)\n",
        "spectrogram_concat = np.concatenate((spectrogram_concat,spectrogram_slow_pocket_resized),axis=0)\n",
        "spectrogram_concat = spectrogram_concat[:,:,:,np.newaxis] \n",
        "spectrogram_concat_label = onehot_encoded_labels\n",
        "# Shuffle concat range doppler\n",
        "# shuffle_indx = random.sample(range(0, spectrogram_concat.shape[0]), spectrogram_concat.shape[0]) # split validation data\n",
        "spectrogram_concat_shuffle = spectrogram_concat[shuffle_indx,:,:,:]\n",
        "spectrogram_concat_label_shuffle = spectrogram_concat_label[shuffle_indx,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1aBNkjoLCvI"
      },
      "source": [
        "# ---------------- Augmente and shuffle (train and test) data data ----------------\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "  layers.RandomRotation(0.2),\n",
        "])\n",
        "def split_and_augmentation_of_training(range_doppler_concat_shuffle_train,range_doppler_concat_label_shuffle_train, randomlist_for_validation_indx, augmentation_enable):\n",
        "  # ---------------- Parameters ----------------\n",
        "  repeat_of_augmentation = 3\n",
        "  size_of_validation = 30\n",
        "\n",
        "\n",
        "\n",
        "  # Split validation\n",
        "  if bool(randomlist_for_validation_indx) == False:  # check randomlist_for_validation_indx is empty, (empty case). For using same validation indexes.\n",
        "    randomlist_for_validation_indx = random.sample(range(0, range_doppler_concat_shuffle_train.shape[0]), size_of_validation) # split validation data\n",
        "    randomlist_for_train_indx = np.delete(range(0, range_doppler_concat_shuffle_train.shape[0]), randomlist_for_validation_indx) # split training data\n",
        "  else: # non-empty case\n",
        "    randomlist_for_validation_indx = randomlist_for_validation_indx # split validation data\n",
        "    randomlist_for_train_indx = np.delete(range(0, range_doppler_concat_shuffle_train.shape[0]), randomlist_for_validation_indx) # split training data\n",
        "\n",
        "  # get validation data\n",
        "  validation_spectrograms = range_doppler_concat_shuffle_train[randomlist_for_validation_indx,:,:,:]\n",
        "  validation_labels = range_doppler_concat_label_shuffle_train[randomlist_for_validation_indx,:]\n",
        "  # get training data\n",
        "  training_spectrograms = range_doppler_concat_shuffle_train[randomlist_for_train_indx,:,:,:]\n",
        "  training_labels = range_doppler_concat_label_shuffle_train[randomlist_for_train_indx,:]\n",
        "\n",
        "  size_of_training = training_spectrograms.shape[0]\n",
        "\n",
        "  if augmentation_enable == True: \n",
        "    augmented_image = np.zeros((size_of_training*repeat_of_augmentation,range_doppler_concat_shuffle_train.shape[1],range_doppler_concat_shuffle_train.shape[2],1))\n",
        "    spectrograms_label = np.ones((size_of_training*(repeat_of_augmentation+1),1))\n",
        "    for jj in range(repeat_of_augmentation):\n",
        "      for ii in range(size_of_training):\n",
        "        augmented_image[size_of_training*jj+ii,:,:,:] = data_augmentation(training_spectrograms[ii,:,:,:])\n",
        "    augmented_image = np.concatenate((augmented_image,training_spectrograms),axis=0)   \n",
        "    spectrograms_label = np.tile(training_labels,(repeat_of_augmentation+1,1))\n",
        "  else:\n",
        "    augmented_image = training_spectrograms\n",
        "    spectrograms_label = training_labels\n",
        "  return (augmented_image,spectrograms_label,\\\n",
        "          validation_spectrograms,validation_labels, randomlist_for_validation_indx)\n",
        "\n",
        "\n",
        "def normalize_inputs(range_doppler_concat_shuffle_test, validation_spectrograms, augmented_image, normalize_inputs_enable):\n",
        "  # ---------------- Normalize Inputs ----------------\n",
        "  if normalize_inputs_enable == True:\n",
        "    layer = Normalization(axis=None)\n",
        "    layer.adapt(range_doppler_concat_shuffle_test)\n",
        "    range_doppler_concat_shuffle_test = layer(range_doppler_concat_shuffle_test)\n",
        "    layer = Normalization(axis=None)\n",
        "    layer.adapt(validation_spectrograms)\n",
        "    validation_spectrograms = layer(validation_spectrograms)\n",
        "    layer = Normalization(axis=None)\n",
        "    layer.adapt(augmented_image)\n",
        "    augmented_image = layer(augmented_image)\n",
        "  else:\n",
        "    (range_doppler_concat_shuffle_test, validation_spectrograms, augmented_image) = (range_doppler_concat_shuffle_test, validation_spectrograms, augmented_image)\n",
        "  return(range_doppler_concat_shuffle_test, validation_spectrograms, augmented_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNpkBBIadpPo"
      },
      "source": [
        "t = time.time()\n",
        "# ---------- Parameters ----------------\n",
        "augmentation_enable = True\n",
        "normalize_inputs_enable = True\n",
        "num_folds = 5\n",
        "kfold = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state = None) # random_state = 1 ile split run'dan run'a sabit.\n",
        "test_accuracy_per_run = []\n",
        "f1_score_per_run = []\n",
        "epoch_number = 100\n",
        "batch_size = 32\n",
        "dense_size = 32\n",
        "dropout_prob_cnn = 0.1\n",
        "dropout_prob_dense = 0.3\n",
        "number_of_repeat = 5\n",
        "for repeat_run_number in range(number_of_repeat):\n",
        "  test_accuracy_per_fold = []\n",
        "  f1_score_per_fold = []\n",
        "  for train, test in kfold.split(range_doppler_concat_shuffle,range_doppler_concat_label_shuffle):   \n",
        "\n",
        "    # One-Hot Encode Label\n",
        "    # integer encode\n",
        "    label_encoder = LabelEncoder()\n",
        "    integer_encoded = label_encoder.fit_transform(range_doppler_concat_label_shuffle)\n",
        "    # binary encode\n",
        "    onehot_encoder = OneHotEncoder(sparse=False)\n",
        "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
        "    onehot_encoded_labels = onehot_encoder.fit_transform(integer_encoded)\n",
        "\n",
        "\n",
        "    # ---------------- Range-Doppler Data ----------------\n",
        "    randomlist_for_test_indx = test\n",
        "    randomlist_for_train_indx = train\n",
        "    # test data\n",
        "    range_doppler_concat_shuffle_test = range_doppler_concat_shuffle[randomlist_for_test_indx,:,:,:]\n",
        "    range_doppler_concat_label_shuffle_test = onehot_encoded_labels[randomlist_for_test_indx,:]\n",
        "    #train data\n",
        "    range_doppler_concat_shuffle_train = range_doppler_concat_shuffle[randomlist_for_train_indx,:,:,:]\n",
        "    range_doppler_concat_label_shuffle_train = onehot_encoded_labels[randomlist_for_train_indx,:]\n",
        "      # ---------------- Split labels to equal them during augmentation for Validation ----------------\n",
        "    randomlist_for_validation_indx = []\n",
        "    (range_doppler_augmented_image,range_doppler_concat_label_shuffle_concat,\\\n",
        "          validation_range_doppler,range_doppler_validation_labels, randomlist_for_validation_indx) = split_and_augmentation_of_training(range_doppler_concat_shuffle_train,range_doppler_concat_label_shuffle_train,randomlist_for_validation_indx, augmentation_enable)\n",
        "\n",
        "    # ---------------- Spectrogram Data ----------------\n",
        "    # test data\n",
        "    spectrogram_concat_shuffle_test = spectrogram_concat_shuffle[randomlist_for_test_indx,:,:,:]\n",
        "    spectrogram_concat_label_shuffle_test = spectrogram_concat_label_shuffle[randomlist_for_validation_indx,:]\n",
        "    #train data\n",
        "    spectrogram_concat_shuffle_train = spectrogram_concat_shuffle[randomlist_for_train_indx,:,:,:]\n",
        "    spectrogram_concat_label_shuffle_train = spectrogram_concat_label_shuffle[randomlist_for_train_indx,:]\n",
        "      # ---------------- Split labels to equal them during augmentation for Validation ----------------\n",
        "    (spectrogram_augmented_image,spectrogram_concat_label_shuffle_concat,\\\n",
        "     validation_spectrogram, spectrogram_validation_labels, randomlist_for_validation_indx)  = split_and_augmentation_of_training(spectrogram_concat_shuffle_train,spectrogram_concat_label_shuffle_train,randomlist_for_validation_indx, augmentation_enable)\n",
        "\n",
        "\n",
        "\n",
        "    # ---------------- Normalization ----------------\n",
        "    (range_doppler_concat_shuffle_test, validation_range_doppler, range_doppler_augmented_image) = normalize_inputs(range_doppler_concat_shuffle_test,\\\n",
        "                                                                                                     validation_range_doppler, range_doppler_augmented_image, normalize_inputs_enable)   \n",
        "    (spectrogram_concat_shuffle_test, validation_spectrogram, spectrogram_augmented_image) = normalize_inputs(spectrogram_concat_shuffle_test,\\\n",
        "                                                                                                     validation_spectrogram, spectrogram_augmented_image, normalize_inputs_enable)\n",
        "    # ---------------- Neural Network Architecture ----------------\n",
        "\n",
        "\n",
        "    def encoder_for_range_doppler(input_shape):\n",
        "      input = Input(shape=input_shape)\n",
        "      x = Conv2D(4, (3, 3),padding='same',kernel_initializer=\"glorot_normal\")(input)\n",
        "      x = BatchNormalization()(x)\n",
        "      x = Activation('relu')(x)\n",
        "      x = Dropout(dropout_prob_cnn)(x)\n",
        "      x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "      x = Conv2D(8, (3, 3),padding='same',kernel_initializer=\"glorot_normal\")(x)\n",
        "      x = BatchNormalization()(x)\n",
        "      x = Activation('relu')(x)\n",
        "      x = Dropout(dropout_prob_cnn)(x)\n",
        "      x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "      x = Conv2D(16, (3, 3),padding='same',kernel_initializer=\"glorot_normal\")(x)\n",
        "      x = BatchNormalization()(x)\n",
        "      x = Activation('relu')(x)\n",
        "      x = Dropout(dropout_prob_cnn)(x)\n",
        "      x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "      x = Flatten()(x)\n",
        "      return Model(input, x)\n",
        "\n",
        "    def encoder_for_spectrogram(input_shape):\n",
        "      input = Input(shape=input_shape)\n",
        "      x = Conv2D(4, (3, 3),padding='same',kernel_initializer=\"glorot_normal\")(input)\n",
        "      x = BatchNormalization()(x)\n",
        "      x = Activation('relu')(x)\n",
        "      x = Dropout(dropout_prob_cnn)(x)\n",
        "      x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "      x = Conv2D(8, (3, 3),padding='same',kernel_initializer=\"glorot_normal\")(x)\n",
        "      x = BatchNormalization()(x)\n",
        "      x = Activation('relu')(x)\n",
        "      x = Dropout(dropout_prob_cnn)(x)\n",
        "      x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "      x = Conv2D(16, (3, 3),padding='same',kernel_initializer=\"glorot_normal\")(x)\n",
        "      x = BatchNormalization()(x)\n",
        "      x = Activation('relu')(x)\n",
        "      x = Dropout(dropout_prob_cnn)(x)\n",
        "      x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "      x = Flatten()(x)\n",
        "      return Model(input, x)\n",
        "\n",
        "    def decoder_for_concat(input_shape):\n",
        "      input = Input(shape=input_shape)\n",
        "      x = Dense(128, activation=\"relu\")(input)\n",
        "      x = Dropout(dropout_prob_dense)(x)\n",
        "      x = Dense(dense_size, activation=\"relu\")(x)\n",
        "      x = Dropout(dropout_prob_dense)(x)\n",
        "      x = Dense(3, activation=\"softmax\")(x)\n",
        "      return Model(input, x)\n",
        "    input_shape = range_doppler_concat_shuffle.shape[1:]\n",
        "    base_network_range_doppler = encoder_for_range_doppler(input_shape)\n",
        "    range_doppler_input  = Input(shape=input_shape)\n",
        "    processed_range_doppler  = base_network_range_doppler(range_doppler_input)\n",
        "\n",
        "    input_shape = spectrogram_concat_shuffle.shape[1:]\n",
        "    base_network_spectrogram = encoder_for_spectrogram(input_shape) \n",
        "    spectrogram_input  = Input(shape=input_shape)\n",
        "    processed_spectrogram  = base_network_spectrogram(spectrogram_input)\n",
        "\n",
        "    concat_layer = Concatenate()([processed_range_doppler, processed_spectrogram])\n",
        "\n",
        "    base_decoder_network = decoder_for_concat((concat_layer.shape[1]))\n",
        "    out = base_decoder_network(concat_layer)\n",
        "\n",
        "    model = Model(inputs=[range_doppler_input, spectrogram_input], outputs=[out])\n",
        "\n",
        "   \n",
        "    print(model.summary())\n",
        "    # ---------------- Compile and Fit ----------------\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    earlyStopping = EarlyStopping(monitor='val_loss', patience=35, verbose=0,restore_best_weights=True, mode='min')\n",
        "    # earlyStopping = EarlyStopping(monitor='val_accuracy', patience=15, verbose=0,restore_best_weights=True, mode='max')\n",
        "    history = model.fit((range_doppler_augmented_image,spectrogram_augmented_image),(range_doppler_concat_label_shuffle_concat),\n",
        "                    epochs=epoch_number,\n",
        "                    batch_size=batch_size,\n",
        "                    shuffle = True,\n",
        "                    callbacks=[earlyStopping],\n",
        "                    validation_data = ((validation_range_doppler,validation_spectrogram) , (range_doppler_validation_labels)))\n",
        "    tf.keras.models.load_model\n",
        "    test_loss, test_accuracy  = model.evaluate([range_doppler_concat_shuffle_test,spectrogram_concat_shuffle_test],\\\n",
        "                                               [range_doppler_concat_label_shuffle_test],\n",
        "                  batch_size=batch_size)\n",
        "    # ---------------- Get Test Results ----------------\n",
        "    y_test_predicted = model.predict((range_doppler_concat_shuffle_test,spectrogram_concat_shuffle_test), batch_size=batch_size)\n",
        "    # ----- Binarize y_test_predicted values -----\n",
        "    y_test_predicted_binary = np.zeros(y_test_predicted.shape[0])\n",
        "    for ii in range(y_test_predicted.shape[0]):\n",
        "      if argmax(y_test_predicted[ii,:]) == 0:\n",
        "        y_test_predicted_binary[ii] = 0\n",
        "      elif argmax(y_test_predicted[ii,:]) == 1:\n",
        "        y_test_predicted_binary[ii] = 1\n",
        "      else:\n",
        "        y_test_predicted_binary[ii] = 2\n",
        "    range_doppler_concat_label_shuffle_test1 = range_doppler_concat_label_shuffle[randomlist_for_test_indx,:]\n",
        "    test_precision, test_recall, test_f1_score, support = precision_recall_fscore_support(range_doppler_concat_label_shuffle_test1, y_test_predicted_binary, average='macro')\n",
        "    # ----------------------------------------------------------------------------------------------------------\n",
        "    test_accuracy_per_fold.append(test_accuracy)\n",
        "    f1_score_per_fold.append(test_f1_score)\n",
        "\n",
        "  test_accuracy_per_run.append(sum(test_accuracy_per_fold)/num_folds)\n",
        "  f1_score_per_run.append(sum(f1_score_per_fold)/num_folds)\n",
        "print(f'Mean test accuracy is {\"{:.2f}\".format(sum(test_accuracy_per_run)/number_of_repeat)}, mean test f1 score is {\"{:.2f}\".format(sum(f1_score_per_run)/number_of_repeat)}, \\\n",
        "max test accuracy is {\"{:.2f}\".format(max(test_accuracy_per_run))}, max test f1 score is {\"{:.2f}\".format(max(f1_score_per_run))}, \\\n",
        "min test accuracy is {\"{:.2f}\".format(min(test_accuracy_per_run))}, min test f1 score is {\"{:.2f}\".format(min(f1_score_per_run))}, \\\n",
        "std of test accuracy is {\"{:.2f}\".format(np.std(test_accuracy_per_run, axis=0))}, std of test f1 score is {\"{:.2f}\".format(np.std(f1_score_per_run, axis=0))}')\n",
        "elapsed = time.time() - t\n",
        "print(f'Time elapsed through all process: {\"{:.2f}\".format(elapsed)}, sec')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0N7v4PDP4Dv2",
        "outputId": "0a34b712-eeef-4d93-c360-cefde29f3150"
      },
      "source": [
        "print(f'Mean test accuracy is {\"{:.2f}\".format(sum(test_accuracy_per_run)/number_of_repeat)}, mean test f1 score is {\"{:.2f}\".format(sum(f1_score_per_run)/number_of_repeat)}, \\\n",
        "max test accuracy is {\"{:.2f}\".format(max(test_accuracy_per_run))}, max test f1 score is {\"{:.2f}\".format(max(f1_score_per_run))}, \\\n",
        "min test accuracy is {\"{:.2f}\".format(min(test_accuracy_per_run))}, min test f1 score is {\"{:.2f}\".format(min(f1_score_per_run))}, \\\n",
        "std of test accuracy is {\"{:.2f}\".format(np.std(test_accuracy_per_run, axis=0))}, std of test f1 score is {\"{:.2f}\".format(np.std(f1_score_per_run, axis=0))}')\n",
        "print(f'Time elapsed through all process: {\"{:.2f}\".format(elapsed)}, sec')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean test accuracy is 0.57, mean test f1 score is 0.13, max test accuracy is 0.62, max test f1 score is 0.18, min test accuracy is 0.51, min test f1 score is 0.09, std of test accuracy is 0.04, std of test f1 score is 0.03\n",
            "Time elapsed through all process: 5937.29, sec\n"
          ]
        }
      ]
    }
  ]
}