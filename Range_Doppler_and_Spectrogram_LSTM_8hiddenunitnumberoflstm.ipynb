{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mertege/FMCW-Data-Classification-/blob/Range-Doppler-Spectrogram-LSTM/Range_Doppler_and_Spectrogram_LSTM_8hiddenunitnumberoflstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kN4ixvH39HW6"
      },
      "outputs": [],
      "source": [
        "# burada 8 hiddenunitoflstm \n",
        "# [0.9588235139846801, 0.9470588088035583, 0.9647058725357056, 0.9588235139846801, 0.970588219165802]\n",
        "#[0.9507813140511734, 0.9385649310603057, 0.958319725121037, 0.9507813140511734, 0.9664525191120935]\n",
        "#Mean test accuracy is 0.960, mean test f1 score is 0.953, max test accuracy is 0.971, max test f1 score is 0.966, min test accuracy is 0.947, min test f1 score is 0.939, std of test accuracy is 0.008, std of test f1 score is 0.009\n",
        "#Time elapsed through all process: 10502.753, sec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lzJwN6GfkN8Z"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from keras.models import Model\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization, Normalization, Input, Conv2D, MaxPooling2D, Concatenate, GRU, LSTM, GRU, TimeDistributed, Bidirectional\n",
        "import tensorflow as tf\n",
        "import scipy.io\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from numpy.random import seed\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "import time\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from keras.callbacks import EarlyStopping\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from keras import backend as K \n",
        "import gc\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FERVnWrkrwE",
        "outputId": "1b05f39b-af43-419c-e066-15fb4ba19115"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "o19JHieQ81cS"
      },
      "outputs": [],
      "source": [
        "# Get Range-Doppler data from\n",
        "range_doppler_fast_resized = scipy.io.loadmat('/content/drive/MyDrive/data/range_doppler_fast_resized.mat')\n",
        "range_doppler_fast_resized = range_doppler_fast_resized['range_doppler_fast_resized']\n",
        "range_doppler_fast_resized = np.transpose(range_doppler_fast_resized, (2, 0, 1))\n",
        "# range_doppler_fast_resized = np.delete(range_doppler_fast_resized,(49), axis=0) # 50th row is deleted since there is no 50th row in spectrogram fast data.\n",
        "range_doppler_fast_label = scipy.io.loadmat('/content/drive/MyDrive/data/range_doppler_fast_label.mat')\n",
        "range_doppler_fast_label = range_doppler_fast_label['range_doppler_fast_label']  \n",
        "\n",
        "range_doppler_slow_resized = scipy.io.loadmat('/content/drive/MyDrive/data/range_doppler_slow_resized.mat')\n",
        "range_doppler_slow_resized = range_doppler_slow_resized['range_doppler_slow_resized']\n",
        "range_doppler_slow_resized = np.transpose(range_doppler_slow_resized, (2, 0, 1))\n",
        "range_doppler_slow_label = scipy.io.loadmat('/content/drive/MyDrive/data/range_doppler_slow_label.mat')\n",
        "range_doppler_slow_label = range_doppler_slow_label['range_doppler_slow_label']  \n",
        "\n",
        "range_doppler_slow_pocket_resized = scipy.io.loadmat('/content/drive/MyDrive/data/range_doppler_slow_pocket_resized.mat')\n",
        "range_doppler_slow_pocket_resized = range_doppler_slow_pocket_resized['range_doppler_slow_pocket_resized']\n",
        "range_doppler_slow_pocket_resized = np.transpose(range_doppler_slow_pocket_resized, (2, 0, 1))\n",
        "range_doppler_pocket_label = scipy.io.loadmat('/content/drive/MyDrive/data/range_doppler_pocket_label.mat')\n",
        "range_doppler_pocket_label = range_doppler_pocket_label['range_doppler_pocket_label']  \n",
        "# Get Range-Doppler data from\n",
        "spectrogram_fast_resized = scipy.io.loadmat('/content/drive/MyDrive/data/spectrogram_fast_resized.mat')\n",
        "spectrogram_fast_resized = spectrogram_fast_resized['spectrogram_fast_resized']\n",
        "spectrogram_fast_resized = np.transpose(spectrogram_fast_resized, (2, 0, 1))\n",
        "spectrogram_fast_label = scipy.io.loadmat('/content/drive/MyDrive/data/spectrogram_fast_label.mat')\n",
        "spectrogram_fast_label = spectrogram_fast_label['spectrogram_fast_label']  \n",
        "\n",
        "spectrogram_slow_resized = scipy.io.loadmat('/content/drive/MyDrive/data/spectrogram_slow_resized.mat')\n",
        "spectrogram_slow_resized = spectrogram_slow_resized['spectrogram_slow_resized']\n",
        "spectrogram_slow_resized = np.transpose(spectrogram_slow_resized, (2, 0, 1))\n",
        "spectrogram_slow_label = scipy.io.loadmat('/content/drive/MyDrive/data/spectrogram_slow_label.mat')\n",
        "spectrogram_slow_label = spectrogram_slow_label['spectrogram_slow_label']  \n",
        "\n",
        "spectrogram_slow_pocket_resized = scipy.io.loadmat('/content/drive/MyDrive/data/spectrogram_slow_pocket_resized.mat')\n",
        "spectrogram_slow_pocket_resized = spectrogram_slow_pocket_resized['spectrogram_slow_pocket_resized']\n",
        "spectrogram_slow_pocket_resized = np.transpose(spectrogram_slow_pocket_resized, (2, 0, 1))\n",
        "spectrogram_slow_pocket_label = scipy.io.loadmat('/content/drive/MyDrive/data/spectrogram_slow_pocket_label.mat')\n",
        "spectrogram_slow_pocket_label = spectrogram_slow_pocket_label['spectrogram_slow_pocket_label']  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wFp_PErnMLN2"
      },
      "outputs": [],
      "source": [
        "# Concat range-doppler data\n",
        "range_doppler_concat = np.concatenate((range_doppler_fast_resized,range_doppler_slow_resized),axis=0)\n",
        "range_doppler_concat = np.concatenate((range_doppler_concat,range_doppler_slow_pocket_resized),axis=0)\n",
        "range_doppler_concat = range_doppler_concat[:,:,:,np.newaxis] \n",
        "range_doppler_concat_label = np.zeros((range_doppler_concat.shape[0],1))\n",
        "range_doppler_concat_label[:range_doppler_fast_resized.shape[0],:] = 1\n",
        "# Shuffle concat range doppler\n",
        "shuffle_indx = random.sample(range(0, range_doppler_concat.shape[0]), range_doppler_concat.shape[0]) # split validation data\n",
        "range_doppler_concat_shuffle = range_doppler_concat[shuffle_indx,:,:,:]\n",
        "range_doppler_concat_label_shuffle = range_doppler_concat_label[shuffle_indx,:]\n",
        "# Concat range-doppler data\n",
        "spectrogram_concat = np.concatenate((spectrogram_fast_resized,spectrogram_slow_resized),axis=0)\n",
        "spectrogram_concat = np.concatenate((spectrogram_concat,spectrogram_slow_pocket_resized),axis=0)\n",
        "spectrogram_concat = spectrogram_concat[:,:,:,np.newaxis] \n",
        "spectrogram_concat_label = np.zeros((spectrogram_concat.shape[0],1))\n",
        "spectrogram_concat_label[:spectrogram_fast_resized.shape[0],:] = 1\n",
        "# Shuffle concat range doppler\n",
        "# shuffle_indx = random.sample(range(0, spectrogram_concat.shape[0]), spectrogram_concat.shape[0]) # split validation data\n",
        "spectrogram_concat_shuffle = spectrogram_concat[shuffle_indx,:,:,:]\n",
        "spectrogram_concat_label_shuffle = spectrogram_concat_label[shuffle_indx,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_1aBNkjoLCvI"
      },
      "outputs": [],
      "source": [
        "# ---------------- Augmente and shuffle (train and test) data data ----------------\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "  layers.RandomRotation(0.1),\n",
        "])\n",
        "\n",
        "\n",
        "def mixup_augmentation(images,range_doppler_training_data, labels, repeat_of_mixup, alpha=0.2):\n",
        "    batch_size = images.shape[0]\n",
        "    concat_images = np.zeros((batch_size*(repeat_of_mixup+1),images.shape[1],images.shape[2],images.shape[3]))\n",
        "    concat_images_range_doppler = np.zeros((batch_size*(repeat_of_mixup+1),range_doppler_training_data.shape[1],\\\n",
        "                                            range_doppler_training_data.shape[2],range_doppler_training_data.shape[3]))\n",
        "    concat_label = np.zeros((batch_size*(repeat_of_mixup+1),labels.shape[1]))\n",
        "    for ii in range(repeat_of_mixup):\n",
        "      # shuffle train dataset\n",
        "      shuffle_indx_1 = random.sample(range(0, images.shape[0]), images.shape[0]) # split validation data\n",
        "      images_shuffled_1 = images[shuffle_indx_1,:,:,:]\n",
        "      range_doppler_training_data_shuffled_1 = range_doppler_training_data[shuffle_indx_1,:,:,:]\n",
        "      labels_shuffled_1 = labels[shuffle_indx_1,:]\n",
        "\n",
        "      shuffle_indx_2 = random.sample(range(0, images.shape[0]), images.shape[0]) # split validation data\n",
        "      images_shuffled_2 = images[shuffle_indx_2,:,:,:]\n",
        "      range_doppler_training_data_shuffled_2 = range_doppler_training_data[shuffle_indx_2,:,:,:]\n",
        "      labels_shuffled_2 = labels[shuffle_indx_2,:]\n",
        "\n",
        "      # Sample lambda and reshape it to do the mixup\n",
        "      gaussian_mean = 0.2\n",
        "      gaussian_std = 0.02\n",
        "      ll = np.random.normal(gaussian_mean, gaussian_std, (batch_size,1,1,1))\n",
        "      x_l = np.reshape(ll, (batch_size,1,1,1))\n",
        "      y_l = np.reshape(ll, (batch_size,1))\n",
        "      \n",
        "      # Perform mixup on both images and labels by combining a pair of images/labels\n",
        "      images_mixup = images_shuffled_1 * x_l + images_shuffled_2 * (1 - x_l)\n",
        "      images_mixup_range_doppler = range_doppler_training_data_shuffled_1 * x_l + range_doppler_training_data_shuffled_2 * (1 - x_l)\n",
        "      labels_mixup = labels_shuffled_1 * y_l + labels_shuffled_2 * (1 - y_l)\n",
        "      concat_images[ii*batch_size:(ii+1)*batch_size,:,:,:] = images_mixup\n",
        "      concat_images_range_doppler[ii*batch_size:(ii+1)*batch_size,:,:,:] = images_mixup_range_doppler\n",
        "      concat_label[ii*batch_size:(ii+1)*batch_size,:] = labels_mixup\n",
        "\n",
        "    concat_images[repeat_of_mixup*batch_size:,:,:,:] = images\n",
        "    concat_images_range_doppler[repeat_of_mixup*batch_size:,:,:,:] = range_doppler_training_data\n",
        "    concat_label[repeat_of_mixup*batch_size:,:] = labels\n",
        "    return (concat_images,concat_images_range_doppler, concat_label)\n",
        "def split_and_augmentation_of_training(spectrogram_concat_shuffle_train,range_doppler_concat_shuffle_train,range_doppler_concat_label_shuffle_train,\\\n",
        "                                       repeat_of_mixup, augmentation_enable):\n",
        "  # ---------------- Parameters ----------------\n",
        "  repeat_of_augmentation_for_fast = 1\n",
        "  repeat_of_augmentation_for_slow = np.floor(repeat_of_augmentation_for_fast/2)\n",
        "  repeat_of_augmentation_for_slow = int(repeat_of_augmentation_for_slow)\n",
        "  # size_of_validation = 30\n",
        "  alpha = 0.2\n",
        "  dummy_label = np.zeros((spectrogram_concat_shuffle_train.shape[0],1))\n",
        "  for randomlist_for_train_indx, randomlist_for_validation_indx in kfold.split(spectrogram_concat_shuffle_train,dummy_label):   \n",
        "    randomlist_for_validation_indx\n",
        "  # Split validation\n",
        "  # randomlist_for_validation_indx = random.sample(range(0, range_doppler_concat_shuffle_train.shape[0]), size_of_validation) # split validation data\n",
        "  # randomlist_for_train_indx = np.delete(range(0, range_doppler_concat_shuffle_train.shape[0]), randomlist_for_validation_indx) # split training data\n",
        "  # get validation data\n",
        "  spectrogram_validation_data = spectrogram_concat_shuffle_train[randomlist_for_validation_indx,:,:,:]\n",
        "  spectrogram_validation_labels = range_doppler_concat_label_shuffle_train[randomlist_for_validation_indx,:]\n",
        "  range_doppler_validation_data = range_doppler_concat_shuffle_train[randomlist_for_validation_indx,:,:,:]\n",
        "  # get training data\n",
        "  spectrogram_training_data = spectrogram_concat_shuffle_train[randomlist_for_train_indx,:,:,:]\n",
        "  spectrogram_training_labels = spectrogram_concat_label_shuffle_train[randomlist_for_train_indx,:]\n",
        "  range_doppler_training_data = range_doppler_concat_shuffle_train[randomlist_for_train_indx,:,:,:]\n",
        "\n",
        "  # Rotate Augmentation\n",
        "  # get slow and fast indexes of training data\n",
        "  slow_indexes = np.where(spectrogram_training_labels == 0)[0]\n",
        "  fast_indexes = np.delete(range(0, spectrogram_training_labels.shape[0]), slow_indexes)  \n",
        "\n",
        "  slow_spectrograms_train = spectrogram_training_data[slow_indexes,:,:,:]\n",
        "  size_of_samples_slow = slow_spectrograms_train.shape[0]\n",
        "\n",
        "  fast_spectrograms_train = spectrogram_training_data[fast_indexes,:,:,:]  \n",
        "  size_of_samples_fast = fast_spectrograms_train.shape[0]\n",
        "\n",
        "  slow_range_train = range_doppler_training_data[slow_indexes,:,:,:]\n",
        "  fast_range_train = range_doppler_training_data[fast_indexes,:,:,:]  \n",
        "\n",
        "  if augmentation_enable == True: \n",
        "    # ---------------- Augmente Train Data for Fast ----------------\n",
        "    augmented_image_fast = np.zeros((size_of_samples_fast*repeat_of_augmentation_for_fast,fast_spectrograms_train.shape[1],fast_spectrograms_train.shape[2],1))\n",
        "    spectrograms_fast_label = np.ones((size_of_samples_fast*(repeat_of_augmentation_for_fast+1),1))\n",
        "    # augmented_image_fast = np.flip(fast_spectrograms_train,axis=2)\n",
        "    for jj in range(repeat_of_augmentation_for_fast):\n",
        "      for ii in range(size_of_samples_fast):\n",
        "        augmented_image_fast[size_of_samples_fast*jj+ii,:,:,:] = data_augmentation(fast_spectrograms_train[ii,:,:,:])\n",
        "    augmented_image_fast = np.concatenate((augmented_image_fast,fast_spectrograms_train),axis=0)   \n",
        "\n",
        "    augmented_image_fast_range = np.zeros((size_of_samples_fast*repeat_of_augmentation_for_fast,fast_range_train.shape[1],fast_range_train.shape[2],1))\n",
        "    # augmented_image_fast_range  = np.flip(fast_range_train,axis=2)\n",
        "    for jj in range(repeat_of_augmentation_for_fast):\n",
        "      for ii in range(size_of_samples_fast):\n",
        "        augmented_image_fast_range[size_of_samples_fast*jj+ii,:,:,:]  =data_augmentation(fast_range_train[ii,:,:,:])\n",
        "    augmented_image_fast_range = np.concatenate((augmented_image_fast_range,fast_range_train),axis=0)   \n",
        "\n",
        "    # ---------------- Augmente Train Data for Slow ----------------\n",
        "    augmented_image_slow = slow_spectrograms_train\n",
        "    augmented_image_slow_range = slow_range_train\n",
        "\n",
        "  else:\n",
        "    augmented_image_fast = fast_spectrograms_train\n",
        "    augmented_image_slow = slow_spectrograms_train\n",
        "    augmented_image_fast_range = fast_range_train\n",
        "    augmented_image_slow_range = slow_range_train\n",
        "    spectrograms_fast_label = np.ones((size_of_samples_fast,1))\n",
        "    \n",
        "  spectrograms_slow_label = np.zeros((size_of_samples_slow,1))\n",
        "\n",
        "  spectrogram_training_data = np.concatenate((augmented_image_fast,augmented_image_slow),axis=0)\n",
        "  range_doppler_training_data = np.concatenate((augmented_image_fast_range,augmented_image_slow_range),axis=0)\n",
        "  spectrogram_training_labels = np.concatenate((spectrograms_fast_label,spectrograms_slow_label),axis=0)\n",
        "\n",
        "  (spectrogram_augmented_image,range_doppler_augmented_image,spectrograms_label)=\\\n",
        "   mixup_augmentation(spectrogram_training_data,range_doppler_training_data, spectrogram_training_labels, repeat_of_mixup, alpha=0.2)\n",
        "\n",
        "  return (spectrogram_augmented_image,range_doppler_augmented_image,spectrograms_label,\\\n",
        "     spectrogram_validation_data,range_doppler_validation_data, spectrogram_validation_labels)\n",
        "def normalize_inputs(range_doppler_concat_shuffle, normalize_inputs_enable):\n",
        "  # ---------------- Normalize Inputs ----------------\n",
        "  if normalize_inputs_enable == True:\n",
        "    layer = Normalization(axis=None)\n",
        "    layer.adapt(range_doppler_concat_shuffle)\n",
        "    range_doppler_concat_shuffle = layer(range_doppler_concat_shuffle)\n",
        "  else:\n",
        "    range_doppler_concat_shuffle = range_doppler_concat_shuffle\n",
        "  return(range_doppler_concat_shuffle)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8CUvxggth7ZQ"
      },
      "outputs": [],
      "source": [
        "normalize_inputs_enable = 1\n",
        "range_doppler_concat_shuffle = normalize_inputs(range_doppler_concat_shuffle, normalize_inputs_enable)\n",
        "spectrogram_concat_shuffle = normalize_inputs(spectrogram_concat_shuffle, normalize_inputs_enable)\n",
        "range_doppler_concat_shuffle = np.float32(range_doppler_concat_shuffle)\n",
        "spectrogram_concat_shuffle = np.float32(spectrogram_concat_shuffle)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "38jkSYXM4aey"
      },
      "outputs": [],
      "source": [
        "n_features = range_doppler_concat_shuffle.shape[1]\n",
        "n_steps = range_doppler_concat_shuffle.shape[2]\n",
        "range_doppler_concat_shuffle = np.transpose(range_doppler_concat_shuffle, axes = (0,2,1,3)) \n",
        "spectrogram_concat_shuffle = np.transpose(spectrogram_concat_shuffle, axes = (0,2,1,3)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNpkBBIadpPo",
        "outputId": "9e23d184-6a2d-47af-9d68-31fb351630c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 5120, 52)]        0         \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 5120, 16)         3904      \n",
            " l)                                                              \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 81920)             0         \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 81920)            327680    \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 81920)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               20971776  \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 256)              1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation (Activation)     (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21,304,384\n",
            "Trainable params: 21,140,032\n",
            "Non-trainable params: 164,352\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 423, 52)]         0         \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 423, 16)          3904      \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 6768)              0         \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 6768)             27072     \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 6768)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 8)                 54152     \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 8)                32        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 8)                 0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 8)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 85,160\n",
            "Trainable params: 71,608\n",
            "Non-trainable params: 13,552\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 264)]             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               67840     \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 256)              1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 64)                16448     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 64)                0         \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 85,377\n",
            "Trainable params: 84,865\n",
            "Non-trainable params: 512\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "28/28 [==============================] - 21s 435ms/step - loss: 0.5194 - accuracy: 0.4885 - val_loss: 0.6229 - val_accuracy: 0.8148\n",
            "Epoch 2/100\n",
            "28/28 [==============================] - 11s 381ms/step - loss: 0.4308 - accuracy: 0.5310 - val_loss: 0.4072 - val_accuracy: 0.8889\n",
            "Epoch 3/100\n",
            "28/28 [==============================] - 11s 383ms/step - loss: 0.3686 - accuracy: 0.5540 - val_loss: 0.3437 - val_accuracy: 0.8519\n",
            "Epoch 4/100\n",
            "28/28 [==============================] - 11s 382ms/step - loss: 0.3545 - accuracy: 0.5494 - val_loss: 0.3427 - val_accuracy: 0.8889\n",
            "Epoch 5/100\n",
            "28/28 [==============================] - 11s 379ms/step - loss: 0.3251 - accuracy: 0.5655 - val_loss: 0.4164 - val_accuracy: 0.8519\n",
            "Epoch 6/100\n",
            "28/28 [==============================] - 11s 381ms/step - loss: 0.3170 - accuracy: 0.5655 - val_loss: 0.3386 - val_accuracy: 0.8889\n",
            "Epoch 7/100\n",
            "28/28 [==============================] - 11s 381ms/step - loss: 0.3145 - accuracy: 0.5667 - val_loss: 0.3354 - val_accuracy: 0.8889\n",
            "Epoch 8/100\n",
            "28/28 [==============================] - 11s 381ms/step - loss: 0.3173 - accuracy: 0.5690 - val_loss: 0.3048 - val_accuracy: 0.8889\n",
            "Epoch 9/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.3117 - accuracy: 0.5678 - val_loss: 0.2828 - val_accuracy: 0.8889\n",
            "Epoch 10/100\n",
            "28/28 [==============================] - 11s 379ms/step - loss: 0.3008 - accuracy: 0.5678 - val_loss: 0.3055 - val_accuracy: 0.8889\n",
            "Epoch 11/100\n",
            "28/28 [==============================] - 11s 379ms/step - loss: 0.2948 - accuracy: 0.5678 - val_loss: 0.2981 - val_accuracy: 0.8889\n",
            "Epoch 12/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.3005 - accuracy: 0.5690 - val_loss: 0.3169 - val_accuracy: 0.9259\n",
            "Epoch 13/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.2934 - accuracy: 0.5690 - val_loss: 0.3868 - val_accuracy: 0.8889\n",
            "Epoch 14/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.2944 - accuracy: 0.5701 - val_loss: 0.2982 - val_accuracy: 0.8889\n",
            "Epoch 15/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.2982 - accuracy: 0.5667 - val_loss: 0.3233 - val_accuracy: 0.8889\n",
            "Epoch 16/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.3094 - accuracy: 0.5678 - val_loss: 0.2881 - val_accuracy: 0.8889\n",
            "Epoch 17/100\n",
            "28/28 [==============================] - 11s 381ms/step - loss: 0.2970 - accuracy: 0.5701 - val_loss: 0.3261 - val_accuracy: 0.8889\n",
            "Epoch 18/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.2844 - accuracy: 0.5678 - val_loss: 0.3060 - val_accuracy: 0.9259\n",
            "Epoch 19/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.2820 - accuracy: 0.5701 - val_loss: 0.3389 - val_accuracy: 0.8889\n",
            "Epoch 20/100\n",
            "28/28 [==============================] - 11s 378ms/step - loss: 0.2888 - accuracy: 0.5701 - val_loss: 0.3532 - val_accuracy: 0.8889\n",
            "Epoch 21/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.2821 - accuracy: 0.5701 - val_loss: 0.3229 - val_accuracy: 0.9259\n",
            "Epoch 22/100\n",
            "28/28 [==============================] - 11s 378ms/step - loss: 0.2843 - accuracy: 0.5690 - val_loss: 0.3385 - val_accuracy: 0.9259\n",
            "Epoch 23/100\n",
            "28/28 [==============================] - 11s 379ms/step - loss: 0.2796 - accuracy: 0.5701 - val_loss: 0.3464 - val_accuracy: 0.8889\n",
            "Epoch 24/100\n",
            "28/28 [==============================] - 11s 382ms/step - loss: 0.2837 - accuracy: 0.5690 - val_loss: 0.2746 - val_accuracy: 0.9259\n",
            "Epoch 25/100\n",
            "28/28 [==============================] - 11s 379ms/step - loss: 0.2841 - accuracy: 0.5701 - val_loss: 0.4527 - val_accuracy: 0.9259\n",
            "Epoch 26/100\n",
            "28/28 [==============================] - 11s 381ms/step - loss: 0.2828 - accuracy: 0.5701 - val_loss: 0.2545 - val_accuracy: 0.8889\n",
            "Epoch 27/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.2713 - accuracy: 0.5701 - val_loss: 0.3086 - val_accuracy: 0.8889\n",
            "Epoch 28/100\n",
            "28/28 [==============================] - 11s 378ms/step - loss: 0.2741 - accuracy: 0.5701 - val_loss: 0.3303 - val_accuracy: 0.8889\n",
            "Epoch 29/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2668 - accuracy: 0.5701 - val_loss: 0.3232 - val_accuracy: 0.8889\n",
            "Epoch 30/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.2804 - accuracy: 0.5701 - val_loss: 0.3931 - val_accuracy: 0.8519\n",
            "Epoch 31/100\n",
            "28/28 [==============================] - 11s 379ms/step - loss: 0.2798 - accuracy: 0.5701 - val_loss: 0.4715 - val_accuracy: 0.8519\n",
            "Epoch 32/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.2856 - accuracy: 0.5690 - val_loss: 0.3339 - val_accuracy: 0.8889\n",
            "Epoch 33/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.2685 - accuracy: 0.5701 - val_loss: 0.3192 - val_accuracy: 0.8889\n",
            "Epoch 34/100\n",
            "28/28 [==============================] - 11s 381ms/step - loss: 0.2674 - accuracy: 0.5701 - val_loss: 0.3694 - val_accuracy: 0.8519\n",
            "Epoch 35/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.2764 - accuracy: 0.5701 - val_loss: 0.2745 - val_accuracy: 0.9259\n",
            "Epoch 36/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.2666 - accuracy: 0.5701 - val_loss: 0.3479 - val_accuracy: 0.8889\n",
            "Epoch 37/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.2700 - accuracy: 0.5701 - val_loss: 0.2739 - val_accuracy: 0.9259\n",
            "Epoch 38/100\n",
            "28/28 [==============================] - 11s 382ms/step - loss: 0.2684 - accuracy: 0.5701 - val_loss: 0.2530 - val_accuracy: 0.9259\n",
            "Epoch 39/100\n",
            "28/28 [==============================] - 11s 378ms/step - loss: 0.2683 - accuracy: 0.5701 - val_loss: 0.3476 - val_accuracy: 0.8889\n",
            "Epoch 40/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.2635 - accuracy: 0.5701 - val_loss: 0.3041 - val_accuracy: 0.8889\n",
            "Epoch 41/100\n",
            "28/28 [==============================] - 11s 379ms/step - loss: 0.2614 - accuracy: 0.5701 - val_loss: 0.3819 - val_accuracy: 0.8519\n",
            "Epoch 42/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.2679 - accuracy: 0.5701 - val_loss: 0.2979 - val_accuracy: 0.8889\n",
            "Epoch 43/100\n",
            "28/28 [==============================] - 11s 383ms/step - loss: 0.2688 - accuracy: 0.5701 - val_loss: 0.2496 - val_accuracy: 0.8889\n",
            "Epoch 44/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.2659 - accuracy: 0.5690 - val_loss: 0.4589 - val_accuracy: 0.8519\n",
            "Epoch 45/100\n",
            "28/28 [==============================] - 11s 379ms/step - loss: 0.2718 - accuracy: 0.5690 - val_loss: 0.3868 - val_accuracy: 0.8889\n",
            "Epoch 46/100\n",
            "28/28 [==============================] - 11s 378ms/step - loss: 0.2704 - accuracy: 0.5690 - val_loss: 0.3280 - val_accuracy: 0.8889\n",
            "Epoch 47/100\n",
            "28/28 [==============================] - 11s 379ms/step - loss: 0.2670 - accuracy: 0.5701 - val_loss: 0.3164 - val_accuracy: 0.9259\n",
            "Epoch 48/100\n",
            "28/28 [==============================] - 11s 378ms/step - loss: 0.2634 - accuracy: 0.5701 - val_loss: 0.4206 - val_accuracy: 0.8889\n",
            "Epoch 49/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.2627 - accuracy: 0.5701 - val_loss: 0.2984 - val_accuracy: 0.9259\n",
            "Epoch 50/100\n",
            "28/28 [==============================] - 11s 378ms/step - loss: 0.2597 - accuracy: 0.5701 - val_loss: 0.2913 - val_accuracy: 0.9259\n",
            "Epoch 51/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2714 - accuracy: 0.5701 - val_loss: 0.2498 - val_accuracy: 0.9259\n",
            "Epoch 52/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.2635 - accuracy: 0.5690 - val_loss: 0.2984 - val_accuracy: 0.8148\n",
            "Epoch 53/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2661 - accuracy: 0.5701 - val_loss: 0.2689 - val_accuracy: 0.8889\n",
            "Epoch 54/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.2623 - accuracy: 0.5701 - val_loss: 0.2729 - val_accuracy: 0.9259\n",
            "Epoch 55/100\n",
            "28/28 [==============================] - 11s 378ms/step - loss: 0.2728 - accuracy: 0.5701 - val_loss: 0.2700 - val_accuracy: 0.8889\n",
            "Epoch 56/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.2813 - accuracy: 0.5701 - val_loss: 0.3657 - val_accuracy: 0.9259\n",
            "Epoch 57/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2617 - accuracy: 0.5701 - val_loss: 0.3715 - val_accuracy: 0.9259\n",
            "Epoch 58/100\n",
            "28/28 [==============================] - 11s 378ms/step - loss: 0.2621 - accuracy: 0.5690 - val_loss: 0.2899 - val_accuracy: 0.9259\n",
            "2/2 [==============================] - 2s 132ms/step - loss: 0.1925 - accuracy: 0.9706\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 5120, 52)]        0         \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 5120, 16)         3904      \n",
            " l)                                                              \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 81920)             0         \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 81920)            327680    \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 81920)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               20971776  \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 256)              1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation (Activation)     (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21,304,384\n",
            "Trainable params: 21,140,032\n",
            "Non-trainable params: 164,352\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 423, 52)]         0         \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 423, 16)          3904      \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 6768)              0         \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 6768)             27072     \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 6768)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 8)                 54152     \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 8)                32        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 8)                 0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 8)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 85,160\n",
            "Trainable params: 71,608\n",
            "Non-trainable params: 13,552\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 264)]             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               67840     \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 256)              1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 64)                16448     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 64)                0         \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 85,377\n",
            "Trainable params: 84,865\n",
            "Non-trainable params: 512\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "27/27 [==============================] - 17s 452ms/step - loss: 0.5421 - accuracy: 0.5197 - val_loss: 0.2898 - val_accuracy: 0.8889\n",
            "Epoch 2/100\n",
            "27/27 [==============================] - 10s 388ms/step - loss: 0.4069 - accuracy: 0.5637 - val_loss: 0.2475 - val_accuracy: 0.8519\n",
            "Epoch 3/100\n",
            "27/27 [==============================] - 10s 389ms/step - loss: 0.3664 - accuracy: 0.5752 - val_loss: 0.1757 - val_accuracy: 0.9630\n",
            "Epoch 4/100\n",
            "27/27 [==============================] - 10s 388ms/step - loss: 0.3247 - accuracy: 0.5949 - val_loss: 0.1647 - val_accuracy: 0.9630\n",
            "Epoch 5/100\n",
            "27/27 [==============================] - 10s 389ms/step - loss: 0.3224 - accuracy: 0.5891 - val_loss: 0.1569 - val_accuracy: 0.9630\n",
            "Epoch 6/100\n",
            "27/27 [==============================] - 10s 389ms/step - loss: 0.3013 - accuracy: 0.6042 - val_loss: 0.1430 - val_accuracy: 0.9630\n",
            "Epoch 7/100\n",
            "27/27 [==============================] - 10s 386ms/step - loss: 0.3011 - accuracy: 0.6053 - val_loss: 0.1532 - val_accuracy: 0.9630\n",
            "Epoch 8/100\n",
            "27/27 [==============================] - 10s 389ms/step - loss: 0.3001 - accuracy: 0.6007 - val_loss: 0.1269 - val_accuracy: 0.9630\n",
            "Epoch 9/100\n",
            "27/27 [==============================] - 10s 389ms/step - loss: 0.2882 - accuracy: 0.6042 - val_loss: 0.1519 - val_accuracy: 0.9630\n",
            "Epoch 10/100\n",
            "27/27 [==============================] - 10s 387ms/step - loss: 0.2835 - accuracy: 0.6065 - val_loss: 0.1358 - val_accuracy: 0.9630\n",
            "Epoch 11/100\n",
            "27/27 [==============================] - 10s 388ms/step - loss: 0.2854 - accuracy: 0.6030 - val_loss: 0.1050 - val_accuracy: 0.9630\n",
            "Epoch 12/100\n",
            "27/27 [==============================] - 10s 389ms/step - loss: 0.2741 - accuracy: 0.6065 - val_loss: 0.1203 - val_accuracy: 0.9630\n",
            "Epoch 13/100\n",
            "27/27 [==============================] - 10s 388ms/step - loss: 0.2790 - accuracy: 0.6053 - val_loss: 0.1143 - val_accuracy: 0.9630\n",
            "Epoch 14/100\n",
            "27/27 [==============================] - 10s 387ms/step - loss: 0.2744 - accuracy: 0.6065 - val_loss: 0.1133 - val_accuracy: 1.0000\n",
            "Epoch 15/100\n",
            "27/27 [==============================] - 10s 387ms/step - loss: 0.2706 - accuracy: 0.6065 - val_loss: 0.0945 - val_accuracy: 1.0000\n",
            "Epoch 16/100\n",
            "27/27 [==============================] - 10s 387ms/step - loss: 0.2658 - accuracy: 0.6065 - val_loss: 0.1079 - val_accuracy: 0.9630\n",
            "Epoch 17/100\n",
            "27/27 [==============================] - 10s 386ms/step - loss: 0.2651 - accuracy: 0.6053 - val_loss: 0.1140 - val_accuracy: 0.9630\n",
            "Epoch 18/100\n",
            "27/27 [==============================] - 10s 387ms/step - loss: 0.2727 - accuracy: 0.6053 - val_loss: 0.2065 - val_accuracy: 0.8889\n",
            "Epoch 19/100\n",
            "27/27 [==============================] - 10s 387ms/step - loss: 0.2557 - accuracy: 0.6065 - val_loss: 0.1083 - val_accuracy: 0.9630\n",
            "Epoch 20/100\n",
            "27/27 [==============================] - 10s 387ms/step - loss: 0.2585 - accuracy: 0.6065 - val_loss: 0.0983 - val_accuracy: 0.9259\n",
            "Epoch 21/100\n",
            "27/27 [==============================] - 10s 387ms/step - loss: 0.2549 - accuracy: 0.6065 - val_loss: 0.0820 - val_accuracy: 1.0000\n",
            "Epoch 22/100\n",
            "27/27 [==============================] - 10s 387ms/step - loss: 0.2617 - accuracy: 0.6065 - val_loss: 0.0860 - val_accuracy: 1.0000\n",
            "Epoch 23/100\n",
            "27/27 [==============================] - 10s 389ms/step - loss: 0.2673 - accuracy: 0.6053 - val_loss: 0.1401 - val_accuracy: 0.9259\n",
            "Epoch 24/100\n",
            "27/27 [==============================] - 10s 386ms/step - loss: 0.2531 - accuracy: 0.6065 - val_loss: 0.1076 - val_accuracy: 0.9630\n",
            "Epoch 25/100\n",
            "27/27 [==============================] - 10s 389ms/step - loss: 0.2531 - accuracy: 0.6065 - val_loss: 0.1278 - val_accuracy: 0.9259\n",
            "Epoch 26/100\n",
            "27/27 [==============================] - 10s 387ms/step - loss: 0.2552 - accuracy: 0.6065 - val_loss: 0.1063 - val_accuracy: 0.9259\n",
            "Epoch 27/100\n",
            "27/27 [==============================] - 10s 387ms/step - loss: 0.2558 - accuracy: 0.6065 - val_loss: 0.1309 - val_accuracy: 0.9259\n",
            "Epoch 28/100\n",
            "27/27 [==============================] - 10s 389ms/step - loss: 0.2599 - accuracy: 0.6065 - val_loss: 0.1363 - val_accuracy: 0.9259\n",
            "Epoch 29/100\n",
            "27/27 [==============================] - 10s 388ms/step - loss: 0.2544 - accuracy: 0.6065 - val_loss: 0.1757 - val_accuracy: 0.9259\n",
            "Epoch 30/100\n",
            "27/27 [==============================] - 10s 387ms/step - loss: 0.2608 - accuracy: 0.6065 - val_loss: 0.1217 - val_accuracy: 0.9259\n",
            "Epoch 31/100\n",
            "27/27 [==============================] - 10s 384ms/step - loss: 0.2504 - accuracy: 0.6065 - val_loss: 0.1683 - val_accuracy: 0.9259\n",
            "Epoch 32/100\n",
            "27/27 [==============================] - 10s 389ms/step - loss: 0.2482 - accuracy: 0.6065 - val_loss: 0.1740 - val_accuracy: 0.8889\n",
            "Epoch 33/100\n",
            "27/27 [==============================] - 10s 387ms/step - loss: 0.2484 - accuracy: 0.6065 - val_loss: 0.1001 - val_accuracy: 0.9630\n",
            "Epoch 34/100\n",
            "27/27 [==============================] - 10s 386ms/step - loss: 0.2486 - accuracy: 0.6065 - val_loss: 0.1836 - val_accuracy: 0.8889\n",
            "Epoch 35/100\n",
            "27/27 [==============================] - 10s 389ms/step - loss: 0.2479 - accuracy: 0.6065 - val_loss: 0.1941 - val_accuracy: 0.9259\n",
            "Epoch 36/100\n",
            "27/27 [==============================] - 10s 389ms/step - loss: 0.2466 - accuracy: 0.6065 - val_loss: 0.1762 - val_accuracy: 0.9259\n",
            "2/2 [==============================] - 2s 125ms/step - loss: 0.1220 - accuracy: 0.9706\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 5120, 52)]        0         \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 5120, 16)         3904      \n",
            " l)                                                              \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 81920)             0         \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 81920)            327680    \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 81920)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               20971776  \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 256)              1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation (Activation)     (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21,304,384\n",
            "Trainable params: 21,140,032\n",
            "Non-trainable params: 164,352\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 423, 52)]         0         \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 423, 16)          3904      \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 6768)              0         \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 6768)             27072     \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 6768)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 8)                 54152     \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 8)                32        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 8)                 0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 8)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 85,160\n",
            "Trainable params: 71,608\n",
            "Non-trainable params: 13,552\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 264)]             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               67840     \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 256)              1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 64)                16448     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 64)                0         \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 85,377\n",
            "Trainable params: 84,865\n",
            "Non-trainable params: 512\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "28/28 [==============================] - 18s 428ms/step - loss: 0.5419 - accuracy: 0.5000 - val_loss: 0.3595 - val_accuracy: 0.8889\n",
            "Epoch 2/100\n",
            "28/28 [==============================] - 11s 381ms/step - loss: 0.4090 - accuracy: 0.5374 - val_loss: 0.2568 - val_accuracy: 0.8889\n",
            "Epoch 3/100\n",
            "28/28 [==============================] - 11s 381ms/step - loss: 0.3914 - accuracy: 0.5590 - val_loss: 0.1206 - val_accuracy: 0.9630\n",
            "Epoch 4/100\n",
            "28/28 [==============================] - 11s 378ms/step - loss: 0.3633 - accuracy: 0.5748 - val_loss: 0.1422 - val_accuracy: 0.9630\n",
            "Epoch 5/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.3553 - accuracy: 0.5703 - val_loss: 0.0971 - val_accuracy: 1.0000\n",
            "Epoch 6/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.3288 - accuracy: 0.5794 - val_loss: 0.1112 - val_accuracy: 1.0000\n",
            "Epoch 7/100\n",
            "28/28 [==============================] - 11s 379ms/step - loss: 0.3196 - accuracy: 0.5839 - val_loss: 0.2199 - val_accuracy: 1.0000\n",
            "Epoch 8/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.3213 - accuracy: 0.5816 - val_loss: 0.4005 - val_accuracy: 0.8519\n",
            "Epoch 9/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.3129 - accuracy: 0.5850 - val_loss: 0.0585 - val_accuracy: 1.0000\n",
            "Epoch 10/100\n",
            "28/28 [==============================] - 11s 378ms/step - loss: 0.3067 - accuracy: 0.5816 - val_loss: 0.1476 - val_accuracy: 1.0000\n",
            "Epoch 11/100\n",
            "28/28 [==============================] - 11s 379ms/step - loss: 0.3057 - accuracy: 0.5862 - val_loss: 0.1264 - val_accuracy: 1.0000\n",
            "Epoch 12/100\n",
            "28/28 [==============================] - 11s 378ms/step - loss: 0.3014 - accuracy: 0.5828 - val_loss: 0.2207 - val_accuracy: 0.8519\n",
            "Epoch 13/100\n",
            "28/28 [==============================] - 11s 378ms/step - loss: 0.2927 - accuracy: 0.5839 - val_loss: 0.0692 - val_accuracy: 1.0000\n",
            "Epoch 14/100\n",
            "28/28 [==============================] - 11s 378ms/step - loss: 0.2935 - accuracy: 0.5873 - val_loss: 0.0624 - val_accuracy: 1.0000\n",
            "Epoch 15/100\n",
            "28/28 [==============================] - 11s 378ms/step - loss: 0.2841 - accuracy: 0.5873 - val_loss: 0.0612 - val_accuracy: 0.9630\n",
            "Epoch 16/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.2773 - accuracy: 0.5862 - val_loss: 0.0555 - val_accuracy: 1.0000\n",
            "Epoch 17/100\n",
            "28/28 [==============================] - 11s 383ms/step - loss: 0.2783 - accuracy: 0.5873 - val_loss: 0.0470 - val_accuracy: 1.0000\n",
            "Epoch 18/100\n",
            "28/28 [==============================] - 11s 381ms/step - loss: 0.2727 - accuracy: 0.5873 - val_loss: 0.0478 - val_accuracy: 1.0000\n",
            "Epoch 19/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.2835 - accuracy: 0.5873 - val_loss: 0.0897 - val_accuracy: 1.0000\n",
            "Epoch 20/100\n",
            "28/28 [==============================] - 11s 381ms/step - loss: 0.2746 - accuracy: 0.5873 - val_loss: 0.0719 - val_accuracy: 1.0000\n",
            "Epoch 21/100\n",
            "28/28 [==============================] - 11s 381ms/step - loss: 0.2719 - accuracy: 0.5862 - val_loss: 0.0622 - val_accuracy: 1.0000\n",
            "Epoch 22/100\n",
            "28/28 [==============================] - 11s 382ms/step - loss: 0.2783 - accuracy: 0.5873 - val_loss: 0.0842 - val_accuracy: 0.9630\n",
            "Epoch 23/100\n",
            "28/28 [==============================] - 11s 382ms/step - loss: 0.2759 - accuracy: 0.5862 - val_loss: 0.0434 - val_accuracy: 1.0000\n",
            "Epoch 24/100\n",
            "28/28 [==============================] - 11s 384ms/step - loss: 0.2742 - accuracy: 0.5873 - val_loss: 0.0419 - val_accuracy: 1.0000\n",
            "Epoch 25/100\n",
            "28/28 [==============================] - 11s 382ms/step - loss: 0.2719 - accuracy: 0.5873 - val_loss: 0.0636 - val_accuracy: 1.0000\n",
            "Epoch 26/100\n",
            "28/28 [==============================] - 11s 381ms/step - loss: 0.2646 - accuracy: 0.5873 - val_loss: 0.0600 - val_accuracy: 1.0000\n",
            "Epoch 27/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.2740 - accuracy: 0.5850 - val_loss: 0.0670 - val_accuracy: 1.0000\n",
            "Epoch 28/100\n",
            "28/28 [==============================] - 11s 381ms/step - loss: 0.2701 - accuracy: 0.5862 - val_loss: 0.0735 - val_accuracy: 1.0000\n",
            "Epoch 29/100\n",
            "28/28 [==============================] - 11s 381ms/step - loss: 0.2670 - accuracy: 0.5873 - val_loss: 0.0796 - val_accuracy: 0.9630\n",
            "Epoch 30/100\n",
            "28/28 [==============================] - 11s 381ms/step - loss: 0.2602 - accuracy: 0.5873 - val_loss: 0.0510 - val_accuracy: 1.0000\n",
            "Epoch 31/100\n",
            "28/28 [==============================] - 11s 379ms/step - loss: 0.2624 - accuracy: 0.5873 - val_loss: 0.0840 - val_accuracy: 0.9630\n",
            "Epoch 32/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.2593 - accuracy: 0.5873 - val_loss: 0.2572 - val_accuracy: 0.9259\n",
            "Epoch 33/100\n",
            "28/28 [==============================] - 11s 382ms/step - loss: 0.2657 - accuracy: 0.5873 - val_loss: 0.1594 - val_accuracy: 0.9630\n",
            "Epoch 34/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.2577 - accuracy: 0.5873 - val_loss: 0.0754 - val_accuracy: 1.0000\n",
            "Epoch 35/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.2654 - accuracy: 0.5873 - val_loss: 0.0826 - val_accuracy: 1.0000\n",
            "Epoch 36/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.2524 - accuracy: 0.5873 - val_loss: 0.0657 - val_accuracy: 0.9630\n",
            "Epoch 37/100\n",
            "28/28 [==============================] - 11s 381ms/step - loss: 0.2560 - accuracy: 0.5873 - val_loss: 0.1878 - val_accuracy: 0.8889\n",
            "Epoch 38/100\n",
            "28/28 [==============================] - 11s 381ms/step - loss: 0.2608 - accuracy: 0.5873 - val_loss: 0.1651 - val_accuracy: 0.9630\n",
            "Epoch 39/100\n",
            "28/28 [==============================] - 11s 381ms/step - loss: 0.2581 - accuracy: 0.5873 - val_loss: 0.0917 - val_accuracy: 0.9630\n",
            "2/2 [==============================] - 2s 120ms/step - loss: 0.0294 - accuracy: 1.0000\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 5120, 52)]        0         \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 5120, 16)         3904      \n",
            " l)                                                              \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 81920)             0         \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 81920)            327680    \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 81920)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               20971776  \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 256)              1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation (Activation)     (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21,304,384\n",
            "Trainable params: 21,140,032\n",
            "Non-trainable params: 164,352\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 423, 52)]         0         \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 423, 16)          3904      \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 6768)              0         \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 6768)             27072     \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 6768)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 8)                 54152     \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 8)                32        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 8)                 0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 8)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 85,160\n",
            "Trainable params: 71,608\n",
            "Non-trainable params: 13,552\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 264)]             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               67840     \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 256)              1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 64)                16448     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 64)                0         \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 85,377\n",
            "Trainable params: 84,865\n",
            "Non-trainable params: 512\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "28/28 [==============================] - 18s 430ms/step - loss: 0.4917 - accuracy: 0.5057 - val_loss: 0.3923 - val_accuracy: 0.8889\n",
            "Epoch 2/100\n",
            "28/28 [==============================] - 11s 384ms/step - loss: 0.4218 - accuracy: 0.5476 - val_loss: 0.2033 - val_accuracy: 0.8889\n",
            "Epoch 3/100\n",
            "28/28 [==============================] - 11s 384ms/step - loss: 0.3809 - accuracy: 0.5488 - val_loss: 0.1876 - val_accuracy: 0.9259\n",
            "Epoch 4/100\n",
            "28/28 [==============================] - 11s 383ms/step - loss: 0.3447 - accuracy: 0.5658 - val_loss: 0.1410 - val_accuracy: 0.9259\n",
            "Epoch 5/100\n",
            "28/28 [==============================] - 11s 381ms/step - loss: 0.3313 - accuracy: 0.5658 - val_loss: 0.1813 - val_accuracy: 0.9259\n",
            "Epoch 6/100\n",
            "28/28 [==============================] - 11s 382ms/step - loss: 0.3120 - accuracy: 0.5714 - val_loss: 0.1731 - val_accuracy: 0.8889\n",
            "Epoch 7/100\n",
            "28/28 [==============================] - 11s 382ms/step - loss: 0.3017 - accuracy: 0.5714 - val_loss: 0.2116 - val_accuracy: 0.9259\n",
            "Epoch 8/100\n",
            "28/28 [==============================] - 11s 378ms/step - loss: 0.3053 - accuracy: 0.5714 - val_loss: 0.1656 - val_accuracy: 0.9259\n",
            "Epoch 9/100\n",
            "28/28 [==============================] - 11s 382ms/step - loss: 0.3015 - accuracy: 0.5726 - val_loss: 0.1351 - val_accuracy: 0.9259\n",
            "Epoch 10/100\n",
            "28/28 [==============================] - 11s 382ms/step - loss: 0.2941 - accuracy: 0.5737 - val_loss: 0.1143 - val_accuracy: 1.0000\n",
            "Epoch 11/100\n",
            "28/28 [==============================] - 11s 383ms/step - loss: 0.2951 - accuracy: 0.5748 - val_loss: 0.0895 - val_accuracy: 1.0000\n",
            "Epoch 12/100\n",
            "28/28 [==============================] - 11s 381ms/step - loss: 0.2896 - accuracy: 0.5737 - val_loss: 0.1175 - val_accuracy: 0.9630\n",
            "Epoch 13/100\n",
            "28/28 [==============================] - 11s 382ms/step - loss: 0.2877 - accuracy: 0.5760 - val_loss: 0.1685 - val_accuracy: 0.9259\n",
            "Epoch 14/100\n",
            "28/28 [==============================] - 11s 381ms/step - loss: 0.3018 - accuracy: 0.5692 - val_loss: 0.1934 - val_accuracy: 0.9259\n",
            "Epoch 15/100\n",
            "28/28 [==============================] - 11s 382ms/step - loss: 0.2928 - accuracy: 0.5737 - val_loss: 0.1135 - val_accuracy: 0.9630\n",
            "Epoch 16/100\n",
            "28/28 [==============================] - 11s 382ms/step - loss: 0.2764 - accuracy: 0.5748 - val_loss: 0.1227 - val_accuracy: 0.9259\n",
            "Epoch 17/100\n",
            "28/28 [==============================] - 11s 379ms/step - loss: 0.2820 - accuracy: 0.5760 - val_loss: 0.1929 - val_accuracy: 0.9259\n",
            "Epoch 18/100\n",
            "28/28 [==============================] - 11s 381ms/step - loss: 0.2757 - accuracy: 0.5737 - val_loss: 0.1036 - val_accuracy: 0.9630\n",
            "Epoch 19/100\n",
            "28/28 [==============================] - 11s 379ms/step - loss: 0.2761 - accuracy: 0.5748 - val_loss: 0.1204 - val_accuracy: 0.9630\n",
            "Epoch 20/100\n",
            "28/28 [==============================] - 10s 375ms/step - loss: 0.2729 - accuracy: 0.5760 - val_loss: 0.1415 - val_accuracy: 0.9259\n",
            "Epoch 21/100\n",
            "28/28 [==============================] - 11s 379ms/step - loss: 0.2704 - accuracy: 0.5748 - val_loss: 0.0791 - val_accuracy: 1.0000\n",
            "Epoch 22/100\n",
            "28/28 [==============================] - 11s 375ms/step - loss: 0.2860 - accuracy: 0.5760 - val_loss: 0.1541 - val_accuracy: 0.9259\n",
            "Epoch 23/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2745 - accuracy: 0.5760 - val_loss: 0.1609 - val_accuracy: 0.9259\n",
            "Epoch 24/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.2770 - accuracy: 0.5760 - val_loss: 0.1218 - val_accuracy: 0.9630\n",
            "Epoch 25/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2712 - accuracy: 0.5737 - val_loss: 0.1470 - val_accuracy: 0.9259\n",
            "Epoch 26/100\n",
            "28/28 [==============================] - 11s 375ms/step - loss: 0.2737 - accuracy: 0.5760 - val_loss: 0.1856 - val_accuracy: 0.8889\n",
            "Epoch 27/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.2725 - accuracy: 0.5748 - val_loss: 0.1456 - val_accuracy: 0.9259\n",
            "Epoch 28/100\n",
            "28/28 [==============================] - 11s 375ms/step - loss: 0.2655 - accuracy: 0.5760 - val_loss: 0.1347 - val_accuracy: 0.9630\n",
            "Epoch 29/100\n",
            "28/28 [==============================] - 11s 378ms/step - loss: 0.2637 - accuracy: 0.5760 - val_loss: 0.1111 - val_accuracy: 1.0000\n",
            "Epoch 30/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.2779 - accuracy: 0.5748 - val_loss: 0.1302 - val_accuracy: 0.8889\n",
            "Epoch 31/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.2660 - accuracy: 0.5748 - val_loss: 0.1152 - val_accuracy: 0.9630\n",
            "Epoch 32/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2605 - accuracy: 0.5760 - val_loss: 0.1522 - val_accuracy: 0.9259\n",
            "Epoch 33/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2615 - accuracy: 0.5760 - val_loss: 0.1295 - val_accuracy: 0.9630\n",
            "Epoch 34/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2553 - accuracy: 0.5760 - val_loss: 0.1407 - val_accuracy: 0.9630\n",
            "Epoch 35/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2571 - accuracy: 0.5760 - val_loss: 0.2181 - val_accuracy: 0.9259\n",
            "Epoch 36/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.2689 - accuracy: 0.5760 - val_loss: 0.1858 - val_accuracy: 0.9259\n",
            "2/2 [==============================] - 2s 127ms/step - loss: 0.1837 - accuracy: 0.9412\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 5120, 52)]        0         \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 5120, 16)         3904      \n",
            " l)                                                              \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 81920)             0         \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 81920)            327680    \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 81920)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               20971776  \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 256)              1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation (Activation)     (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21,304,384\n",
            "Trainable params: 21,140,032\n",
            "Non-trainable params: 164,352\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 423, 52)]         0         \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 423, 16)          3904      \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 6768)              0         \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 6768)             27072     \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 6768)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 8)                 54152     \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 8)                32        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 8)                 0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 8)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 85,160\n",
            "Trainable params: 71,608\n",
            "Non-trainable params: 13,552\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 264)]             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               67840     \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 256)              1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 64)                16448     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 64)                0         \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 85,377\n",
            "Trainable params: 84,865\n",
            "Non-trainable params: 512\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "28/28 [==============================] - 18s 426ms/step - loss: 0.5369 - accuracy: 0.4885 - val_loss: 0.4051 - val_accuracy: 0.8148\n",
            "Epoch 2/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.4088 - accuracy: 0.5448 - val_loss: 0.2127 - val_accuracy: 0.8889\n",
            "Epoch 3/100\n",
            "28/28 [==============================] - 10s 374ms/step - loss: 0.3806 - accuracy: 0.5575 - val_loss: 0.2419 - val_accuracy: 0.8889\n",
            "Epoch 4/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.3584 - accuracy: 0.5586 - val_loss: 0.2086 - val_accuracy: 0.9259\n",
            "Epoch 5/100\n",
            "28/28 [==============================] - 10s 374ms/step - loss: 0.3383 - accuracy: 0.5655 - val_loss: 0.2102 - val_accuracy: 0.8889\n",
            "Epoch 6/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.3226 - accuracy: 0.5701 - val_loss: 0.1802 - val_accuracy: 0.9630\n",
            "Epoch 7/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.3333 - accuracy: 0.5713 - val_loss: 0.1701 - val_accuracy: 0.9630\n",
            "Epoch 8/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.3122 - accuracy: 0.5759 - val_loss: 0.1908 - val_accuracy: 0.9259\n",
            "Epoch 9/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.3108 - accuracy: 0.5736 - val_loss: 0.1241 - val_accuracy: 0.9630\n",
            "Epoch 10/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.3037 - accuracy: 0.5759 - val_loss: 0.1192 - val_accuracy: 0.9630\n",
            "Epoch 11/100\n",
            "28/28 [==============================] - 10s 374ms/step - loss: 0.2830 - accuracy: 0.5759 - val_loss: 0.1586 - val_accuracy: 0.9259\n",
            "Epoch 12/100\n",
            "28/28 [==============================] - 11s 375ms/step - loss: 0.2938 - accuracy: 0.5770 - val_loss: 0.1603 - val_accuracy: 0.9630\n",
            "Epoch 13/100\n",
            "28/28 [==============================] - 10s 373ms/step - loss: 0.2891 - accuracy: 0.5770 - val_loss: 0.1457 - val_accuracy: 0.9630\n",
            "Epoch 14/100\n",
            "28/28 [==============================] - 11s 375ms/step - loss: 0.2960 - accuracy: 0.5759 - val_loss: 0.1876 - val_accuracy: 0.9259\n",
            "Epoch 15/100\n",
            "28/28 [==============================] - 10s 375ms/step - loss: 0.2896 - accuracy: 0.5770 - val_loss: 0.1452 - val_accuracy: 0.9630\n",
            "Epoch 16/100\n",
            "28/28 [==============================] - 11s 375ms/step - loss: 0.2844 - accuracy: 0.5770 - val_loss: 0.1326 - val_accuracy: 0.9630\n",
            "Epoch 17/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.2796 - accuracy: 0.5759 - val_loss: 0.1085 - val_accuracy: 0.9630\n",
            "Epoch 18/100\n",
            "28/28 [==============================] - 10s 374ms/step - loss: 0.2815 - accuracy: 0.5770 - val_loss: 0.1283 - val_accuracy: 0.9630\n",
            "Epoch 19/100\n",
            "28/28 [==============================] - 10s 374ms/step - loss: 0.2797 - accuracy: 0.5759 - val_loss: 0.1571 - val_accuracy: 0.9630\n",
            "Epoch 20/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2828 - accuracy: 0.5770 - val_loss: 0.1340 - val_accuracy: 0.9630\n",
            "Epoch 21/100\n",
            "28/28 [==============================] - 11s 375ms/step - loss: 0.2792 - accuracy: 0.5770 - val_loss: 0.1490 - val_accuracy: 0.9259\n",
            "Epoch 22/100\n",
            "28/28 [==============================] - 11s 375ms/step - loss: 0.2706 - accuracy: 0.5770 - val_loss: 0.1404 - val_accuracy: 0.9630\n",
            "Epoch 23/100\n",
            "28/28 [==============================] - 10s 374ms/step - loss: 0.2736 - accuracy: 0.5770 - val_loss: 0.1360 - val_accuracy: 0.9630\n",
            "Epoch 24/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2703 - accuracy: 0.5770 - val_loss: 0.1336 - val_accuracy: 0.9630\n",
            "Epoch 25/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2700 - accuracy: 0.5770 - val_loss: 0.1346 - val_accuracy: 0.9259\n",
            "Epoch 26/100\n",
            "28/28 [==============================] - 10s 375ms/step - loss: 0.2839 - accuracy: 0.5759 - val_loss: 0.1234 - val_accuracy: 0.9259\n",
            "Epoch 27/100\n",
            "28/28 [==============================] - 10s 375ms/step - loss: 0.2769 - accuracy: 0.5770 - val_loss: 0.1095 - val_accuracy: 0.9630\n",
            "Epoch 28/100\n",
            "28/28 [==============================] - 10s 375ms/step - loss: 0.2702 - accuracy: 0.5770 - val_loss: 0.1206 - val_accuracy: 0.9630\n",
            "Epoch 29/100\n",
            "28/28 [==============================] - 10s 375ms/step - loss: 0.2728 - accuracy: 0.5770 - val_loss: 0.1201 - val_accuracy: 0.9630\n",
            "Epoch 30/100\n",
            "28/28 [==============================] - 10s 375ms/step - loss: 0.2649 - accuracy: 0.5770 - val_loss: 0.1377 - val_accuracy: 0.9630\n",
            "Epoch 31/100\n",
            "28/28 [==============================] - 10s 373ms/step - loss: 0.2732 - accuracy: 0.5770 - val_loss: 0.1415 - val_accuracy: 0.9630\n",
            "Epoch 32/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2775 - accuracy: 0.5770 - val_loss: 0.1586 - val_accuracy: 0.9259\n",
            "2/2 [==============================] - 2s 127ms/step - loss: 0.1250 - accuracy: 0.9118\n",
            "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f40400bf200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[0.9588235139846801]\n",
            "[0.9507813140511734]\n",
            "Epoch 1/100\n",
            "28/28 [==============================] - 18s 427ms/step - loss: 0.5265 - accuracy: 0.5011 - val_loss: 0.7114 - val_accuracy: 0.7407\n",
            "Epoch 2/100\n",
            "28/28 [==============================] - 11s 379ms/step - loss: 0.4265 - accuracy: 0.5609 - val_loss: 0.4289 - val_accuracy: 0.7407\n",
            "Epoch 3/100\n",
            "28/28 [==============================] - 11s 379ms/step - loss: 0.3816 - accuracy: 0.5598 - val_loss: 0.2314 - val_accuracy: 0.8889\n",
            "Epoch 4/100\n",
            "28/28 [==============================] - 11s 378ms/step - loss: 0.3550 - accuracy: 0.5805 - val_loss: 0.1830 - val_accuracy: 0.9630\n",
            "Epoch 5/100\n",
            "28/28 [==============================] - 10s 375ms/step - loss: 0.3300 - accuracy: 0.5862 - val_loss: 0.2873 - val_accuracy: 0.8148\n",
            "Epoch 6/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.3142 - accuracy: 0.5920 - val_loss: 0.2162 - val_accuracy: 0.8889\n",
            "Epoch 7/100\n",
            "28/28 [==============================] - 10s 374ms/step - loss: 0.3188 - accuracy: 0.5908 - val_loss: 0.2057 - val_accuracy: 0.8889\n",
            "Epoch 8/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.3142 - accuracy: 0.5920 - val_loss: 0.1396 - val_accuracy: 0.9630\n",
            "Epoch 9/100\n",
            "28/28 [==============================] - 11s 378ms/step - loss: 0.3076 - accuracy: 0.5885 - val_loss: 0.0979 - val_accuracy: 1.0000\n",
            "Epoch 10/100\n",
            "28/28 [==============================] - 10s 374ms/step - loss: 0.3038 - accuracy: 0.5943 - val_loss: 0.1007 - val_accuracy: 1.0000\n",
            "Epoch 11/100\n",
            "28/28 [==============================] - 10s 374ms/step - loss: 0.2862 - accuracy: 0.5954 - val_loss: 0.1278 - val_accuracy: 0.9259\n",
            "Epoch 12/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.2883 - accuracy: 0.5966 - val_loss: 0.0773 - val_accuracy: 1.0000\n",
            "Epoch 13/100\n",
            "28/28 [==============================] - 10s 375ms/step - loss: 0.2916 - accuracy: 0.5931 - val_loss: 0.1113 - val_accuracy: 0.9630\n",
            "Epoch 14/100\n",
            "28/28 [==============================] - 11s 375ms/step - loss: 0.2866 - accuracy: 0.5966 - val_loss: 0.0977 - val_accuracy: 0.9630\n",
            "Epoch 15/100\n",
            "28/28 [==============================] - 10s 375ms/step - loss: 0.2773 - accuracy: 0.5977 - val_loss: 0.1668 - val_accuracy: 0.9259\n",
            "Epoch 16/100\n",
            "28/28 [==============================] - 10s 375ms/step - loss: 0.2653 - accuracy: 0.5977 - val_loss: 0.0812 - val_accuracy: 1.0000\n",
            "Epoch 17/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2734 - accuracy: 0.5977 - val_loss: 0.0858 - val_accuracy: 1.0000\n",
            "Epoch 18/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2764 - accuracy: 0.5977 - val_loss: 0.1027 - val_accuracy: 0.9630\n",
            "Epoch 19/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2731 - accuracy: 0.5977 - val_loss: 0.1269 - val_accuracy: 0.9630\n",
            "Epoch 20/100\n",
            "28/28 [==============================] - 11s 375ms/step - loss: 0.2772 - accuracy: 0.5977 - val_loss: 0.1413 - val_accuracy: 0.8889\n",
            "Epoch 21/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.2680 - accuracy: 0.5977 - val_loss: 0.1916 - val_accuracy: 0.8519\n",
            "Epoch 22/100\n",
            "28/28 [==============================] - 11s 378ms/step - loss: 0.2684 - accuracy: 0.5966 - val_loss: 0.0720 - val_accuracy: 1.0000\n",
            "Epoch 23/100\n",
            "28/28 [==============================] - 11s 375ms/step - loss: 0.2735 - accuracy: 0.5966 - val_loss: 0.1081 - val_accuracy: 0.9630\n",
            "Epoch 24/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.2661 - accuracy: 0.5977 - val_loss: 0.0718 - val_accuracy: 1.0000\n",
            "Epoch 25/100\n",
            "28/28 [==============================] - 10s 373ms/step - loss: 0.2637 - accuracy: 0.5966 - val_loss: 0.0738 - val_accuracy: 1.0000\n",
            "Epoch 26/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2771 - accuracy: 0.5977 - val_loss: 0.1082 - val_accuracy: 0.9630\n",
            "Epoch 27/100\n",
            "28/28 [==============================] - 11s 375ms/step - loss: 0.2735 - accuracy: 0.5954 - val_loss: 0.1378 - val_accuracy: 0.9630\n",
            "Epoch 28/100\n",
            "28/28 [==============================] - 10s 375ms/step - loss: 0.2637 - accuracy: 0.5977 - val_loss: 0.1009 - val_accuracy: 0.9630\n",
            "Epoch 29/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2721 - accuracy: 0.5966 - val_loss: 0.0936 - val_accuracy: 0.9630\n",
            "Epoch 30/100\n",
            "28/28 [==============================] - 11s 375ms/step - loss: 0.2615 - accuracy: 0.5977 - val_loss: 0.2012 - val_accuracy: 0.8519\n",
            "Epoch 31/100\n",
            "28/28 [==============================] - 11s 375ms/step - loss: 0.2713 - accuracy: 0.5966 - val_loss: 0.0733 - val_accuracy: 1.0000\n",
            "Epoch 32/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2630 - accuracy: 0.5977 - val_loss: 0.0647 - val_accuracy: 1.0000\n",
            "Epoch 33/100\n",
            "28/28 [==============================] - 10s 375ms/step - loss: 0.2655 - accuracy: 0.5977 - val_loss: 0.1085 - val_accuracy: 0.9630\n",
            "Epoch 34/100\n",
            "28/28 [==============================] - 10s 375ms/step - loss: 0.2576 - accuracy: 0.5977 - val_loss: 0.2056 - val_accuracy: 0.8519\n",
            "Epoch 35/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2619 - accuracy: 0.5977 - val_loss: 0.1125 - val_accuracy: 1.0000\n",
            "Epoch 36/100\n",
            "28/28 [==============================] - 11s 375ms/step - loss: 0.2659 - accuracy: 0.5954 - val_loss: 0.1015 - val_accuracy: 0.9630\n",
            "Epoch 37/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2608 - accuracy: 0.5977 - val_loss: 0.1166 - val_accuracy: 0.9259\n",
            "Epoch 38/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.2584 - accuracy: 0.5977 - val_loss: 0.0980 - val_accuracy: 1.0000\n",
            "Epoch 39/100\n",
            "28/28 [==============================] - 10s 373ms/step - loss: 0.2535 - accuracy: 0.5977 - val_loss: 0.1129 - val_accuracy: 0.9630\n",
            "Epoch 40/100\n",
            "28/28 [==============================] - 10s 375ms/step - loss: 0.2527 - accuracy: 0.5966 - val_loss: 0.1676 - val_accuracy: 0.9259\n",
            "Epoch 41/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2570 - accuracy: 0.5977 - val_loss: 0.1433 - val_accuracy: 0.9259\n",
            "Epoch 42/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2583 - accuracy: 0.5977 - val_loss: 0.2081 - val_accuracy: 0.8519\n",
            "Epoch 43/100\n",
            "28/28 [==============================] - 11s 375ms/step - loss: 0.2538 - accuracy: 0.5977 - val_loss: 0.1423 - val_accuracy: 0.8889\n",
            "Epoch 44/100\n",
            "28/28 [==============================] - 11s 375ms/step - loss: 0.2537 - accuracy: 0.5977 - val_loss: 0.1966 - val_accuracy: 0.8519\n",
            "Epoch 45/100\n",
            "28/28 [==============================] - 10s 374ms/step - loss: 0.2587 - accuracy: 0.5966 - val_loss: 0.1245 - val_accuracy: 0.9630\n",
            "Epoch 46/100\n",
            "28/28 [==============================] - 10s 375ms/step - loss: 0.2642 - accuracy: 0.5977 - val_loss: 0.1016 - val_accuracy: 0.9630\n",
            "Epoch 47/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.2565 - accuracy: 0.5977 - val_loss: 0.0815 - val_accuracy: 1.0000\n",
            "2/2 [==============================] - 2s 125ms/step - loss: 0.1315 - accuracy: 0.9118\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3fb2e1c320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Epoch 1/100\n",
            "28/28 [==============================] - 18s 429ms/step - loss: 0.5311 - accuracy: 0.5034 - val_loss: 0.7198 - val_accuracy: 0.7037\n",
            "Epoch 2/100\n",
            "28/28 [==============================] - 11s 378ms/step - loss: 0.4020 - accuracy: 0.5552 - val_loss: 0.5585 - val_accuracy: 0.7407\n",
            "Epoch 3/100\n",
            "28/28 [==============================] - 11s 378ms/step - loss: 0.3853 - accuracy: 0.5678 - val_loss: 0.2818 - val_accuracy: 0.8519\n",
            "Epoch 4/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.3472 - accuracy: 0.5839 - val_loss: 0.2498 - val_accuracy: 0.8519\n",
            "Epoch 5/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.3389 - accuracy: 0.5805 - val_loss: 0.1950 - val_accuracy: 0.9630\n",
            "Epoch 6/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.3392 - accuracy: 0.5782 - val_loss: 0.1794 - val_accuracy: 0.9259\n",
            "Epoch 7/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.3266 - accuracy: 0.5862 - val_loss: 0.1512 - val_accuracy: 0.9630\n",
            "Epoch 8/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.3208 - accuracy: 0.5839 - val_loss: 0.1490 - val_accuracy: 0.9630\n",
            "Epoch 9/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.3032 - accuracy: 0.5908 - val_loss: 0.1135 - val_accuracy: 0.9630\n",
            "Epoch 10/100\n",
            "28/28 [==============================] - 11s 378ms/step - loss: 0.3104 - accuracy: 0.5885 - val_loss: 0.1072 - val_accuracy: 0.9630\n",
            "Epoch 11/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.3062 - accuracy: 0.5828 - val_loss: 0.0944 - val_accuracy: 0.9630\n",
            "Epoch 12/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.2912 - accuracy: 0.5920 - val_loss: 0.0799 - val_accuracy: 1.0000\n",
            "Epoch 13/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2851 - accuracy: 0.5931 - val_loss: 0.0754 - val_accuracy: 1.0000\n",
            "Epoch 14/100\n",
            "28/28 [==============================] - 11s 378ms/step - loss: 0.2837 - accuracy: 0.5931 - val_loss: 0.0626 - val_accuracy: 1.0000\n",
            "Epoch 15/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.2830 - accuracy: 0.5908 - val_loss: 0.0720 - val_accuracy: 1.0000\n",
            "Epoch 16/100\n",
            "28/28 [==============================] - 10s 375ms/step - loss: 0.2881 - accuracy: 0.5874 - val_loss: 0.1064 - val_accuracy: 0.9630\n",
            "Epoch 17/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.2864 - accuracy: 0.5920 - val_loss: 0.1232 - val_accuracy: 0.9630\n",
            "Epoch 18/100\n",
            "28/28 [==============================] - 11s 375ms/step - loss: 0.2847 - accuracy: 0.5931 - val_loss: 0.0906 - val_accuracy: 0.9630\n",
            "Epoch 19/100\n",
            "28/28 [==============================] - 11s 375ms/step - loss: 0.2797 - accuracy: 0.5920 - val_loss: 0.0835 - val_accuracy: 0.9630\n",
            "Epoch 20/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2712 - accuracy: 0.5908 - val_loss: 0.1286 - val_accuracy: 0.9630\n",
            "Epoch 21/100\n",
            "28/28 [==============================] - 10s 375ms/step - loss: 0.2767 - accuracy: 0.5931 - val_loss: 0.0629 - val_accuracy: 1.0000\n",
            "Epoch 22/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.2792 - accuracy: 0.5931 - val_loss: 0.0428 - val_accuracy: 1.0000\n",
            "Epoch 23/100\n",
            "28/28 [==============================] - 10s 375ms/step - loss: 0.2753 - accuracy: 0.5908 - val_loss: 0.0763 - val_accuracy: 1.0000\n",
            "Epoch 24/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2722 - accuracy: 0.5931 - val_loss: 0.0526 - val_accuracy: 1.0000\n",
            "Epoch 25/100\n",
            "28/28 [==============================] - 11s 375ms/step - loss: 0.2671 - accuracy: 0.5920 - val_loss: 0.0439 - val_accuracy: 1.0000\n",
            "Epoch 26/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2627 - accuracy: 0.5931 - val_loss: 0.0549 - val_accuracy: 1.0000\n",
            "Epoch 27/100\n",
            "28/28 [==============================] - 10s 374ms/step - loss: 0.2777 - accuracy: 0.5920 - val_loss: 0.2002 - val_accuracy: 0.9259\n",
            "Epoch 28/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2657 - accuracy: 0.5920 - val_loss: 0.0381 - val_accuracy: 1.0000\n",
            "Epoch 29/100\n",
            "28/28 [==============================] - 11s 375ms/step - loss: 0.2644 - accuracy: 0.5931 - val_loss: 0.0462 - val_accuracy: 1.0000\n",
            "Epoch 30/100\n",
            "28/28 [==============================] - 10s 374ms/step - loss: 0.2619 - accuracy: 0.5931 - val_loss: 0.0468 - val_accuracy: 1.0000\n",
            "Epoch 31/100\n",
            "28/28 [==============================] - 10s 375ms/step - loss: 0.2616 - accuracy: 0.5931 - val_loss: 0.0607 - val_accuracy: 1.0000\n",
            "Epoch 32/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2643 - accuracy: 0.5931 - val_loss: 0.0475 - val_accuracy: 1.0000\n",
            "Epoch 33/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2639 - accuracy: 0.5931 - val_loss: 0.0419 - val_accuracy: 1.0000\n",
            "Epoch 34/100\n",
            "28/28 [==============================] - 10s 375ms/step - loss: 0.2629 - accuracy: 0.5931 - val_loss: 0.0524 - val_accuracy: 1.0000\n",
            "Epoch 35/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2615 - accuracy: 0.5920 - val_loss: 0.0450 - val_accuracy: 1.0000\n",
            "Epoch 36/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.2596 - accuracy: 0.5931 - val_loss: 0.0436 - val_accuracy: 1.0000\n",
            "Epoch 37/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.2657 - accuracy: 0.5908 - val_loss: 0.0373 - val_accuracy: 1.0000\n",
            "Epoch 38/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.2690 - accuracy: 0.5931 - val_loss: 0.0566 - val_accuracy: 1.0000\n",
            "Epoch 39/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2664 - accuracy: 0.5920 - val_loss: 0.0433 - val_accuracy: 1.0000\n",
            "Epoch 40/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2586 - accuracy: 0.5931 - val_loss: 0.0728 - val_accuracy: 0.9630\n",
            "Epoch 41/100\n",
            "28/28 [==============================] - 11s 375ms/step - loss: 0.2572 - accuracy: 0.5931 - val_loss: 0.0674 - val_accuracy: 1.0000\n",
            "Epoch 42/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.2676 - accuracy: 0.5931 - val_loss: 0.0635 - val_accuracy: 1.0000\n",
            "Epoch 43/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.2670 - accuracy: 0.5931 - val_loss: 0.1016 - val_accuracy: 0.9630\n",
            "Epoch 44/100\n",
            "28/28 [==============================] - 11s 375ms/step - loss: 0.2630 - accuracy: 0.5931 - val_loss: 0.0449 - val_accuracy: 1.0000\n",
            "Epoch 45/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2577 - accuracy: 0.5931 - val_loss: 0.1169 - val_accuracy: 0.9630\n",
            "Epoch 46/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2521 - accuracy: 0.5931 - val_loss: 0.0730 - val_accuracy: 0.9630\n",
            "Epoch 47/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.2524 - accuracy: 0.5931 - val_loss: 0.1299 - val_accuracy: 0.9259\n",
            "Epoch 48/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2577 - accuracy: 0.5931 - val_loss: 0.0573 - val_accuracy: 1.0000\n",
            "Epoch 49/100\n",
            "28/28 [==============================] - 11s 375ms/step - loss: 0.2564 - accuracy: 0.5931 - val_loss: 0.0445 - val_accuracy: 1.0000\n",
            "Epoch 50/100\n",
            "28/28 [==============================] - 10s 374ms/step - loss: 0.2468 - accuracy: 0.5931 - val_loss: 0.0439 - val_accuracy: 1.0000\n",
            "Epoch 51/100\n",
            "28/28 [==============================] - 10s 375ms/step - loss: 0.2559 - accuracy: 0.5931 - val_loss: 0.0556 - val_accuracy: 1.0000\n",
            "Epoch 52/100\n",
            "28/28 [==============================] - 11s 378ms/step - loss: 0.2534 - accuracy: 0.5931 - val_loss: 0.0437 - val_accuracy: 1.0000\n",
            "2/2 [==============================] - 2s 122ms/step - loss: 0.0320 - accuracy: 1.0000\n",
            "Epoch 1/100\n",
            "27/27 [==============================] - 18s 430ms/step - loss: 0.5088 - accuracy: 0.5120 - val_loss: 0.7027 - val_accuracy: 0.7778\n",
            "Epoch 2/100\n",
            "27/27 [==============================] - 10s 378ms/step - loss: 0.4030 - accuracy: 0.5564 - val_loss: 0.6119 - val_accuracy: 0.7407\n",
            "Epoch 3/100\n",
            "27/27 [==============================] - 10s 376ms/step - loss: 0.3553 - accuracy: 0.5707 - val_loss: 0.3698 - val_accuracy: 0.8148\n",
            "Epoch 4/100\n",
            "27/27 [==============================] - 10s 375ms/step - loss: 0.3394 - accuracy: 0.5839 - val_loss: 0.5964 - val_accuracy: 0.7407\n",
            "Epoch 5/100\n",
            "27/27 [==============================] - 10s 375ms/step - loss: 0.3296 - accuracy: 0.5839 - val_loss: 0.4505 - val_accuracy: 0.7778\n",
            "Epoch 6/100\n",
            "27/27 [==============================] - 10s 376ms/step - loss: 0.3152 - accuracy: 0.5899 - val_loss: 0.2934 - val_accuracy: 0.8519\n",
            "Epoch 7/100\n",
            "27/27 [==============================] - 10s 377ms/step - loss: 0.3275 - accuracy: 0.5731 - val_loss: 0.1970 - val_accuracy: 0.9630\n",
            "Epoch 8/100\n",
            "27/27 [==============================] - 10s 376ms/step - loss: 0.3059 - accuracy: 0.5947 - val_loss: 0.4143 - val_accuracy: 0.8148\n",
            "Epoch 9/100\n",
            "27/27 [==============================] - 10s 375ms/step - loss: 0.3096 - accuracy: 0.5911 - val_loss: 0.4338 - val_accuracy: 0.8148\n",
            "Epoch 10/100\n",
            "27/27 [==============================] - 10s 375ms/step - loss: 0.3119 - accuracy: 0.5887 - val_loss: 0.4786 - val_accuracy: 0.8148\n",
            "Epoch 11/100\n",
            "27/27 [==============================] - 10s 376ms/step - loss: 0.3054 - accuracy: 0.5911 - val_loss: 0.3134 - val_accuracy: 0.8148\n",
            "Epoch 12/100\n",
            "27/27 [==============================] - 10s 375ms/step - loss: 0.3033 - accuracy: 0.5899 - val_loss: 0.2639 - val_accuracy: 0.8148\n",
            "Epoch 13/100\n",
            "27/27 [==============================] - 10s 375ms/step - loss: 0.2913 - accuracy: 0.5911 - val_loss: 0.3982 - val_accuracy: 0.8148\n",
            "Epoch 14/100\n",
            "27/27 [==============================] - 10s 373ms/step - loss: 0.2833 - accuracy: 0.5911 - val_loss: 0.5968 - val_accuracy: 0.8148\n",
            "Epoch 15/100\n",
            "27/27 [==============================] - 10s 375ms/step - loss: 0.2867 - accuracy: 0.5947 - val_loss: 0.5084 - val_accuracy: 0.8148\n",
            "Epoch 16/100\n",
            "27/27 [==============================] - 10s 375ms/step - loss: 0.2838 - accuracy: 0.5923 - val_loss: 0.5014 - val_accuracy: 0.8148\n",
            "Epoch 17/100\n",
            "27/27 [==============================] - 10s 378ms/step - loss: 0.2966 - accuracy: 0.5899 - val_loss: 0.1860 - val_accuracy: 0.8889\n",
            "Epoch 18/100\n",
            "27/27 [==============================] - 10s 376ms/step - loss: 0.2846 - accuracy: 0.5947 - val_loss: 0.1627 - val_accuracy: 0.9630\n",
            "Epoch 19/100\n",
            "27/27 [==============================] - 10s 373ms/step - loss: 0.2904 - accuracy: 0.5923 - val_loss: 0.2990 - val_accuracy: 0.8519\n",
            "Epoch 20/100\n",
            "27/27 [==============================] - 10s 375ms/step - loss: 0.2765 - accuracy: 0.5923 - val_loss: 0.2849 - val_accuracy: 0.8889\n",
            "Epoch 21/100\n",
            "27/27 [==============================] - 10s 375ms/step - loss: 0.2743 - accuracy: 0.5947 - val_loss: 0.2059 - val_accuracy: 0.9259\n",
            "Epoch 22/100\n",
            "27/27 [==============================] - 10s 376ms/step - loss: 0.2858 - accuracy: 0.5923 - val_loss: 0.2394 - val_accuracy: 0.8889\n",
            "Epoch 23/100\n",
            "27/27 [==============================] - 10s 375ms/step - loss: 0.2761 - accuracy: 0.5911 - val_loss: 0.2549 - val_accuracy: 0.9259\n",
            "Epoch 24/100\n",
            "27/27 [==============================] - 10s 374ms/step - loss: 0.2718 - accuracy: 0.5935 - val_loss: 0.2461 - val_accuracy: 0.8889\n",
            "Epoch 25/100\n",
            "27/27 [==============================] - 10s 375ms/step - loss: 0.2764 - accuracy: 0.5935 - val_loss: 0.2070 - val_accuracy: 0.9259\n",
            "Epoch 26/100\n",
            "27/27 [==============================] - 10s 376ms/step - loss: 0.2821 - accuracy: 0.5935 - val_loss: 0.2357 - val_accuracy: 0.9259\n",
            "Epoch 27/100\n",
            "27/27 [==============================] - 10s 375ms/step - loss: 0.2760 - accuracy: 0.5935 - val_loss: 0.4182 - val_accuracy: 0.8148\n",
            "Epoch 28/100\n",
            "27/27 [==============================] - 10s 373ms/step - loss: 0.2741 - accuracy: 0.5947 - val_loss: 0.5598 - val_accuracy: 0.8148\n",
            "Epoch 29/100\n",
            "27/27 [==============================] - 10s 376ms/step - loss: 0.2721 - accuracy: 0.5947 - val_loss: 0.4132 - val_accuracy: 0.8148\n",
            "Epoch 30/100\n",
            "27/27 [==============================] - 10s 376ms/step - loss: 0.2702 - accuracy: 0.5935 - val_loss: 0.3646 - val_accuracy: 0.8148\n",
            "Epoch 31/100\n",
            "27/27 [==============================] - 10s 375ms/step - loss: 0.2709 - accuracy: 0.5947 - val_loss: 0.4223 - val_accuracy: 0.8148\n",
            "Epoch 32/100\n",
            "27/27 [==============================] - 10s 376ms/step - loss: 0.2716 - accuracy: 0.5947 - val_loss: 0.3374 - val_accuracy: 0.8519\n",
            "Epoch 33/100\n",
            "27/27 [==============================] - 10s 376ms/step - loss: 0.2780 - accuracy: 0.5935 - val_loss: 0.3296 - val_accuracy: 0.8148\n",
            "2/2 [==============================] - 2s 122ms/step - loss: 0.2085 - accuracy: 0.9118\n",
            "Epoch 1/100\n",
            "28/28 [==============================] - 18s 427ms/step - loss: 0.4876 - accuracy: 0.5181 - val_loss: 0.1807 - val_accuracy: 0.9259\n",
            "Epoch 2/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.4061 - accuracy: 0.5567 - val_loss: 0.1758 - val_accuracy: 0.8889\n",
            "Epoch 3/100\n",
            "28/28 [==============================] - 11s 379ms/step - loss: 0.3832 - accuracy: 0.5635 - val_loss: 0.1351 - val_accuracy: 0.9630\n",
            "Epoch 4/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.3532 - accuracy: 0.5726 - val_loss: 0.1628 - val_accuracy: 0.8889\n",
            "Epoch 5/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.3460 - accuracy: 0.5782 - val_loss: 0.1409 - val_accuracy: 0.9259\n",
            "Epoch 6/100\n",
            "28/28 [==============================] - 11s 379ms/step - loss: 0.3426 - accuracy: 0.5726 - val_loss: 0.1254 - val_accuracy: 1.0000\n",
            "Epoch 7/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.3194 - accuracy: 0.5794 - val_loss: 0.0851 - val_accuracy: 1.0000\n",
            "Epoch 8/100\n",
            "28/28 [==============================] - 11s 378ms/step - loss: 0.3144 - accuracy: 0.5805 - val_loss: 0.0832 - val_accuracy: 1.0000\n",
            "Epoch 9/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.3075 - accuracy: 0.5873 - val_loss: 0.1041 - val_accuracy: 0.9630\n",
            "Epoch 10/100\n",
            "28/28 [==============================] - 11s 378ms/step - loss: 0.3025 - accuracy: 0.5873 - val_loss: 0.0765 - val_accuracy: 1.0000\n",
            "Epoch 11/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.3025 - accuracy: 0.5873 - val_loss: 0.0803 - val_accuracy: 1.0000\n",
            "Epoch 12/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.2823 - accuracy: 0.5896 - val_loss: 0.0708 - val_accuracy: 1.0000\n",
            "Epoch 13/100\n",
            "28/28 [==============================] - 11s 378ms/step - loss: 0.2825 - accuracy: 0.5884 - val_loss: 0.0760 - val_accuracy: 1.0000\n",
            "Epoch 14/100\n",
            "28/28 [==============================] - 11s 378ms/step - loss: 0.2794 - accuracy: 0.5896 - val_loss: 0.0607 - val_accuracy: 1.0000\n",
            "Epoch 15/100\n",
            "28/28 [==============================] - 11s 379ms/step - loss: 0.2850 - accuracy: 0.5884 - val_loss: 0.0487 - val_accuracy: 1.0000\n",
            "Epoch 16/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.2762 - accuracy: 0.5896 - val_loss: 0.0832 - val_accuracy: 0.9630\n",
            "Epoch 17/100\n",
            "28/28 [==============================] - 11s 375ms/step - loss: 0.2740 - accuracy: 0.5884 - val_loss: 0.0518 - val_accuracy: 1.0000\n",
            "Epoch 18/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2775 - accuracy: 0.5896 - val_loss: 0.0975 - val_accuracy: 0.9630\n",
            "Epoch 19/100\n",
            "28/28 [==============================] - 11s 378ms/step - loss: 0.2712 - accuracy: 0.5884 - val_loss: 0.0917 - val_accuracy: 0.9630\n",
            "Epoch 20/100\n",
            "28/28 [==============================] - 11s 378ms/step - loss: 0.2812 - accuracy: 0.5896 - val_loss: 0.0492 - val_accuracy: 1.0000\n",
            "Epoch 21/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.2760 - accuracy: 0.5884 - val_loss: 0.0721 - val_accuracy: 1.0000\n",
            "Epoch 22/100\n",
            "28/28 [==============================] - 11s 378ms/step - loss: 0.2678 - accuracy: 0.5896 - val_loss: 0.0333 - val_accuracy: 1.0000\n",
            "Epoch 23/100\n",
            "28/28 [==============================] - 10s 374ms/step - loss: 0.2755 - accuracy: 0.5896 - val_loss: 0.0693 - val_accuracy: 1.0000\n",
            "Epoch 24/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.2689 - accuracy: 0.5873 - val_loss: 0.0726 - val_accuracy: 0.9630\n",
            "Epoch 25/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.2656 - accuracy: 0.5896 - val_loss: 0.0565 - val_accuracy: 1.0000\n",
            "Epoch 26/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.2763 - accuracy: 0.5884 - val_loss: 0.0567 - val_accuracy: 1.0000\n",
            "Epoch 27/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.2691 - accuracy: 0.5896 - val_loss: 0.0729 - val_accuracy: 0.9630\n",
            "Epoch 28/100\n",
            "28/28 [==============================] - 11s 379ms/step - loss: 0.2635 - accuracy: 0.5884 - val_loss: 0.0706 - val_accuracy: 0.9630\n",
            "Epoch 29/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2665 - accuracy: 0.5873 - val_loss: 0.0899 - val_accuracy: 0.9630\n",
            "Epoch 30/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2628 - accuracy: 0.5896 - val_loss: 0.0700 - val_accuracy: 0.9630\n",
            "Epoch 31/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2657 - accuracy: 0.5896 - val_loss: 0.0633 - val_accuracy: 1.0000\n",
            "Epoch 32/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2670 - accuracy: 0.5896 - val_loss: 0.0630 - val_accuracy: 1.0000\n",
            "Epoch 33/100\n",
            "28/28 [==============================] - 11s 375ms/step - loss: 0.2672 - accuracy: 0.5896 - val_loss: 0.0617 - val_accuracy: 1.0000\n",
            "Epoch 34/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.2653 - accuracy: 0.5896 - val_loss: 0.0443 - val_accuracy: 1.0000\n",
            "Epoch 35/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.2649 - accuracy: 0.5896 - val_loss: 0.0512 - val_accuracy: 1.0000\n",
            "Epoch 36/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.2570 - accuracy: 0.5896 - val_loss: 0.0588 - val_accuracy: 1.0000\n",
            "Epoch 37/100\n",
            "28/28 [==============================] - 11s 378ms/step - loss: 0.2606 - accuracy: 0.5896 - val_loss: 0.0707 - val_accuracy: 1.0000\n",
            "2/2 [==============================] - 2s 119ms/step - loss: 0.1302 - accuracy: 0.9706\n",
            "Epoch 1/100\n",
            "26/26 [==============================] - 17s 436ms/step - loss: 0.5173 - accuracy: 0.5145 - val_loss: 0.4772 - val_accuracy: 0.8519\n",
            "Epoch 2/100\n",
            "26/26 [==============================] - 10s 379ms/step - loss: 0.3993 - accuracy: 0.5592 - val_loss: 0.7429 - val_accuracy: 0.7407\n",
            "Epoch 3/100\n",
            "26/26 [==============================] - 10s 381ms/step - loss: 0.3680 - accuracy: 0.5676 - val_loss: 0.2133 - val_accuracy: 0.8889\n",
            "Epoch 4/100\n",
            "26/26 [==============================] - 10s 381ms/step - loss: 0.3472 - accuracy: 0.5785 - val_loss: 0.2055 - val_accuracy: 0.9259\n",
            "Epoch 5/100\n",
            "26/26 [==============================] - 10s 378ms/step - loss: 0.3286 - accuracy: 0.5845 - val_loss: 0.2328 - val_accuracy: 0.8889\n",
            "Epoch 6/100\n",
            "26/26 [==============================] - 10s 377ms/step - loss: 0.3291 - accuracy: 0.5833 - val_loss: 0.3685 - val_accuracy: 0.7778\n",
            "Epoch 7/100\n",
            "26/26 [==============================] - 10s 378ms/step - loss: 0.3215 - accuracy: 0.5833 - val_loss: 0.2196 - val_accuracy: 0.8519\n",
            "Epoch 8/100\n",
            "26/26 [==============================] - 10s 377ms/step - loss: 0.2922 - accuracy: 0.5906 - val_loss: 0.3053 - val_accuracy: 0.7778\n",
            "Epoch 9/100\n",
            "26/26 [==============================] - 10s 379ms/step - loss: 0.3004 - accuracy: 0.5882 - val_loss: 0.5203 - val_accuracy: 0.7778\n",
            "Epoch 10/100\n",
            "26/26 [==============================] - 10s 378ms/step - loss: 0.2894 - accuracy: 0.5918 - val_loss: 0.2255 - val_accuracy: 0.9259\n",
            "Epoch 11/100\n",
            "26/26 [==============================] - 10s 379ms/step - loss: 0.2951 - accuracy: 0.5918 - val_loss: 0.2933 - val_accuracy: 0.8148\n",
            "Epoch 12/100\n",
            "26/26 [==============================] - 10s 381ms/step - loss: 0.2819 - accuracy: 0.5918 - val_loss: 0.2034 - val_accuracy: 0.9259\n",
            "Epoch 13/100\n",
            "26/26 [==============================] - 10s 381ms/step - loss: 0.2835 - accuracy: 0.5906 - val_loss: 0.1572 - val_accuracy: 0.9259\n",
            "Epoch 14/100\n",
            "26/26 [==============================] - 10s 377ms/step - loss: 0.2809 - accuracy: 0.5906 - val_loss: 0.2359 - val_accuracy: 0.8519\n",
            "Epoch 15/100\n",
            "26/26 [==============================] - 10s 379ms/step - loss: 0.2745 - accuracy: 0.5906 - val_loss: 0.1920 - val_accuracy: 0.9259\n",
            "Epoch 16/100\n",
            "26/26 [==============================] - 10s 378ms/step - loss: 0.2804 - accuracy: 0.5894 - val_loss: 0.1926 - val_accuracy: 0.8889\n",
            "Epoch 17/100\n",
            "26/26 [==============================] - 10s 380ms/step - loss: 0.2714 - accuracy: 0.5918 - val_loss: 0.2161 - val_accuracy: 0.8519\n",
            "Epoch 18/100\n",
            "26/26 [==============================] - 10s 379ms/step - loss: 0.2723 - accuracy: 0.5918 - val_loss: 0.1725 - val_accuracy: 0.8889\n",
            "Epoch 19/100\n",
            "26/26 [==============================] - 10s 378ms/step - loss: 0.2643 - accuracy: 0.5918 - val_loss: 0.4200 - val_accuracy: 0.7778\n",
            "Epoch 20/100\n",
            "26/26 [==============================] - 10s 381ms/step - loss: 0.2631 - accuracy: 0.5918 - val_loss: 0.3243 - val_accuracy: 0.8519\n",
            "Epoch 21/100\n",
            "26/26 [==============================] - 10s 378ms/step - loss: 0.2665 - accuracy: 0.5918 - val_loss: 0.3310 - val_accuracy: 0.8519\n",
            "Epoch 22/100\n",
            "26/26 [==============================] - 10s 379ms/step - loss: 0.2574 - accuracy: 0.5918 - val_loss: 0.3436 - val_accuracy: 0.8519\n",
            "Epoch 23/100\n",
            "26/26 [==============================] - 10s 378ms/step - loss: 0.2604 - accuracy: 0.5918 - val_loss: 0.2748 - val_accuracy: 0.8519\n",
            "Epoch 24/100\n",
            "26/26 [==============================] - 10s 378ms/step - loss: 0.2646 - accuracy: 0.5918 - val_loss: 0.3000 - val_accuracy: 0.8519\n",
            "Epoch 25/100\n",
            "26/26 [==============================] - 10s 378ms/step - loss: 0.2618 - accuracy: 0.5906 - val_loss: 0.5116 - val_accuracy: 0.8148\n",
            "Epoch 26/100\n",
            "26/26 [==============================] - 10s 379ms/step - loss: 0.2682 - accuracy: 0.5918 - val_loss: 0.4213 - val_accuracy: 0.8519\n",
            "Epoch 27/100\n",
            "26/26 [==============================] - 10s 380ms/step - loss: 0.2718 - accuracy: 0.5906 - val_loss: 0.2723 - val_accuracy: 0.8519\n",
            "Epoch 28/100\n",
            "26/26 [==============================] - 10s 380ms/step - loss: 0.2592 - accuracy: 0.5918 - val_loss: 0.3266 - val_accuracy: 0.8519\n",
            "2/2 [==============================] - 2s 121ms/step - loss: 0.1805 - accuracy: 0.9412\n",
            "[0.9588235139846801, 0.9470588088035583]\n",
            "[0.9507813140511734, 0.9385649310603057]\n",
            "Epoch 1/100\n",
            "27/27 [==============================] - 18s 434ms/step - loss: 0.5169 - accuracy: 0.5047 - val_loss: 1.8897 - val_accuracy: 0.5926\n",
            "Epoch 2/100\n",
            "27/27 [==============================] - 10s 378ms/step - loss: 0.3768 - accuracy: 0.5622 - val_loss: 0.5837 - val_accuracy: 0.7407\n",
            "Epoch 3/100\n",
            "27/27 [==============================] - 10s 377ms/step - loss: 0.3590 - accuracy: 0.5622 - val_loss: 0.6207 - val_accuracy: 0.7407\n",
            "Epoch 4/100\n",
            "27/27 [==============================] - 10s 379ms/step - loss: 0.3538 - accuracy: 0.5657 - val_loss: 0.3801 - val_accuracy: 0.8148\n",
            "Epoch 5/100\n",
            "27/27 [==============================] - 10s 381ms/step - loss: 0.3379 - accuracy: 0.5739 - val_loss: 0.2626 - val_accuracy: 0.8889\n",
            "Epoch 6/100\n",
            "27/27 [==============================] - 10s 379ms/step - loss: 0.3175 - accuracy: 0.5822 - val_loss: 0.2842 - val_accuracy: 0.8889\n",
            "Epoch 7/100\n",
            "27/27 [==============================] - 10s 378ms/step - loss: 0.3175 - accuracy: 0.5786 - val_loss: 0.3283 - val_accuracy: 0.8889\n",
            "Epoch 8/100\n",
            "27/27 [==============================] - 10s 379ms/step - loss: 0.3066 - accuracy: 0.5798 - val_loss: 0.2729 - val_accuracy: 0.9259\n",
            "Epoch 9/100\n",
            "27/27 [==============================] - 10s 378ms/step - loss: 0.3034 - accuracy: 0.5810 - val_loss: 0.2758 - val_accuracy: 0.9259\n",
            "Epoch 10/100\n",
            "27/27 [==============================] - 10s 377ms/step - loss: 0.2972 - accuracy: 0.5798 - val_loss: 0.3182 - val_accuracy: 0.8889\n",
            "Epoch 11/100\n",
            "27/27 [==============================] - 10s 380ms/step - loss: 0.2955 - accuracy: 0.5786 - val_loss: 0.1965 - val_accuracy: 0.9259\n",
            "Epoch 12/100\n",
            "27/27 [==============================] - 10s 379ms/step - loss: 0.3038 - accuracy: 0.5786 - val_loss: 0.1673 - val_accuracy: 0.9259\n",
            "Epoch 13/100\n",
            "27/27 [==============================] - 10s 378ms/step - loss: 0.2907 - accuracy: 0.5822 - val_loss: 0.1699 - val_accuracy: 0.9630\n",
            "Epoch 14/100\n",
            "27/27 [==============================] - 10s 377ms/step - loss: 0.2860 - accuracy: 0.5810 - val_loss: 0.2145 - val_accuracy: 0.9259\n",
            "Epoch 15/100\n",
            "27/27 [==============================] - 10s 377ms/step - loss: 0.2867 - accuracy: 0.5786 - val_loss: 0.1909 - val_accuracy: 0.8889\n",
            "Epoch 16/100\n",
            "27/27 [==============================] - 10s 380ms/step - loss: 0.2826 - accuracy: 0.5810 - val_loss: 0.1499 - val_accuracy: 0.9630\n",
            "Epoch 17/100\n",
            "27/27 [==============================] - 10s 377ms/step - loss: 0.2801 - accuracy: 0.5822 - val_loss: 0.1579 - val_accuracy: 0.9259\n",
            "Epoch 18/100\n",
            "27/27 [==============================] - 10s 380ms/step - loss: 0.2684 - accuracy: 0.5822 - val_loss: 0.1395 - val_accuracy: 0.9630\n",
            "Epoch 19/100\n",
            "27/27 [==============================] - 10s 378ms/step - loss: 0.2776 - accuracy: 0.5822 - val_loss: 0.1961 - val_accuracy: 0.9259\n",
            "Epoch 20/100\n",
            "27/27 [==============================] - 10s 377ms/step - loss: 0.2700 - accuracy: 0.5822 - val_loss: 0.1987 - val_accuracy: 0.9259\n",
            "Epoch 21/100\n",
            "27/27 [==============================] - 10s 378ms/step - loss: 0.2735 - accuracy: 0.5822 - val_loss: 0.1913 - val_accuracy: 0.9259\n",
            "Epoch 22/100\n",
            "27/27 [==============================] - 10s 377ms/step - loss: 0.2710 - accuracy: 0.5822 - val_loss: 0.1724 - val_accuracy: 0.9259\n",
            "Epoch 23/100\n",
            "27/27 [==============================] - 10s 377ms/step - loss: 0.2735 - accuracy: 0.5822 - val_loss: 0.1895 - val_accuracy: 0.9259\n",
            "Epoch 24/100\n",
            "27/27 [==============================] - 10s 378ms/step - loss: 0.2748 - accuracy: 0.5822 - val_loss: 0.1549 - val_accuracy: 0.9259\n",
            "Epoch 25/100\n",
            "27/27 [==============================] - 10s 378ms/step - loss: 0.2688 - accuracy: 0.5822 - val_loss: 0.1272 - val_accuracy: 0.9630\n",
            "Epoch 26/100\n",
            "27/27 [==============================] - 10s 377ms/step - loss: 0.2728 - accuracy: 0.5822 - val_loss: 0.1994 - val_accuracy: 0.9259\n",
            "Epoch 27/100\n",
            "27/27 [==============================] - 10s 376ms/step - loss: 0.2702 - accuracy: 0.5822 - val_loss: 0.2141 - val_accuracy: 0.9259\n",
            "Epoch 28/100\n",
            "27/27 [==============================] - 10s 377ms/step - loss: 0.2665 - accuracy: 0.5822 - val_loss: 0.1755 - val_accuracy: 0.9259\n",
            "Epoch 29/100\n",
            "27/27 [==============================] - 10s 377ms/step - loss: 0.2669 - accuracy: 0.5822 - val_loss: 0.1894 - val_accuracy: 0.9259\n",
            "Epoch 30/100\n",
            "27/27 [==============================] - 10s 380ms/step - loss: 0.2695 - accuracy: 0.5810 - val_loss: 0.1500 - val_accuracy: 0.9259\n",
            "Epoch 31/100\n",
            "27/27 [==============================] - 10s 377ms/step - loss: 0.2675 - accuracy: 0.5822 - val_loss: 0.1635 - val_accuracy: 0.9259\n",
            "Epoch 32/100\n",
            "27/27 [==============================] - 10s 377ms/step - loss: 0.2660 - accuracy: 0.5822 - val_loss: 0.1660 - val_accuracy: 0.9259\n",
            "Epoch 33/100\n",
            "27/27 [==============================] - 10s 377ms/step - loss: 0.2596 - accuracy: 0.5822 - val_loss: 0.1844 - val_accuracy: 0.9259\n",
            "Epoch 34/100\n",
            "27/27 [==============================] - 10s 377ms/step - loss: 0.2631 - accuracy: 0.5822 - val_loss: 0.1280 - val_accuracy: 0.9630\n",
            "Epoch 35/100\n",
            "27/27 [==============================] - 10s 378ms/step - loss: 0.2714 - accuracy: 0.5822 - val_loss: 0.2021 - val_accuracy: 0.9259\n",
            "Epoch 36/100\n",
            "27/27 [==============================] - 10s 378ms/step - loss: 0.2638 - accuracy: 0.5822 - val_loss: 0.2164 - val_accuracy: 0.9259\n",
            "Epoch 37/100\n",
            "27/27 [==============================] - 10s 378ms/step - loss: 0.2620 - accuracy: 0.5822 - val_loss: 0.1426 - val_accuracy: 0.9630\n",
            "Epoch 38/100\n",
            "27/27 [==============================] - 10s 377ms/step - loss: 0.2614 - accuracy: 0.5822 - val_loss: 0.1741 - val_accuracy: 0.9259\n",
            "Epoch 39/100\n",
            "27/27 [==============================] - 10s 378ms/step - loss: 0.2514 - accuracy: 0.5822 - val_loss: 0.2161 - val_accuracy: 0.9259\n",
            "Epoch 40/100\n",
            "27/27 [==============================] - 10s 378ms/step - loss: 0.2597 - accuracy: 0.5822 - val_loss: 0.1517 - val_accuracy: 0.9630\n",
            "2/2 [==============================] - 2s 123ms/step - loss: 0.1779 - accuracy: 0.9412\n",
            "Epoch 1/100\n",
            "27/27 [==============================] - 17s 451ms/step - loss: 0.5680 - accuracy: 0.4757 - val_loss: 0.2955 - val_accuracy: 0.9259\n",
            "Epoch 2/100\n",
            "27/27 [==============================] - 10s 383ms/step - loss: 0.4483 - accuracy: 0.5347 - val_loss: 0.2262 - val_accuracy: 0.9259\n",
            "Epoch 3/100\n",
            "27/27 [==============================] - 10s 383ms/step - loss: 0.3888 - accuracy: 0.5475 - val_loss: 0.2398 - val_accuracy: 0.9259\n",
            "Epoch 4/100\n",
            "27/27 [==============================] - 10s 386ms/step - loss: 0.3518 - accuracy: 0.5567 - val_loss: 0.2102 - val_accuracy: 0.9259\n",
            "Epoch 5/100\n",
            "27/27 [==============================] - 10s 383ms/step - loss: 0.3459 - accuracy: 0.5637 - val_loss: 0.2954 - val_accuracy: 0.8519\n",
            "Epoch 6/100\n",
            "27/27 [==============================] - 10s 385ms/step - loss: 0.3418 - accuracy: 0.5625 - val_loss: 0.1868 - val_accuracy: 0.9259\n",
            "Epoch 7/100\n",
            "27/27 [==============================] - 10s 382ms/step - loss: 0.3150 - accuracy: 0.5660 - val_loss: 0.1870 - val_accuracy: 0.9259\n",
            "Epoch 8/100\n",
            "27/27 [==============================] - 10s 384ms/step - loss: 0.3076 - accuracy: 0.5718 - val_loss: 0.1451 - val_accuracy: 0.9630\n",
            "Epoch 9/100\n",
            "27/27 [==============================] - 10s 386ms/step - loss: 0.3226 - accuracy: 0.5637 - val_loss: 0.1437 - val_accuracy: 0.9630\n",
            "Epoch 10/100\n",
            "27/27 [==============================] - 10s 382ms/step - loss: 0.3103 - accuracy: 0.5694 - val_loss: 0.2123 - val_accuracy: 0.8889\n",
            "Epoch 11/100\n",
            "27/27 [==============================] - 10s 382ms/step - loss: 0.3006 - accuracy: 0.5694 - val_loss: 0.1490 - val_accuracy: 0.9630\n",
            "Epoch 12/100\n",
            "27/27 [==============================] - 10s 384ms/step - loss: 0.3156 - accuracy: 0.5694 - val_loss: 0.1192 - val_accuracy: 1.0000\n",
            "Epoch 13/100\n",
            "27/27 [==============================] - 10s 383ms/step - loss: 0.2993 - accuracy: 0.5706 - val_loss: 0.2258 - val_accuracy: 0.8519\n",
            "Epoch 14/100\n",
            "27/27 [==============================] - 10s 383ms/step - loss: 0.2915 - accuracy: 0.5706 - val_loss: 0.1538 - val_accuracy: 0.8889\n",
            "Epoch 15/100\n",
            "27/27 [==============================] - 10s 382ms/step - loss: 0.2887 - accuracy: 0.5718 - val_loss: 0.1339 - val_accuracy: 0.9630\n",
            "Epoch 16/100\n",
            "27/27 [==============================] - 10s 385ms/step - loss: 0.2954 - accuracy: 0.5694 - val_loss: 0.1966 - val_accuracy: 0.8889\n",
            "Epoch 17/100\n",
            "27/27 [==============================] - 10s 385ms/step - loss: 0.2824 - accuracy: 0.5718 - val_loss: 0.1163 - val_accuracy: 0.9630\n",
            "Epoch 18/100\n",
            "27/27 [==============================] - 10s 383ms/step - loss: 0.2892 - accuracy: 0.5718 - val_loss: 0.1269 - val_accuracy: 0.9630\n",
            "Epoch 19/100\n",
            "27/27 [==============================] - 10s 383ms/step - loss: 0.2853 - accuracy: 0.5718 - val_loss: 0.1053 - val_accuracy: 1.0000\n",
            "Epoch 20/100\n",
            "27/27 [==============================] - 10s 384ms/step - loss: 0.2934 - accuracy: 0.5706 - val_loss: 0.1965 - val_accuracy: 0.8889\n",
            "Epoch 21/100\n",
            "27/27 [==============================] - 10s 383ms/step - loss: 0.2823 - accuracy: 0.5718 - val_loss: 0.1187 - val_accuracy: 1.0000\n",
            "Epoch 22/100\n",
            "27/27 [==============================] - 10s 381ms/step - loss: 0.2803 - accuracy: 0.5718 - val_loss: 0.1426 - val_accuracy: 0.9630\n",
            "Epoch 23/100\n",
            "27/27 [==============================] - 10s 383ms/step - loss: 0.2702 - accuracy: 0.5718 - val_loss: 0.1914 - val_accuracy: 0.9630\n",
            "Epoch 24/100\n",
            "27/27 [==============================] - 10s 379ms/step - loss: 0.2715 - accuracy: 0.5718 - val_loss: 0.1602 - val_accuracy: 0.9259\n",
            "Epoch 25/100\n",
            "27/27 [==============================] - 10s 380ms/step - loss: 0.2799 - accuracy: 0.5718 - val_loss: 0.1366 - val_accuracy: 0.9259\n",
            "Epoch 26/100\n",
            "27/27 [==============================] - 10s 384ms/step - loss: 0.2766 - accuracy: 0.5718 - val_loss: 0.1218 - val_accuracy: 0.9630\n",
            "Epoch 27/100\n",
            "27/27 [==============================] - 10s 382ms/step - loss: 0.2712 - accuracy: 0.5706 - val_loss: 0.1237 - val_accuracy: 1.0000\n",
            "Epoch 28/100\n",
            "27/27 [==============================] - 10s 384ms/step - loss: 0.2744 - accuracy: 0.5718 - val_loss: 0.1223 - val_accuracy: 0.9630\n",
            "Epoch 29/100\n",
            "27/27 [==============================] - 10s 382ms/step - loss: 0.2701 - accuracy: 0.5718 - val_loss: 0.1266 - val_accuracy: 0.9630\n",
            "Epoch 30/100\n",
            "27/27 [==============================] - 10s 381ms/step - loss: 0.2698 - accuracy: 0.5718 - val_loss: 0.1273 - val_accuracy: 1.0000\n",
            "Epoch 31/100\n",
            "27/27 [==============================] - 10s 384ms/step - loss: 0.2703 - accuracy: 0.5718 - val_loss: 0.1323 - val_accuracy: 0.9630\n",
            "Epoch 32/100\n",
            "27/27 [==============================] - 10s 381ms/step - loss: 0.2671 - accuracy: 0.5706 - val_loss: 0.1434 - val_accuracy: 0.9630\n",
            "Epoch 33/100\n",
            "27/27 [==============================] - 10s 383ms/step - loss: 0.2685 - accuracy: 0.5718 - val_loss: 0.1302 - val_accuracy: 0.9630\n",
            "Epoch 34/100\n",
            "27/27 [==============================] - 10s 386ms/step - loss: 0.2730 - accuracy: 0.5718 - val_loss: 0.1037 - val_accuracy: 1.0000\n",
            "Epoch 35/100\n",
            "27/27 [==============================] - 10s 382ms/step - loss: 0.2664 - accuracy: 0.5718 - val_loss: 0.1617 - val_accuracy: 0.9630\n",
            "Epoch 36/100\n",
            "27/27 [==============================] - 10s 382ms/step - loss: 0.2647 - accuracy: 0.5718 - val_loss: 0.1110 - val_accuracy: 0.9630\n",
            "Epoch 37/100\n",
            "27/27 [==============================] - 10s 381ms/step - loss: 0.2646 - accuracy: 0.5718 - val_loss: 0.1363 - val_accuracy: 1.0000\n",
            "Epoch 38/100\n",
            "27/27 [==============================] - 10s 383ms/step - loss: 0.2682 - accuracy: 0.5706 - val_loss: 0.1458 - val_accuracy: 0.9630\n",
            "Epoch 39/100\n",
            "27/27 [==============================] - 10s 383ms/step - loss: 0.2686 - accuracy: 0.5718 - val_loss: 0.1397 - val_accuracy: 0.9630\n",
            "Epoch 40/100\n",
            "27/27 [==============================] - 10s 385ms/step - loss: 0.2657 - accuracy: 0.5718 - val_loss: 0.1631 - val_accuracy: 0.9630\n",
            "Epoch 41/100\n",
            "27/27 [==============================] - 10s 382ms/step - loss: 0.2716 - accuracy: 0.5718 - val_loss: 0.1862 - val_accuracy: 0.9259\n",
            "Epoch 42/100\n",
            "27/27 [==============================] - 10s 384ms/step - loss: 0.2677 - accuracy: 0.5706 - val_loss: 0.1546 - val_accuracy: 0.9630\n",
            "Epoch 43/100\n",
            "27/27 [==============================] - 10s 382ms/step - loss: 0.2720 - accuracy: 0.5718 - val_loss: 0.1703 - val_accuracy: 0.9630\n",
            "Epoch 44/100\n",
            "27/27 [==============================] - 10s 383ms/step - loss: 0.2567 - accuracy: 0.5718 - val_loss: 0.1488 - val_accuracy: 0.9630\n",
            "Epoch 45/100\n",
            "27/27 [==============================] - 10s 384ms/step - loss: 0.2647 - accuracy: 0.5718 - val_loss: 0.1751 - val_accuracy: 0.9630\n",
            "Epoch 46/100\n",
            "27/27 [==============================] - 10s 382ms/step - loss: 0.2613 - accuracy: 0.5718 - val_loss: 0.1439 - val_accuracy: 0.9630\n",
            "Epoch 47/100\n",
            "27/27 [==============================] - 10s 381ms/step - loss: 0.2639 - accuracy: 0.5706 - val_loss: 0.1311 - val_accuracy: 0.9630\n",
            "Epoch 48/100\n",
            "27/27 [==============================] - 10s 382ms/step - loss: 0.2582 - accuracy: 0.5718 - val_loss: 0.1485 - val_accuracy: 0.9630\n",
            "Epoch 49/100\n",
            "27/27 [==============================] - 10s 385ms/step - loss: 0.2597 - accuracy: 0.5718 - val_loss: 0.1664 - val_accuracy: 0.9259\n",
            "2/2 [==============================] - 2s 123ms/step - loss: 0.1005 - accuracy: 1.0000\n",
            "Epoch 1/100\n",
            "28/28 [==============================] - 18s 426ms/step - loss: 0.5421 - accuracy: 0.4840 - val_loss: 0.1169 - val_accuracy: 1.0000\n",
            "Epoch 2/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.4050 - accuracy: 0.5445 - val_loss: 0.1366 - val_accuracy: 0.9630\n",
            "Epoch 3/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.3607 - accuracy: 0.5582 - val_loss: 0.1253 - val_accuracy: 1.0000\n",
            "Epoch 4/100\n",
            "28/28 [==============================] - 11s 378ms/step - loss: 0.3449 - accuracy: 0.5662 - val_loss: 0.1131 - val_accuracy: 1.0000\n",
            "Epoch 5/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.3373 - accuracy: 0.5696 - val_loss: 0.1854 - val_accuracy: 0.9259\n",
            "Epoch 6/100\n",
            "28/28 [==============================] - 10s 375ms/step - loss: 0.3256 - accuracy: 0.5765 - val_loss: 0.2285 - val_accuracy: 0.8889\n",
            "Epoch 7/100\n",
            "28/28 [==============================] - 11s 378ms/step - loss: 0.3112 - accuracy: 0.5788 - val_loss: 0.2280 - val_accuracy: 0.8519\n",
            "Epoch 8/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.3076 - accuracy: 0.5799 - val_loss: 0.2238 - val_accuracy: 0.8519\n",
            "Epoch 9/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.3024 - accuracy: 0.5765 - val_loss: 0.2790 - val_accuracy: 0.8519\n",
            "Epoch 10/100\n",
            "28/28 [==============================] - 11s 375ms/step - loss: 0.2974 - accuracy: 0.5799 - val_loss: 0.3635 - val_accuracy: 0.8519\n",
            "Epoch 11/100\n",
            "28/28 [==============================] - 10s 374ms/step - loss: 0.3039 - accuracy: 0.5822 - val_loss: 0.3305 - val_accuracy: 0.8519\n",
            "Epoch 12/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2903 - accuracy: 0.5811 - val_loss: 0.2623 - val_accuracy: 0.8519\n",
            "Epoch 13/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2961 - accuracy: 0.5822 - val_loss: 0.3034 - val_accuracy: 0.8519\n",
            "Epoch 14/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2907 - accuracy: 0.5788 - val_loss: 0.1731 - val_accuracy: 0.9259\n",
            "Epoch 15/100\n",
            "28/28 [==============================] - 11s 375ms/step - loss: 0.2792 - accuracy: 0.5822 - val_loss: 0.3289 - val_accuracy: 0.8519\n",
            "Epoch 16/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2733 - accuracy: 0.5822 - val_loss: 0.2505 - val_accuracy: 0.8889\n",
            "Epoch 17/100\n",
            "28/28 [==============================] - 10s 375ms/step - loss: 0.2784 - accuracy: 0.5811 - val_loss: 0.2866 - val_accuracy: 0.8519\n",
            "Epoch 18/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2688 - accuracy: 0.5822 - val_loss: 0.2728 - val_accuracy: 0.8519\n",
            "Epoch 19/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.2680 - accuracy: 0.5822 - val_loss: 0.3934 - val_accuracy: 0.8519\n",
            "2/2 [==============================] - 2s 121ms/step - loss: 0.2309 - accuracy: 0.9118\n",
            "Epoch 1/100\n",
            "28/28 [==============================] - 18s 428ms/step - loss: 0.4992 - accuracy: 0.4943 - val_loss: 0.4151 - val_accuracy: 0.8889\n",
            "Epoch 2/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.3789 - accuracy: 0.5434 - val_loss: 0.3665 - val_accuracy: 0.7778\n",
            "Epoch 3/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.3606 - accuracy: 0.5571 - val_loss: 0.3855 - val_accuracy: 0.7778\n",
            "Epoch 4/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.3661 - accuracy: 0.5548 - val_loss: 0.2666 - val_accuracy: 0.9259\n",
            "Epoch 5/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.3377 - accuracy: 0.5616 - val_loss: 0.3088 - val_accuracy: 0.9630\n",
            "Epoch 6/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.3177 - accuracy: 0.5674 - val_loss: 0.3145 - val_accuracy: 0.8148\n",
            "Epoch 7/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.3225 - accuracy: 0.5639 - val_loss: 0.2912 - val_accuracy: 0.8519\n",
            "Epoch 8/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.3141 - accuracy: 0.5696 - val_loss: 0.2986 - val_accuracy: 0.8148\n",
            "Epoch 9/100\n",
            "28/28 [==============================] - 10s 374ms/step - loss: 0.3076 - accuracy: 0.5685 - val_loss: 0.3797 - val_accuracy: 0.7778\n",
            "Epoch 10/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.3002 - accuracy: 0.5696 - val_loss: 0.2728 - val_accuracy: 0.8519\n",
            "Epoch 11/100\n",
            "28/28 [==============================] - 11s 375ms/step - loss: 0.2911 - accuracy: 0.5685 - val_loss: 0.3160 - val_accuracy: 0.7778\n",
            "Epoch 12/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2899 - accuracy: 0.5708 - val_loss: 0.2874 - val_accuracy: 0.8889\n",
            "Epoch 13/100\n",
            "28/28 [==============================] - 11s 378ms/step - loss: 0.2984 - accuracy: 0.5708 - val_loss: 0.2493 - val_accuracy: 0.9259\n",
            "Epoch 14/100\n",
            "28/28 [==============================] - 10s 375ms/step - loss: 0.2946 - accuracy: 0.5696 - val_loss: 0.3026 - val_accuracy: 0.8148\n",
            "Epoch 15/100\n",
            "28/28 [==============================] - 11s 375ms/step - loss: 0.2916 - accuracy: 0.5685 - val_loss: 0.3559 - val_accuracy: 0.8148\n",
            "Epoch 16/100\n",
            "28/28 [==============================] - 11s 378ms/step - loss: 0.2868 - accuracy: 0.5685 - val_loss: 0.2437 - val_accuracy: 0.8519\n",
            "Epoch 17/100\n",
            "28/28 [==============================] - 10s 375ms/step - loss: 0.2846 - accuracy: 0.5708 - val_loss: 0.3223 - val_accuracy: 0.8148\n",
            "Epoch 18/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2850 - accuracy: 0.5685 - val_loss: 0.1970 - val_accuracy: 0.9630\n",
            "Epoch 19/100\n",
            "28/28 [==============================] - 10s 375ms/step - loss: 0.2881 - accuracy: 0.5696 - val_loss: 0.3045 - val_accuracy: 0.8148\n",
            "Epoch 20/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2785 - accuracy: 0.5708 - val_loss: 0.3128 - val_accuracy: 0.8148\n",
            "Epoch 21/100\n",
            "28/28 [==============================] - 10s 375ms/step - loss: 0.2833 - accuracy: 0.5696 - val_loss: 0.2644 - val_accuracy: 0.8148\n",
            "Epoch 22/100\n",
            "28/28 [==============================] - 11s 375ms/step - loss: 0.2808 - accuracy: 0.5708 - val_loss: 0.3255 - val_accuracy: 0.8148\n",
            "Epoch 23/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.2762 - accuracy: 0.5708 - val_loss: 0.2209 - val_accuracy: 0.8148\n",
            "Epoch 24/100\n",
            "28/28 [==============================] - 11s 375ms/step - loss: 0.2768 - accuracy: 0.5708 - val_loss: 0.2672 - val_accuracy: 0.8148\n",
            "Epoch 25/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2756 - accuracy: 0.5708 - val_loss: 0.2471 - val_accuracy: 0.8148\n",
            "Epoch 26/100\n",
            "28/28 [==============================] - 10s 374ms/step - loss: 0.2735 - accuracy: 0.5696 - val_loss: 0.2730 - val_accuracy: 0.8148\n",
            "Epoch 27/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2706 - accuracy: 0.5696 - val_loss: 0.1780 - val_accuracy: 0.8889\n",
            "Epoch 28/100\n",
            "28/28 [==============================] - 10s 373ms/step - loss: 0.2719 - accuracy: 0.5708 - val_loss: 0.2573 - val_accuracy: 0.8519\n",
            "Epoch 29/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.2754 - accuracy: 0.5708 - val_loss: 0.2527 - val_accuracy: 0.8519\n",
            "Epoch 30/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2735 - accuracy: 0.5708 - val_loss: 0.1751 - val_accuracy: 0.8889\n",
            "Epoch 31/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.2655 - accuracy: 0.5708 - val_loss: 0.2413 - val_accuracy: 0.8148\n",
            "Epoch 32/100\n",
            "28/28 [==============================] - 10s 375ms/step - loss: 0.2625 - accuracy: 0.5708 - val_loss: 0.2913 - val_accuracy: 0.8519\n",
            "Epoch 33/100\n",
            "28/28 [==============================] - 11s 378ms/step - loss: 0.2682 - accuracy: 0.5708 - val_loss: 0.1458 - val_accuracy: 0.9630\n",
            "Epoch 34/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2681 - accuracy: 0.5708 - val_loss: 0.1761 - val_accuracy: 0.9630\n",
            "Epoch 35/100\n",
            "28/28 [==============================] - 10s 375ms/step - loss: 0.2605 - accuracy: 0.5708 - val_loss: 0.2466 - val_accuracy: 0.8148\n",
            "Epoch 36/100\n",
            "28/28 [==============================] - 11s 375ms/step - loss: 0.2658 - accuracy: 0.5696 - val_loss: 0.2012 - val_accuracy: 0.8889\n",
            "Epoch 37/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.2681 - accuracy: 0.5708 - val_loss: 0.1829 - val_accuracy: 0.9630\n",
            "Epoch 38/100\n",
            "28/28 [==============================] - 11s 375ms/step - loss: 0.2637 - accuracy: 0.5708 - val_loss: 0.2813 - val_accuracy: 0.8148\n",
            "Epoch 39/100\n",
            "28/28 [==============================] - 11s 375ms/step - loss: 0.2633 - accuracy: 0.5708 - val_loss: 0.2335 - val_accuracy: 0.8519\n",
            "Epoch 40/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2648 - accuracy: 0.5708 - val_loss: 0.2206 - val_accuracy: 0.9259\n",
            "Epoch 41/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2653 - accuracy: 0.5708 - val_loss: 0.2031 - val_accuracy: 0.9630\n",
            "Epoch 42/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2732 - accuracy: 0.5708 - val_loss: 0.2093 - val_accuracy: 0.8889\n",
            "Epoch 43/100\n",
            "28/28 [==============================] - 10s 375ms/step - loss: 0.2642 - accuracy: 0.5696 - val_loss: 0.2634 - val_accuracy: 0.8519\n",
            "Epoch 44/100\n",
            "28/28 [==============================] - 10s 374ms/step - loss: 0.2639 - accuracy: 0.5708 - val_loss: 0.2632 - val_accuracy: 0.8148\n",
            "Epoch 45/100\n",
            "28/28 [==============================] - 11s 375ms/step - loss: 0.2704 - accuracy: 0.5708 - val_loss: 0.2795 - val_accuracy: 0.8519\n",
            "Epoch 46/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2615 - accuracy: 0.5708 - val_loss: 0.3313 - val_accuracy: 0.8519\n",
            "Epoch 47/100\n",
            "28/28 [==============================] - 10s 375ms/step - loss: 0.2598 - accuracy: 0.5708 - val_loss: 0.2124 - val_accuracy: 0.8519\n",
            "Epoch 48/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.2605 - accuracy: 0.5708 - val_loss: 0.2453 - val_accuracy: 0.8148\n",
            "2/2 [==============================] - 2s 104ms/step - loss: 0.0558 - accuracy: 1.0000\n",
            "Epoch 1/100\n",
            "27/27 [==============================] - 18s 431ms/step - loss: 0.5013 - accuracy: 0.5023 - val_loss: 0.3803 - val_accuracy: 0.7778\n",
            "Epoch 2/100\n",
            "27/27 [==============================] - 10s 377ms/step - loss: 0.4087 - accuracy: 0.5501 - val_loss: 0.2659 - val_accuracy: 0.8889\n",
            "Epoch 3/100\n",
            "27/27 [==============================] - 10s 377ms/step - loss: 0.3715 - accuracy: 0.5641 - val_loss: 0.4200 - val_accuracy: 0.7407\n",
            "Epoch 4/100\n",
            "27/27 [==============================] - 10s 379ms/step - loss: 0.3428 - accuracy: 0.5723 - val_loss: 0.2360 - val_accuracy: 0.8148\n",
            "Epoch 5/100\n",
            "27/27 [==============================] - 10s 377ms/step - loss: 0.3279 - accuracy: 0.5769 - val_loss: 0.3064 - val_accuracy: 0.8148\n",
            "Epoch 6/100\n",
            "27/27 [==============================] - 10s 378ms/step - loss: 0.3128 - accuracy: 0.5781 - val_loss: 0.2714 - val_accuracy: 0.8519\n",
            "Epoch 7/100\n",
            "27/27 [==============================] - 10s 378ms/step - loss: 0.3126 - accuracy: 0.5781 - val_loss: 0.2838 - val_accuracy: 0.8519\n",
            "Epoch 8/100\n",
            "27/27 [==============================] - 10s 379ms/step - loss: 0.3053 - accuracy: 0.5816 - val_loss: 0.2485 - val_accuracy: 0.8519\n",
            "Epoch 9/100\n",
            "27/27 [==============================] - 10s 378ms/step - loss: 0.2931 - accuracy: 0.5828 - val_loss: 0.2953 - val_accuracy: 0.8519\n",
            "Epoch 10/100\n",
            "27/27 [==============================] - 10s 378ms/step - loss: 0.2904 - accuracy: 0.5839 - val_loss: 0.3716 - val_accuracy: 0.8519\n",
            "Epoch 11/100\n",
            "27/27 [==============================] - 10s 377ms/step - loss: 0.2973 - accuracy: 0.5839 - val_loss: 0.3338 - val_accuracy: 0.8519\n",
            "Epoch 12/100\n",
            "27/27 [==============================] - 10s 377ms/step - loss: 0.2922 - accuracy: 0.5851 - val_loss: 0.3229 - val_accuracy: 0.8519\n",
            "Epoch 13/100\n",
            "27/27 [==============================] - 10s 378ms/step - loss: 0.2871 - accuracy: 0.5839 - val_loss: 0.2970 - val_accuracy: 0.8519\n",
            "Epoch 14/100\n",
            "27/27 [==============================] - 10s 377ms/step - loss: 0.2751 - accuracy: 0.5839 - val_loss: 0.2664 - val_accuracy: 0.8519\n",
            "Epoch 15/100\n",
            "27/27 [==============================] - 10s 378ms/step - loss: 0.2769 - accuracy: 0.5839 - val_loss: 0.2767 - val_accuracy: 0.8519\n",
            "Epoch 16/100\n",
            "27/27 [==============================] - 10s 377ms/step - loss: 0.2727 - accuracy: 0.5839 - val_loss: 0.2896 - val_accuracy: 0.8519\n",
            "Epoch 17/100\n",
            "27/27 [==============================] - 10s 376ms/step - loss: 0.2775 - accuracy: 0.5839 - val_loss: 0.6346 - val_accuracy: 0.7778\n",
            "Epoch 18/100\n",
            "27/27 [==============================] - 10s 376ms/step - loss: 0.2689 - accuracy: 0.5851 - val_loss: 0.3444 - val_accuracy: 0.8519\n",
            "Epoch 19/100\n",
            "27/27 [==============================] - 10s 379ms/step - loss: 0.2723 - accuracy: 0.5839 - val_loss: 0.2498 - val_accuracy: 0.8889\n",
            "2/2 [==============================] - 2s 124ms/step - loss: 0.1659 - accuracy: 0.9706\n",
            "[0.9588235139846801, 0.9470588088035583, 0.9647058725357056]\n",
            "[0.9507813140511734, 0.9385649310603057, 0.958319725121037]\n",
            "Epoch 1/100\n",
            "28/28 [==============================] - 18s 427ms/step - loss: 0.5859 - accuracy: 0.4862 - val_loss: 0.4782 - val_accuracy: 0.7407\n",
            "Epoch 2/100\n",
            "28/28 [==============================] - 11s 379ms/step - loss: 0.4289 - accuracy: 0.5241 - val_loss: 0.2608 - val_accuracy: 0.9259\n",
            "Epoch 3/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.3847 - accuracy: 0.5391 - val_loss: 0.2643 - val_accuracy: 0.8519\n",
            "Epoch 4/100\n",
            "28/28 [==============================] - 11s 378ms/step - loss: 0.3561 - accuracy: 0.5471 - val_loss: 0.2531 - val_accuracy: 0.8889\n",
            "Epoch 5/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.3503 - accuracy: 0.5494 - val_loss: 0.2782 - val_accuracy: 0.8889\n",
            "Epoch 6/100\n",
            "28/28 [==============================] - 11s 379ms/step - loss: 0.3437 - accuracy: 0.5517 - val_loss: 0.2449 - val_accuracy: 0.9259\n",
            "Epoch 7/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.3182 - accuracy: 0.5540 - val_loss: 0.2217 - val_accuracy: 0.9259\n",
            "Epoch 8/100\n",
            "28/28 [==============================] - 10s 374ms/step - loss: 0.3271 - accuracy: 0.5540 - val_loss: 0.2254 - val_accuracy: 0.9259\n",
            "Epoch 9/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.3240 - accuracy: 0.5517 - val_loss: 0.2130 - val_accuracy: 0.9259\n",
            "Epoch 10/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.3126 - accuracy: 0.5552 - val_loss: 0.2198 - val_accuracy: 0.9259\n",
            "Epoch 11/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.3146 - accuracy: 0.5517 - val_loss: 0.2006 - val_accuracy: 0.9259\n",
            "Epoch 12/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.3071 - accuracy: 0.5586 - val_loss: 0.1966 - val_accuracy: 0.9259\n",
            "Epoch 13/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.2978 - accuracy: 0.5575 - val_loss: 0.1732 - val_accuracy: 0.9259\n",
            "Epoch 14/100\n",
            "28/28 [==============================] - 10s 374ms/step - loss: 0.3067 - accuracy: 0.5586 - val_loss: 0.1946 - val_accuracy: 0.9259\n",
            "Epoch 15/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2994 - accuracy: 0.5575 - val_loss: 0.1831 - val_accuracy: 0.9630\n",
            "Epoch 16/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.3040 - accuracy: 0.5575 - val_loss: 0.1845 - val_accuracy: 0.9259\n",
            "Epoch 17/100\n",
            "28/28 [==============================] - 11s 378ms/step - loss: 0.3192 - accuracy: 0.5529 - val_loss: 0.1713 - val_accuracy: 0.8889\n",
            "Epoch 18/100\n",
            "28/28 [==============================] - 11s 379ms/step - loss: 0.3108 - accuracy: 0.5540 - val_loss: 0.1565 - val_accuracy: 0.8889\n",
            "Epoch 19/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.3018 - accuracy: 0.5552 - val_loss: 0.1450 - val_accuracy: 0.9259\n",
            "Epoch 20/100\n",
            "28/28 [==============================] - 11s 375ms/step - loss: 0.2922 - accuracy: 0.5575 - val_loss: 0.1625 - val_accuracy: 0.9259\n",
            "Epoch 21/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.2963 - accuracy: 0.5563 - val_loss: 0.1339 - val_accuracy: 0.9630\n",
            "Epoch 22/100\n",
            "28/28 [==============================] - 11s 379ms/step - loss: 0.2935 - accuracy: 0.5586 - val_loss: 0.1330 - val_accuracy: 0.9630\n",
            "Epoch 23/100\n",
            "28/28 [==============================] - 10s 374ms/step - loss: 0.2858 - accuracy: 0.5575 - val_loss: 0.1343 - val_accuracy: 0.9630\n",
            "Epoch 24/100\n",
            "28/28 [==============================] - 11s 375ms/step - loss: 0.2836 - accuracy: 0.5586 - val_loss: 0.1734 - val_accuracy: 0.9630\n",
            "Epoch 25/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2847 - accuracy: 0.5586 - val_loss: 0.1655 - val_accuracy: 0.9630\n",
            "Epoch 26/100\n",
            "28/28 [==============================] - 10s 375ms/step - loss: 0.2776 - accuracy: 0.5586 - val_loss: 0.1858 - val_accuracy: 0.9630\n",
            "Epoch 27/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.2778 - accuracy: 0.5586 - val_loss: 0.1691 - val_accuracy: 0.9259\n",
            "Epoch 28/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2858 - accuracy: 0.5586 - val_loss: 0.2253 - val_accuracy: 0.9259\n",
            "Epoch 29/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2918 - accuracy: 0.5586 - val_loss: 0.1916 - val_accuracy: 0.8889\n",
            "Epoch 30/100\n",
            "28/28 [==============================] - 10s 375ms/step - loss: 0.2780 - accuracy: 0.5586 - val_loss: 0.1850 - val_accuracy: 0.9259\n",
            "Epoch 31/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.2740 - accuracy: 0.5586 - val_loss: 0.2057 - val_accuracy: 0.9259\n",
            "Epoch 32/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2783 - accuracy: 0.5586 - val_loss: 0.2283 - val_accuracy: 0.9630\n",
            "Epoch 33/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.2727 - accuracy: 0.5586 - val_loss: 0.1886 - val_accuracy: 0.9259\n",
            "Epoch 34/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2792 - accuracy: 0.5586 - val_loss: 0.1927 - val_accuracy: 0.9259\n",
            "Epoch 35/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2843 - accuracy: 0.5586 - val_loss: 0.2169 - val_accuracy: 0.9630\n",
            "Epoch 36/100\n",
            "28/28 [==============================] - 11s 375ms/step - loss: 0.2747 - accuracy: 0.5586 - val_loss: 0.2587 - val_accuracy: 0.9259\n",
            "Epoch 37/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2851 - accuracy: 0.5586 - val_loss: 0.1402 - val_accuracy: 0.9259\n",
            "2/2 [==============================] - 2s 103ms/step - loss: 0.1080 - accuracy: 0.9706\n",
            "Epoch 1/100\n",
            "27/27 [==============================] - 17s 452ms/step - loss: 0.5011 - accuracy: 0.5093 - val_loss: 0.7865 - val_accuracy: 0.6667\n",
            "Epoch 2/100\n",
            "27/27 [==============================] - 10s 383ms/step - loss: 0.3852 - accuracy: 0.5752 - val_loss: 0.4389 - val_accuracy: 0.8148\n",
            "Epoch 3/100\n",
            "27/27 [==============================] - 10s 384ms/step - loss: 0.3702 - accuracy: 0.5845 - val_loss: 0.3036 - val_accuracy: 0.8519\n",
            "Epoch 4/100\n",
            "27/27 [==============================] - 10s 385ms/step - loss: 0.3361 - accuracy: 0.5856 - val_loss: 0.1799 - val_accuracy: 0.9630\n",
            "Epoch 5/100\n",
            "27/27 [==============================] - 10s 386ms/step - loss: 0.3085 - accuracy: 0.5984 - val_loss: 0.1596 - val_accuracy: 0.9630\n",
            "Epoch 6/100\n",
            "27/27 [==============================] - 10s 384ms/step - loss: 0.2933 - accuracy: 0.6007 - val_loss: 0.1605 - val_accuracy: 0.9259\n",
            "Epoch 7/100\n",
            "27/27 [==============================] - 10s 386ms/step - loss: 0.2938 - accuracy: 0.6019 - val_loss: 0.1409 - val_accuracy: 0.9630\n",
            "Epoch 8/100\n",
            "27/27 [==============================] - 10s 383ms/step - loss: 0.2886 - accuracy: 0.6019 - val_loss: 0.1909 - val_accuracy: 0.9259\n",
            "Epoch 9/100\n",
            "27/27 [==============================] - 10s 382ms/step - loss: 0.2839 - accuracy: 0.6030 - val_loss: 0.1859 - val_accuracy: 0.8889\n",
            "Epoch 10/100\n",
            "27/27 [==============================] - 10s 383ms/step - loss: 0.2832 - accuracy: 0.6019 - val_loss: 0.1522 - val_accuracy: 0.9630\n",
            "Epoch 11/100\n",
            "27/27 [==============================] - 10s 385ms/step - loss: 0.2687 - accuracy: 0.6042 - val_loss: 0.1386 - val_accuracy: 0.9630\n",
            "Epoch 12/100\n",
            "27/27 [==============================] - 10s 384ms/step - loss: 0.2826 - accuracy: 0.6007 - val_loss: 0.1561 - val_accuracy: 0.9259\n",
            "Epoch 13/100\n",
            "27/27 [==============================] - 10s 387ms/step - loss: 0.2757 - accuracy: 0.6030 - val_loss: 0.1247 - val_accuracy: 0.9630\n",
            "Epoch 14/100\n",
            "27/27 [==============================] - 10s 384ms/step - loss: 0.2659 - accuracy: 0.6042 - val_loss: 0.1733 - val_accuracy: 0.9259\n",
            "Epoch 15/100\n",
            "27/27 [==============================] - 10s 385ms/step - loss: 0.2653 - accuracy: 0.6042 - val_loss: 0.1450 - val_accuracy: 0.9630\n",
            "Epoch 16/100\n",
            "27/27 [==============================] - 10s 388ms/step - loss: 0.2748 - accuracy: 0.6042 - val_loss: 0.1071 - val_accuracy: 0.9630\n",
            "Epoch 17/100\n",
            "27/27 [==============================] - 10s 383ms/step - loss: 0.2616 - accuracy: 0.6030 - val_loss: 0.1990 - val_accuracy: 0.8889\n",
            "Epoch 18/100\n",
            "27/27 [==============================] - 10s 384ms/step - loss: 0.2669 - accuracy: 0.6030 - val_loss: 0.1268 - val_accuracy: 0.9630\n",
            "Epoch 19/100\n",
            "27/27 [==============================] - 10s 382ms/step - loss: 0.2660 - accuracy: 0.6007 - val_loss: 0.1120 - val_accuracy: 0.9630\n",
            "Epoch 20/100\n",
            "27/27 [==============================] - 10s 384ms/step - loss: 0.2586 - accuracy: 0.6030 - val_loss: 0.1198 - val_accuracy: 0.9630\n",
            "Epoch 21/100\n",
            "27/27 [==============================] - 10s 384ms/step - loss: 0.2618 - accuracy: 0.6042 - val_loss: 0.1019 - val_accuracy: 0.9630\n",
            "Epoch 22/100\n",
            "27/27 [==============================] - 10s 384ms/step - loss: 0.2542 - accuracy: 0.6030 - val_loss: 0.1055 - val_accuracy: 0.9630\n",
            "Epoch 23/100\n",
            "27/27 [==============================] - 10s 384ms/step - loss: 0.2634 - accuracy: 0.6030 - val_loss: 0.1011 - val_accuracy: 0.9630\n",
            "Epoch 24/100\n",
            "27/27 [==============================] - 10s 387ms/step - loss: 0.2563 - accuracy: 0.6042 - val_loss: 0.0770 - val_accuracy: 0.9630\n",
            "Epoch 25/100\n",
            "27/27 [==============================] - 10s 384ms/step - loss: 0.2500 - accuracy: 0.6042 - val_loss: 0.0966 - val_accuracy: 0.9630\n",
            "Epoch 26/100\n",
            "27/27 [==============================] - 10s 385ms/step - loss: 0.2579 - accuracy: 0.6042 - val_loss: 0.1034 - val_accuracy: 0.9630\n",
            "Epoch 27/100\n",
            "27/27 [==============================] - 10s 389ms/step - loss: 0.2506 - accuracy: 0.6042 - val_loss: 0.0975 - val_accuracy: 0.9630\n",
            "Epoch 28/100\n",
            "27/27 [==============================] - 10s 389ms/step - loss: 0.2480 - accuracy: 0.6042 - val_loss: 0.1016 - val_accuracy: 0.9630\n",
            "Epoch 29/100\n",
            "27/27 [==============================] - 10s 389ms/step - loss: 0.2480 - accuracy: 0.6042 - val_loss: 0.1088 - val_accuracy: 0.9630\n",
            "Epoch 30/100\n",
            "27/27 [==============================] - 11s 389ms/step - loss: 0.2434 - accuracy: 0.6042 - val_loss: 0.0866 - val_accuracy: 0.9630\n",
            "Epoch 31/100\n",
            "27/27 [==============================] - 11s 391ms/step - loss: 0.2470 - accuracy: 0.6042 - val_loss: 0.0749 - val_accuracy: 1.0000\n",
            "Epoch 32/100\n",
            "27/27 [==============================] - 11s 393ms/step - loss: 0.2524 - accuracy: 0.6042 - val_loss: 0.0717 - val_accuracy: 0.9630\n",
            "Epoch 33/100\n",
            "27/27 [==============================] - 10s 389ms/step - loss: 0.2548 - accuracy: 0.6042 - val_loss: 0.0924 - val_accuracy: 1.0000\n",
            "Epoch 34/100\n",
            "27/27 [==============================] - 11s 391ms/step - loss: 0.2506 - accuracy: 0.6042 - val_loss: 0.0675 - val_accuracy: 0.9630\n",
            "Epoch 35/100\n",
            "27/27 [==============================] - 10s 389ms/step - loss: 0.2487 - accuracy: 0.6042 - val_loss: 0.0763 - val_accuracy: 0.9630\n",
            "Epoch 36/100\n",
            "27/27 [==============================] - 11s 390ms/step - loss: 0.2457 - accuracy: 0.6042 - val_loss: 0.0948 - val_accuracy: 0.9630\n",
            "Epoch 37/100\n",
            "27/27 [==============================] - 11s 390ms/step - loss: 0.2428 - accuracy: 0.6042 - val_loss: 0.0734 - val_accuracy: 0.9630\n",
            "Epoch 38/100\n",
            "27/27 [==============================] - 11s 390ms/step - loss: 0.2480 - accuracy: 0.6030 - val_loss: 0.1014 - val_accuracy: 0.9630\n",
            "Epoch 39/100\n",
            "27/27 [==============================] - 10s 388ms/step - loss: 0.2406 - accuracy: 0.6042 - val_loss: 0.0886 - val_accuracy: 0.9630\n",
            "Epoch 40/100\n",
            "27/27 [==============================] - 10s 388ms/step - loss: 0.2497 - accuracy: 0.6042 - val_loss: 0.1295 - val_accuracy: 1.0000\n",
            "Epoch 41/100\n",
            "27/27 [==============================] - 10s 388ms/step - loss: 0.2407 - accuracy: 0.6042 - val_loss: 0.1191 - val_accuracy: 0.9630\n",
            "Epoch 42/100\n",
            "27/27 [==============================] - 11s 389ms/step - loss: 0.2442 - accuracy: 0.6042 - val_loss: 0.1243 - val_accuracy: 0.9630\n",
            "Epoch 43/100\n",
            "27/27 [==============================] - 10s 388ms/step - loss: 0.2452 - accuracy: 0.6042 - val_loss: 0.0908 - val_accuracy: 0.9630\n",
            "Epoch 44/100\n",
            "27/27 [==============================] - 10s 387ms/step - loss: 0.2560 - accuracy: 0.6042 - val_loss: 0.1637 - val_accuracy: 0.9630\n",
            "Epoch 45/100\n",
            "27/27 [==============================] - 10s 387ms/step - loss: 0.2455 - accuracy: 0.6042 - val_loss: 0.2115 - val_accuracy: 0.9259\n",
            "Epoch 46/100\n",
            "27/27 [==============================] - 10s 387ms/step - loss: 0.2393 - accuracy: 0.6042 - val_loss: 0.1158 - val_accuracy: 0.9630\n",
            "Epoch 47/100\n",
            "27/27 [==============================] - 10s 388ms/step - loss: 0.2440 - accuracy: 0.6042 - val_loss: 0.1375 - val_accuracy: 1.0000\n",
            "Epoch 48/100\n",
            "27/27 [==============================] - 10s 388ms/step - loss: 0.2400 - accuracy: 0.6042 - val_loss: 0.1130 - val_accuracy: 0.9630\n",
            "Epoch 49/100\n",
            "27/27 [==============================] - 10s 388ms/step - loss: 0.2399 - accuracy: 0.6042 - val_loss: 0.1542 - val_accuracy: 0.9630\n",
            "2/2 [==============================] - 2s 119ms/step - loss: 0.1783 - accuracy: 0.9118\n",
            "Epoch 1/100\n",
            "28/28 [==============================] - 18s 432ms/step - loss: 0.4988 - accuracy: 0.5184 - val_loss: 0.5423 - val_accuracy: 0.7778\n",
            "Epoch 2/100\n",
            "28/28 [==============================] - 11s 381ms/step - loss: 0.4109 - accuracy: 0.5655 - val_loss: 0.2760 - val_accuracy: 0.8519\n",
            "Epoch 3/100\n",
            "28/28 [==============================] - 11s 383ms/step - loss: 0.3665 - accuracy: 0.5759 - val_loss: 0.2112 - val_accuracy: 0.9630\n",
            "Epoch 4/100\n",
            "28/28 [==============================] - 11s 382ms/step - loss: 0.3464 - accuracy: 0.5851 - val_loss: 0.1999 - val_accuracy: 0.9630\n",
            "Epoch 5/100\n",
            "28/28 [==============================] - 11s 383ms/step - loss: 0.3264 - accuracy: 0.5885 - val_loss: 0.1532 - val_accuracy: 1.0000\n",
            "Epoch 6/100\n",
            "28/28 [==============================] - 11s 383ms/step - loss: 0.3180 - accuracy: 0.5908 - val_loss: 0.1542 - val_accuracy: 1.0000\n",
            "Epoch 7/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.3175 - accuracy: 0.5977 - val_loss: 0.1577 - val_accuracy: 1.0000\n",
            "Epoch 8/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.3007 - accuracy: 0.5989 - val_loss: 0.1646 - val_accuracy: 1.0000\n",
            "Epoch 9/100\n",
            "28/28 [==============================] - 11s 384ms/step - loss: 0.2974 - accuracy: 0.6000 - val_loss: 0.1389 - val_accuracy: 1.0000\n",
            "Epoch 10/100\n",
            "28/28 [==============================] - 11s 379ms/step - loss: 0.2842 - accuracy: 0.5977 - val_loss: 0.1677 - val_accuracy: 0.9630\n",
            "Epoch 11/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.2914 - accuracy: 0.6000 - val_loss: 0.1676 - val_accuracy: 0.9630\n",
            "Epoch 12/100\n",
            "28/28 [==============================] - 11s 382ms/step - loss: 0.2772 - accuracy: 0.5989 - val_loss: 0.1335 - val_accuracy: 0.9630\n",
            "Epoch 13/100\n",
            "28/28 [==============================] - 11s 383ms/step - loss: 0.2848 - accuracy: 0.6000 - val_loss: 0.1272 - val_accuracy: 0.9259\n",
            "Epoch 14/100\n",
            "28/28 [==============================] - 11s 382ms/step - loss: 0.2820 - accuracy: 0.6000 - val_loss: 0.0870 - val_accuracy: 1.0000\n",
            "Epoch 15/100\n",
            "28/28 [==============================] - 11s 379ms/step - loss: 0.2737 - accuracy: 0.6000 - val_loss: 0.0990 - val_accuracy: 1.0000\n",
            "Epoch 16/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.2765 - accuracy: 0.5989 - val_loss: 0.0918 - val_accuracy: 1.0000\n",
            "Epoch 17/100\n",
            "28/28 [==============================] - 11s 381ms/step - loss: 0.2792 - accuracy: 0.5977 - val_loss: 0.1236 - val_accuracy: 0.9630\n",
            "Epoch 18/100\n",
            "28/28 [==============================] - 11s 381ms/step - loss: 0.2746 - accuracy: 0.5989 - val_loss: 0.1288 - val_accuracy: 0.9630\n",
            "Epoch 19/100\n",
            "28/28 [==============================] - 11s 382ms/step - loss: 0.2707 - accuracy: 0.5977 - val_loss: 0.1014 - val_accuracy: 1.0000\n",
            "Epoch 20/100\n",
            "28/28 [==============================] - 11s 379ms/step - loss: 0.2700 - accuracy: 0.6000 - val_loss: 0.1314 - val_accuracy: 1.0000\n",
            "Epoch 21/100\n",
            "28/28 [==============================] - 11s 381ms/step - loss: 0.2688 - accuracy: 0.5989 - val_loss: 0.1439 - val_accuracy: 0.9630\n",
            "Epoch 22/100\n",
            "28/28 [==============================] - 11s 381ms/step - loss: 0.2644 - accuracy: 0.6000 - val_loss: 0.1230 - val_accuracy: 0.9259\n",
            "Epoch 23/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.2658 - accuracy: 0.6000 - val_loss: 0.1133 - val_accuracy: 1.0000\n",
            "Epoch 24/100\n",
            "28/28 [==============================] - 11s 379ms/step - loss: 0.2624 - accuracy: 0.6000 - val_loss: 0.1151 - val_accuracy: 1.0000\n",
            "Epoch 25/100\n",
            "28/28 [==============================] - 11s 382ms/step - loss: 0.2692 - accuracy: 0.6000 - val_loss: 0.0826 - val_accuracy: 1.0000\n",
            "Epoch 26/100\n",
            "28/28 [==============================] - 11s 382ms/step - loss: 0.2729 - accuracy: 0.6000 - val_loss: 0.0735 - val_accuracy: 1.0000\n",
            "Epoch 27/100\n",
            "28/28 [==============================] - 11s 381ms/step - loss: 0.2675 - accuracy: 0.5989 - val_loss: 0.1100 - val_accuracy: 1.0000\n",
            "Epoch 28/100\n",
            "28/28 [==============================] - 11s 381ms/step - loss: 0.2616 - accuracy: 0.6000 - val_loss: 0.0642 - val_accuracy: 1.0000\n",
            "Epoch 29/100\n",
            "28/28 [==============================] - 11s 381ms/step - loss: 0.2701 - accuracy: 0.6000 - val_loss: 0.1150 - val_accuracy: 1.0000\n",
            "Epoch 30/100\n",
            "28/28 [==============================] - 11s 382ms/step - loss: 0.2613 - accuracy: 0.5989 - val_loss: 0.1236 - val_accuracy: 1.0000\n",
            "Epoch 31/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.2628 - accuracy: 0.6000 - val_loss: 0.0754 - val_accuracy: 1.0000\n",
            "Epoch 32/100\n",
            "28/28 [==============================] - 11s 381ms/step - loss: 0.2645 - accuracy: 0.5989 - val_loss: 0.0946 - val_accuracy: 1.0000\n",
            "Epoch 33/100\n",
            "28/28 [==============================] - 11s 379ms/step - loss: 0.2555 - accuracy: 0.6000 - val_loss: 0.1067 - val_accuracy: 1.0000\n",
            "Epoch 34/100\n",
            "28/28 [==============================] - 11s 381ms/step - loss: 0.2604 - accuracy: 0.6000 - val_loss: 0.0891 - val_accuracy: 1.0000\n",
            "Epoch 35/100\n",
            "28/28 [==============================] - 11s 381ms/step - loss: 0.2591 - accuracy: 0.6000 - val_loss: 0.2172 - val_accuracy: 0.9259\n",
            "Epoch 36/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.2590 - accuracy: 0.6000 - val_loss: 0.1289 - val_accuracy: 1.0000\n",
            "Epoch 37/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.2564 - accuracy: 0.5977 - val_loss: 0.1264 - val_accuracy: 1.0000\n",
            "Epoch 38/100\n",
            "28/28 [==============================] - 11s 382ms/step - loss: 0.2576 - accuracy: 0.6000 - val_loss: 0.0928 - val_accuracy: 1.0000\n",
            "Epoch 39/100\n",
            "28/28 [==============================] - 11s 379ms/step - loss: 0.2538 - accuracy: 0.5989 - val_loss: 0.0753 - val_accuracy: 1.0000\n",
            "Epoch 40/100\n",
            "28/28 [==============================] - 11s 381ms/step - loss: 0.2561 - accuracy: 0.6000 - val_loss: 0.1141 - val_accuracy: 1.0000\n",
            "Epoch 41/100\n",
            "28/28 [==============================] - 11s 382ms/step - loss: 0.2572 - accuracy: 0.6000 - val_loss: 0.0973 - val_accuracy: 1.0000\n",
            "Epoch 42/100\n",
            "28/28 [==============================] - 11s 379ms/step - loss: 0.2568 - accuracy: 0.5989 - val_loss: 0.0984 - val_accuracy: 1.0000\n",
            "Epoch 43/100\n",
            "28/28 [==============================] - 11s 382ms/step - loss: 0.2528 - accuracy: 0.6000 - val_loss: 0.1500 - val_accuracy: 0.9630\n",
            "2/2 [==============================] - 2s 120ms/step - loss: 0.0512 - accuracy: 1.0000\n",
            "Epoch 1/100\n",
            "27/27 [==============================] - 17s 454ms/step - loss: 0.4758 - accuracy: 0.5174 - val_loss: 1.4719 - val_accuracy: 0.6296\n",
            "Epoch 2/100\n",
            "27/27 [==============================] - 11s 393ms/step - loss: 0.3914 - accuracy: 0.5556 - val_loss: 1.0286 - val_accuracy: 0.6667\n",
            "Epoch 3/100\n",
            "27/27 [==============================] - 11s 391ms/step - loss: 0.3670 - accuracy: 0.5613 - val_loss: 0.5908 - val_accuracy: 0.8148\n",
            "Epoch 4/100\n",
            "27/27 [==============================] - 10s 388ms/step - loss: 0.3443 - accuracy: 0.5718 - val_loss: 0.7242 - val_accuracy: 0.8148\n",
            "Epoch 5/100\n",
            "27/27 [==============================] - 10s 386ms/step - loss: 0.3419 - accuracy: 0.5741 - val_loss: 0.6099 - val_accuracy: 0.7778\n",
            "Epoch 6/100\n",
            "27/27 [==============================] - 11s 391ms/step - loss: 0.3248 - accuracy: 0.5775 - val_loss: 0.6467 - val_accuracy: 0.7407\n",
            "Epoch 7/100\n",
            "27/27 [==============================] - 11s 390ms/step - loss: 0.3083 - accuracy: 0.5822 - val_loss: 0.5810 - val_accuracy: 0.8148\n",
            "Epoch 8/100\n",
            "27/27 [==============================] - 11s 391ms/step - loss: 0.3038 - accuracy: 0.5810 - val_loss: 0.5429 - val_accuracy: 0.8148\n",
            "Epoch 9/100\n",
            "27/27 [==============================] - 10s 389ms/step - loss: 0.2956 - accuracy: 0.5845 - val_loss: 0.5528 - val_accuracy: 0.8148\n",
            "Epoch 10/100\n",
            "27/27 [==============================] - 11s 391ms/step - loss: 0.2883 - accuracy: 0.5845 - val_loss: 0.4314 - val_accuracy: 0.8148\n",
            "Epoch 11/100\n",
            "27/27 [==============================] - 10s 387ms/step - loss: 0.2932 - accuracy: 0.5833 - val_loss: 0.6494 - val_accuracy: 0.7778\n",
            "Epoch 12/100\n",
            "27/27 [==============================] - 11s 389ms/step - loss: 0.2967 - accuracy: 0.5833 - val_loss: 0.3674 - val_accuracy: 0.8148\n",
            "Epoch 13/100\n",
            "27/27 [==============================] - 10s 388ms/step - loss: 0.2819 - accuracy: 0.5856 - val_loss: 0.4906 - val_accuracy: 0.8148\n",
            "Epoch 14/100\n",
            "27/27 [==============================] - 10s 389ms/step - loss: 0.2826 - accuracy: 0.5822 - val_loss: 0.6201 - val_accuracy: 0.8148\n",
            "Epoch 15/100\n",
            "27/27 [==============================] - 11s 390ms/step - loss: 0.2817 - accuracy: 0.5833 - val_loss: 0.5455 - val_accuracy: 0.8148\n",
            "Epoch 16/100\n",
            "27/27 [==============================] - 10s 388ms/step - loss: 0.2758 - accuracy: 0.5845 - val_loss: 0.5786 - val_accuracy: 0.8148\n",
            "Epoch 17/100\n",
            "27/27 [==============================] - 10s 388ms/step - loss: 0.2733 - accuracy: 0.5856 - val_loss: 0.6924 - val_accuracy: 0.8148\n",
            "Epoch 18/100\n",
            "27/27 [==============================] - 11s 390ms/step - loss: 0.2725 - accuracy: 0.5856 - val_loss: 0.7095 - val_accuracy: 0.8148\n",
            "Epoch 19/100\n",
            "27/27 [==============================] - 11s 390ms/step - loss: 0.2730 - accuracy: 0.5845 - val_loss: 0.5204 - val_accuracy: 0.8148\n",
            "Epoch 20/100\n",
            "27/27 [==============================] - 10s 389ms/step - loss: 0.2696 - accuracy: 0.5856 - val_loss: 0.6121 - val_accuracy: 0.8148\n",
            "Epoch 21/100\n",
            "27/27 [==============================] - 11s 390ms/step - loss: 0.2690 - accuracy: 0.5845 - val_loss: 0.6512 - val_accuracy: 0.8148\n",
            "Epoch 22/100\n",
            "27/27 [==============================] - 10s 388ms/step - loss: 0.2658 - accuracy: 0.5856 - val_loss: 0.6478 - val_accuracy: 0.8148\n",
            "Epoch 23/100\n",
            "27/27 [==============================] - 10s 388ms/step - loss: 0.2692 - accuracy: 0.5856 - val_loss: 0.5754 - val_accuracy: 0.8148\n",
            "Epoch 24/100\n",
            "27/27 [==============================] - 10s 388ms/step - loss: 0.2683 - accuracy: 0.5856 - val_loss: 0.7882 - val_accuracy: 0.7778\n",
            "Epoch 25/100\n",
            "27/27 [==============================] - 10s 388ms/step - loss: 0.2628 - accuracy: 0.5856 - val_loss: 0.4498 - val_accuracy: 0.8148\n",
            "Epoch 26/100\n",
            "27/27 [==============================] - 10s 389ms/step - loss: 0.2605 - accuracy: 0.5856 - val_loss: 0.6141 - val_accuracy: 0.7778\n",
            "Epoch 27/100\n",
            "27/27 [==============================] - 11s 391ms/step - loss: 0.2555 - accuracy: 0.5856 - val_loss: 0.7718 - val_accuracy: 0.7778\n",
            "2/2 [==============================] - 2s 125ms/step - loss: 0.1041 - accuracy: 0.9412\n",
            "Epoch 1/100\n",
            "28/28 [==============================] - 18s 430ms/step - loss: 0.5336 - accuracy: 0.4816 - val_loss: 0.1027 - val_accuracy: 1.0000\n",
            "Epoch 2/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.4250 - accuracy: 0.5402 - val_loss: 0.2857 - val_accuracy: 0.9259\n",
            "Epoch 3/100\n",
            "28/28 [==============================] - 11s 382ms/step - loss: 0.3901 - accuracy: 0.5609 - val_loss: 0.0802 - val_accuracy: 1.0000\n",
            "Epoch 4/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.3626 - accuracy: 0.5736 - val_loss: 0.1222 - val_accuracy: 0.9630\n",
            "Epoch 5/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.3452 - accuracy: 0.5724 - val_loss: 0.1210 - val_accuracy: 0.9630\n",
            "Epoch 6/100\n",
            "28/28 [==============================] - 11s 378ms/step - loss: 0.3196 - accuracy: 0.5793 - val_loss: 0.0990 - val_accuracy: 1.0000\n",
            "Epoch 7/100\n",
            "28/28 [==============================] - 11s 378ms/step - loss: 0.3167 - accuracy: 0.5805 - val_loss: 0.1239 - val_accuracy: 0.9630\n",
            "Epoch 8/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.3088 - accuracy: 0.5828 - val_loss: 0.1129 - val_accuracy: 0.9630\n",
            "Epoch 9/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.3126 - accuracy: 0.5793 - val_loss: 0.0965 - val_accuracy: 0.9630\n",
            "Epoch 10/100\n",
            "28/28 [==============================] - 11s 382ms/step - loss: 0.3007 - accuracy: 0.5828 - val_loss: 0.0739 - val_accuracy: 1.0000\n",
            "Epoch 11/100\n",
            "28/28 [==============================] - 11s 378ms/step - loss: 0.2955 - accuracy: 0.5828 - val_loss: 0.0931 - val_accuracy: 1.0000\n",
            "Epoch 12/100\n",
            "28/28 [==============================] - 11s 383ms/step - loss: 0.2956 - accuracy: 0.5851 - val_loss: 0.0623 - val_accuracy: 1.0000\n",
            "Epoch 13/100\n",
            "28/28 [==============================] - 11s 381ms/step - loss: 0.2930 - accuracy: 0.5851 - val_loss: 0.0953 - val_accuracy: 1.0000\n",
            "Epoch 14/100\n",
            "28/28 [==============================] - 11s 381ms/step - loss: 0.2873 - accuracy: 0.5862 - val_loss: 0.0794 - val_accuracy: 0.9630\n",
            "Epoch 15/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.2961 - accuracy: 0.5851 - val_loss: 0.0948 - val_accuracy: 0.9630\n",
            "Epoch 16/100\n",
            "28/28 [==============================] - 11s 379ms/step - loss: 0.2823 - accuracy: 0.5851 - val_loss: 0.1153 - val_accuracy: 0.9630\n",
            "Epoch 17/100\n",
            "28/28 [==============================] - 11s 379ms/step - loss: 0.2812 - accuracy: 0.5851 - val_loss: 0.0627 - val_accuracy: 0.9630\n",
            "Epoch 18/100\n",
            "28/28 [==============================] - 11s 381ms/step - loss: 0.2807 - accuracy: 0.5839 - val_loss: 0.0569 - val_accuracy: 1.0000\n",
            "Epoch 19/100\n",
            "28/28 [==============================] - 11s 381ms/step - loss: 0.2740 - accuracy: 0.5851 - val_loss: 0.1688 - val_accuracy: 0.9630\n",
            "Epoch 20/100\n",
            "28/28 [==============================] - 11s 381ms/step - loss: 0.2784 - accuracy: 0.5862 - val_loss: 0.0480 - val_accuracy: 1.0000\n",
            "Epoch 21/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.2759 - accuracy: 0.5862 - val_loss: 0.0815 - val_accuracy: 1.0000\n",
            "Epoch 22/100\n",
            "28/28 [==============================] - 11s 381ms/step - loss: 0.2774 - accuracy: 0.5862 - val_loss: 0.0468 - val_accuracy: 1.0000\n",
            "Epoch 23/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.2754 - accuracy: 0.5862 - val_loss: 0.0559 - val_accuracy: 1.0000\n",
            "Epoch 24/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.2680 - accuracy: 0.5862 - val_loss: 0.0515 - val_accuracy: 1.0000\n",
            "Epoch 25/100\n",
            "28/28 [==============================] - 11s 381ms/step - loss: 0.2840 - accuracy: 0.5851 - val_loss: 0.0544 - val_accuracy: 1.0000\n",
            "Epoch 26/100\n",
            "28/28 [==============================] - 11s 379ms/step - loss: 0.2645 - accuracy: 0.5862 - val_loss: 0.0524 - val_accuracy: 1.0000\n",
            "Epoch 27/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.2798 - accuracy: 0.5862 - val_loss: 0.0493 - val_accuracy: 1.0000\n",
            "Epoch 28/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.2607 - accuracy: 0.5862 - val_loss: 0.0532 - val_accuracy: 1.0000\n",
            "Epoch 29/100\n",
            "28/28 [==============================] - 11s 379ms/step - loss: 0.2710 - accuracy: 0.5839 - val_loss: 0.0602 - val_accuracy: 1.0000\n",
            "Epoch 30/100\n",
            "28/28 [==============================] - 11s 382ms/step - loss: 0.2649 - accuracy: 0.5851 - val_loss: 0.0468 - val_accuracy: 1.0000\n",
            "Epoch 31/100\n",
            "28/28 [==============================] - 11s 381ms/step - loss: 0.2728 - accuracy: 0.5862 - val_loss: 0.0559 - val_accuracy: 0.9630\n",
            "Epoch 32/100\n",
            "28/28 [==============================] - 11s 381ms/step - loss: 0.2567 - accuracy: 0.5851 - val_loss: 0.0924 - val_accuracy: 0.9630\n",
            "Epoch 33/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.2649 - accuracy: 0.5862 - val_loss: 0.0509 - val_accuracy: 1.0000\n",
            "Epoch 34/100\n",
            "28/28 [==============================] - 11s 381ms/step - loss: 0.2651 - accuracy: 0.5862 - val_loss: 0.0447 - val_accuracy: 1.0000\n",
            "Epoch 35/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.2643 - accuracy: 0.5862 - val_loss: 0.0529 - val_accuracy: 1.0000\n",
            "Epoch 36/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.2674 - accuracy: 0.5862 - val_loss: 0.0797 - val_accuracy: 0.9630\n",
            "Epoch 37/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.2700 - accuracy: 0.5862 - val_loss: 0.0729 - val_accuracy: 0.9630\n",
            "Epoch 38/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.2701 - accuracy: 0.5862 - val_loss: 0.0618 - val_accuracy: 0.9630\n",
            "Epoch 39/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.2657 - accuracy: 0.5851 - val_loss: 0.0443 - val_accuracy: 1.0000\n",
            "Epoch 40/100\n",
            "28/28 [==============================] - 11s 379ms/step - loss: 0.2613 - accuracy: 0.5862 - val_loss: 0.0571 - val_accuracy: 1.0000\n",
            "Epoch 41/100\n",
            "28/28 [==============================] - 11s 378ms/step - loss: 0.2624 - accuracy: 0.5862 - val_loss: 0.0508 - val_accuracy: 1.0000\n",
            "Epoch 42/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.2580 - accuracy: 0.5862 - val_loss: 0.0490 - val_accuracy: 1.0000\n",
            "Epoch 43/100\n",
            "28/28 [==============================] - 11s 381ms/step - loss: 0.2586 - accuracy: 0.5862 - val_loss: 0.0520 - val_accuracy: 1.0000\n",
            "Epoch 44/100\n",
            "28/28 [==============================] - 11s 379ms/step - loss: 0.2556 - accuracy: 0.5862 - val_loss: 0.0902 - val_accuracy: 0.9630\n",
            "Epoch 45/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.2584 - accuracy: 0.5862 - val_loss: 0.0694 - val_accuracy: 0.9630\n",
            "Epoch 46/100\n",
            "28/28 [==============================] - 11s 379ms/step - loss: 0.2571 - accuracy: 0.5862 - val_loss: 0.0924 - val_accuracy: 0.9630\n",
            "Epoch 47/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2568 - accuracy: 0.5862 - val_loss: 0.0608 - val_accuracy: 1.0000\n",
            "Epoch 48/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.2602 - accuracy: 0.5862 - val_loss: 0.0309 - val_accuracy: 1.0000\n",
            "Epoch 49/100\n",
            "28/28 [==============================] - 11s 379ms/step - loss: 0.2674 - accuracy: 0.5862 - val_loss: 0.0538 - val_accuracy: 0.9630\n",
            "Epoch 50/100\n",
            "28/28 [==============================] - 11s 381ms/step - loss: 0.2606 - accuracy: 0.5862 - val_loss: 0.0851 - val_accuracy: 0.9630\n",
            "Epoch 51/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.2560 - accuracy: 0.5862 - val_loss: 0.0723 - val_accuracy: 0.9630\n",
            "Epoch 52/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.2605 - accuracy: 0.5862 - val_loss: 0.0589 - val_accuracy: 0.9630\n",
            "Epoch 53/100\n",
            "28/28 [==============================] - 11s 379ms/step - loss: 0.2573 - accuracy: 0.5862 - val_loss: 0.0688 - val_accuracy: 0.9630\n",
            "Epoch 54/100\n",
            "28/28 [==============================] - 11s 381ms/step - loss: 0.2556 - accuracy: 0.5862 - val_loss: 0.0306 - val_accuracy: 1.0000\n",
            "Epoch 55/100\n",
            "28/28 [==============================] - 11s 378ms/step - loss: 0.2607 - accuracy: 0.5851 - val_loss: 0.0583 - val_accuracy: 1.0000\n",
            "Epoch 56/100\n",
            "28/28 [==============================] - 11s 379ms/step - loss: 0.2527 - accuracy: 0.5862 - val_loss: 0.0580 - val_accuracy: 0.9630\n",
            "Epoch 57/100\n",
            "28/28 [==============================] - 11s 378ms/step - loss: 0.2537 - accuracy: 0.5862 - val_loss: 0.0654 - val_accuracy: 1.0000\n",
            "Epoch 58/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.2687 - accuracy: 0.5862 - val_loss: 0.0653 - val_accuracy: 0.9630\n",
            "Epoch 59/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.2563 - accuracy: 0.5862 - val_loss: 0.0967 - val_accuracy: 0.9630\n",
            "Epoch 60/100\n",
            "28/28 [==============================] - 11s 379ms/step - loss: 0.2576 - accuracy: 0.5862 - val_loss: 0.0713 - val_accuracy: 0.9630\n",
            "Epoch 61/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.2525 - accuracy: 0.5862 - val_loss: 0.1105 - val_accuracy: 0.9630\n",
            "Epoch 62/100\n",
            "28/28 [==============================] - 11s 379ms/step - loss: 0.2498 - accuracy: 0.5862 - val_loss: 0.0686 - val_accuracy: 1.0000\n",
            "Epoch 63/100\n",
            "28/28 [==============================] - 11s 378ms/step - loss: 0.2581 - accuracy: 0.5862 - val_loss: 0.1102 - val_accuracy: 0.9630\n",
            "Epoch 64/100\n",
            "28/28 [==============================] - 11s 379ms/step - loss: 0.2586 - accuracy: 0.5851 - val_loss: 0.1054 - val_accuracy: 0.9630\n",
            "Epoch 65/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.2529 - accuracy: 0.5862 - val_loss: 0.0736 - val_accuracy: 0.9630\n",
            "Epoch 66/100\n",
            "28/28 [==============================] - 11s 378ms/step - loss: 0.2522 - accuracy: 0.5862 - val_loss: 0.0625 - val_accuracy: 0.9630\n",
            "Epoch 67/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.2475 - accuracy: 0.5862 - val_loss: 0.0717 - val_accuracy: 0.9630\n",
            "Epoch 68/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.2578 - accuracy: 0.5851 - val_loss: 0.0762 - val_accuracy: 0.9630\n",
            "Epoch 69/100\n",
            "28/28 [==============================] - 11s 383ms/step - loss: 0.2596 - accuracy: 0.5862 - val_loss: 0.0714 - val_accuracy: 1.0000\n",
            "2/2 [==============================] - 2s 127ms/step - loss: 0.0991 - accuracy: 0.9706\n",
            "[0.9588235139846801, 0.9470588088035583, 0.9647058725357056, 0.9588235139846801]\n",
            "[0.9507813140511734, 0.9385649310603057, 0.958319725121037, 0.9507813140511734]\n",
            "Epoch 1/100\n",
            "27/27 [==============================] - 18s 436ms/step - loss: 0.4603 - accuracy: 0.5387 - val_loss: 0.8895 - val_accuracy: 0.7037\n",
            "Epoch 2/100\n",
            "27/27 [==============================] - 10s 383ms/step - loss: 0.3623 - accuracy: 0.5786 - val_loss: 1.1755 - val_accuracy: 0.6667\n",
            "Epoch 3/100\n",
            "27/27 [==============================] - 10s 383ms/step - loss: 0.3689 - accuracy: 0.5728 - val_loss: 0.6154 - val_accuracy: 0.7037\n",
            "Epoch 4/100\n",
            "27/27 [==============================] - 10s 384ms/step - loss: 0.3226 - accuracy: 0.5845 - val_loss: 0.4212 - val_accuracy: 0.7778\n",
            "Epoch 5/100\n",
            "27/27 [==============================] - 10s 386ms/step - loss: 0.3118 - accuracy: 0.5915 - val_loss: 0.3344 - val_accuracy: 0.7778\n",
            "Epoch 6/100\n",
            "27/27 [==============================] - 10s 384ms/step - loss: 0.3072 - accuracy: 0.5939 - val_loss: 0.2737 - val_accuracy: 0.8519\n",
            "Epoch 7/100\n",
            "27/27 [==============================] - 10s 384ms/step - loss: 0.2876 - accuracy: 0.5962 - val_loss: 0.2734 - val_accuracy: 0.9259\n",
            "Epoch 8/100\n",
            "27/27 [==============================] - 10s 381ms/step - loss: 0.2968 - accuracy: 0.5962 - val_loss: 0.4680 - val_accuracy: 0.7778\n",
            "Epoch 9/100\n",
            "27/27 [==============================] - 10s 383ms/step - loss: 0.2935 - accuracy: 0.5939 - val_loss: 0.4115 - val_accuracy: 0.7778\n",
            "Epoch 10/100\n",
            "27/27 [==============================] - 10s 382ms/step - loss: 0.2855 - accuracy: 0.5951 - val_loss: 0.3312 - val_accuracy: 0.8519\n",
            "Epoch 11/100\n",
            "27/27 [==============================] - 10s 384ms/step - loss: 0.2809 - accuracy: 0.5939 - val_loss: 0.4435 - val_accuracy: 0.7778\n",
            "Epoch 12/100\n",
            "27/27 [==============================] - 10s 382ms/step - loss: 0.2802 - accuracy: 0.5962 - val_loss: 0.4580 - val_accuracy: 0.7778\n",
            "Epoch 13/100\n",
            "27/27 [==============================] - 10s 381ms/step - loss: 0.2658 - accuracy: 0.5962 - val_loss: 0.4079 - val_accuracy: 0.8148\n",
            "Epoch 14/100\n",
            "27/27 [==============================] - 10s 382ms/step - loss: 0.2712 - accuracy: 0.5962 - val_loss: 0.3183 - val_accuracy: 0.8148\n",
            "Epoch 15/100\n",
            "27/27 [==============================] - 10s 382ms/step - loss: 0.2654 - accuracy: 0.5951 - val_loss: 0.3605 - val_accuracy: 0.8148\n",
            "Epoch 16/100\n",
            "27/27 [==============================] - 10s 383ms/step - loss: 0.2666 - accuracy: 0.5962 - val_loss: 0.3880 - val_accuracy: 0.8148\n",
            "Epoch 17/100\n",
            "27/27 [==============================] - 10s 381ms/step - loss: 0.2700 - accuracy: 0.5951 - val_loss: 0.4558 - val_accuracy: 0.8148\n",
            "Epoch 18/100\n",
            "27/27 [==============================] - 10s 380ms/step - loss: 0.2602 - accuracy: 0.5962 - val_loss: 0.3606 - val_accuracy: 0.8519\n",
            "Epoch 19/100\n",
            "27/27 [==============================] - 10s 382ms/step - loss: 0.2580 - accuracy: 0.5962 - val_loss: 0.4347 - val_accuracy: 0.8519\n",
            "Epoch 20/100\n",
            "27/27 [==============================] - 10s 381ms/step - loss: 0.2600 - accuracy: 0.5962 - val_loss: 0.4605 - val_accuracy: 0.7778\n",
            "Epoch 21/100\n",
            "27/27 [==============================] - 10s 382ms/step - loss: 0.2603 - accuracy: 0.5962 - val_loss: 0.5568 - val_accuracy: 0.7778\n",
            "Epoch 22/100\n",
            "27/27 [==============================] - 10s 382ms/step - loss: 0.2561 - accuracy: 0.5951 - val_loss: 0.3618 - val_accuracy: 0.8148\n",
            "2/2 [==============================] - 2s 124ms/step - loss: 0.2174 - accuracy: 0.9412\n",
            "Epoch 1/100\n",
            "28/28 [==============================] - 18s 433ms/step - loss: 0.4783 - accuracy: 0.5282 - val_loss: 0.2335 - val_accuracy: 0.9259\n",
            "Epoch 2/100\n",
            "28/28 [==============================] - 11s 384ms/step - loss: 0.3762 - accuracy: 0.5755 - val_loss: 0.1576 - val_accuracy: 0.8889\n",
            "Epoch 3/100\n",
            "28/28 [==============================] - 11s 381ms/step - loss: 0.3865 - accuracy: 0.5788 - val_loss: 0.2299 - val_accuracy: 1.0000\n",
            "Epoch 4/100\n",
            "28/28 [==============================] - 11s 386ms/step - loss: 0.3459 - accuracy: 0.5788 - val_loss: 0.1298 - val_accuracy: 1.0000\n",
            "Epoch 5/100\n",
            "28/28 [==============================] - 11s 385ms/step - loss: 0.3236 - accuracy: 0.5901 - val_loss: 0.2376 - val_accuracy: 0.8889\n",
            "Epoch 6/100\n",
            "28/28 [==============================] - 11s 383ms/step - loss: 0.3197 - accuracy: 0.5912 - val_loss: 0.6623 - val_accuracy: 0.6667\n",
            "Epoch 7/100\n",
            "28/28 [==============================] - 11s 384ms/step - loss: 0.3116 - accuracy: 0.5980 - val_loss: 0.3467 - val_accuracy: 0.8519\n",
            "Epoch 8/100\n",
            "28/28 [==============================] - 11s 381ms/step - loss: 0.3013 - accuracy: 0.5968 - val_loss: 0.1921 - val_accuracy: 1.0000\n",
            "Epoch 9/100\n",
            "28/28 [==============================] - 11s 384ms/step - loss: 0.2925 - accuracy: 0.5968 - val_loss: 0.2239 - val_accuracy: 0.8519\n",
            "Epoch 10/100\n",
            "28/28 [==============================] - 11s 382ms/step - loss: 0.2970 - accuracy: 0.5968 - val_loss: 0.1955 - val_accuracy: 0.9259\n",
            "Epoch 11/100\n",
            "28/28 [==============================] - 11s 381ms/step - loss: 0.2796 - accuracy: 0.6002 - val_loss: 0.3597 - val_accuracy: 0.8148\n",
            "Epoch 12/100\n",
            "28/28 [==============================] - 11s 381ms/step - loss: 0.2881 - accuracy: 0.6002 - val_loss: 0.4859 - val_accuracy: 0.7778\n",
            "Epoch 13/100\n",
            "28/28 [==============================] - 11s 382ms/step - loss: 0.2817 - accuracy: 0.6014 - val_loss: 0.5287 - val_accuracy: 0.7407\n",
            "Epoch 14/100\n",
            "28/28 [==============================] - 11s 383ms/step - loss: 0.2842 - accuracy: 0.6002 - val_loss: 0.2019 - val_accuracy: 0.9259\n",
            "Epoch 15/100\n",
            "28/28 [==============================] - 11s 381ms/step - loss: 0.2675 - accuracy: 0.5991 - val_loss: 0.2229 - val_accuracy: 0.8889\n",
            "Epoch 16/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.2810 - accuracy: 0.6014 - val_loss: 0.1814 - val_accuracy: 0.9259\n",
            "Epoch 17/100\n",
            "28/28 [==============================] - 11s 380ms/step - loss: 0.2881 - accuracy: 0.5991 - val_loss: 0.1982 - val_accuracy: 0.8889\n",
            "Epoch 18/100\n",
            "28/28 [==============================] - 11s 379ms/step - loss: 0.2678 - accuracy: 0.6014 - val_loss: 0.1779 - val_accuracy: 0.8889\n",
            "Epoch 19/100\n",
            "28/28 [==============================] - 11s 379ms/step - loss: 0.2713 - accuracy: 0.6014 - val_loss: 0.1842 - val_accuracy: 0.8889\n",
            "2/2 [==============================] - 2s 115ms/step - loss: 0.1328 - accuracy: 0.9706\n",
            "Epoch 1/100\n",
            "27/27 [==============================] - 18s 434ms/step - loss: 0.4972 - accuracy: 0.5188 - val_loss: 0.2048 - val_accuracy: 0.8519\n",
            "Epoch 2/100\n",
            "27/27 [==============================] - 10s 379ms/step - loss: 0.3834 - accuracy: 0.5704 - val_loss: 0.1253 - val_accuracy: 1.0000\n",
            "Epoch 3/100\n",
            "27/27 [==============================] - 10s 379ms/step - loss: 0.3572 - accuracy: 0.5822 - val_loss: 0.1856 - val_accuracy: 0.9259\n",
            "Epoch 4/100\n",
            "27/27 [==============================] - 10s 380ms/step - loss: 0.3425 - accuracy: 0.5810 - val_loss: 0.3116 - val_accuracy: 0.8148\n",
            "Epoch 5/100\n",
            "27/27 [==============================] - 10s 380ms/step - loss: 0.3204 - accuracy: 0.5927 - val_loss: 0.1799 - val_accuracy: 0.9630\n",
            "Epoch 6/100\n",
            "27/27 [==============================] - 10s 381ms/step - loss: 0.3023 - accuracy: 0.5962 - val_loss: 0.2090 - val_accuracy: 0.9259\n",
            "Epoch 7/100\n",
            "27/27 [==============================] - 10s 377ms/step - loss: 0.3120 - accuracy: 0.5892 - val_loss: 0.3420 - val_accuracy: 0.9259\n",
            "Epoch 8/100\n",
            "27/27 [==============================] - 10s 379ms/step - loss: 0.3021 - accuracy: 0.5951 - val_loss: 0.2250 - val_accuracy: 0.9259\n",
            "Epoch 9/100\n",
            "27/27 [==============================] - 10s 380ms/step - loss: 0.2927 - accuracy: 0.5986 - val_loss: 0.1690 - val_accuracy: 0.9630\n",
            "Epoch 10/100\n",
            "27/27 [==============================] - 10s 381ms/step - loss: 0.2942 - accuracy: 0.6009 - val_loss: 0.2565 - val_accuracy: 0.8889\n",
            "Epoch 11/100\n",
            "27/27 [==============================] - 10s 379ms/step - loss: 0.2944 - accuracy: 0.5962 - val_loss: 0.3156 - val_accuracy: 0.8889\n",
            "Epoch 12/100\n",
            "27/27 [==============================] - 10s 383ms/step - loss: 0.2841 - accuracy: 0.5998 - val_loss: 0.1003 - val_accuracy: 0.9630\n",
            "Epoch 13/100\n",
            "27/27 [==============================] - 10s 379ms/step - loss: 0.2761 - accuracy: 0.6009 - val_loss: 0.3794 - val_accuracy: 0.8519\n",
            "Epoch 14/100\n",
            "27/27 [==============================] - 10s 383ms/step - loss: 0.2770 - accuracy: 0.5998 - val_loss: 0.2018 - val_accuracy: 0.8889\n",
            "Epoch 15/100\n",
            "27/27 [==============================] - 10s 380ms/step - loss: 0.2730 - accuracy: 0.5998 - val_loss: 0.1460 - val_accuracy: 0.9259\n",
            "Epoch 16/100\n",
            "27/27 [==============================] - 10s 383ms/step - loss: 0.2669 - accuracy: 0.6009 - val_loss: 0.1861 - val_accuracy: 0.9259\n",
            "Epoch 17/100\n",
            "27/27 [==============================] - 10s 382ms/step - loss: 0.2743 - accuracy: 0.6009 - val_loss: 0.1374 - val_accuracy: 0.9259\n",
            "Epoch 18/100\n",
            "27/27 [==============================] - 10s 383ms/step - loss: 0.2667 - accuracy: 0.6009 - val_loss: 0.1441 - val_accuracy: 0.9259\n",
            "Epoch 19/100\n",
            "27/27 [==============================] - 10s 384ms/step - loss: 0.2704 - accuracy: 0.5998 - val_loss: 0.0881 - val_accuracy: 0.9630\n",
            "Epoch 20/100\n",
            "27/27 [==============================] - 10s 383ms/step - loss: 0.2723 - accuracy: 0.6009 - val_loss: 0.0620 - val_accuracy: 1.0000\n",
            "Epoch 21/100\n",
            "27/27 [==============================] - 10s 385ms/step - loss: 0.2672 - accuracy: 0.5998 - val_loss: 0.0474 - val_accuracy: 1.0000\n",
            "Epoch 22/100\n",
            "27/27 [==============================] - 10s 380ms/step - loss: 0.2694 - accuracy: 0.5998 - val_loss: 0.0733 - val_accuracy: 0.9630\n",
            "Epoch 23/100\n",
            "27/27 [==============================] - 10s 382ms/step - loss: 0.2600 - accuracy: 0.6009 - val_loss: 0.0410 - val_accuracy: 1.0000\n",
            "Epoch 24/100\n",
            "27/27 [==============================] - 10s 380ms/step - loss: 0.2599 - accuracy: 0.6009 - val_loss: 0.0555 - val_accuracy: 0.9630\n",
            "Epoch 25/100\n",
            "27/27 [==============================] - 10s 379ms/step - loss: 0.2551 - accuracy: 0.6009 - val_loss: 0.0485 - val_accuracy: 1.0000\n",
            "Epoch 26/100\n",
            "27/27 [==============================] - 10s 377ms/step - loss: 0.2581 - accuracy: 0.5998 - val_loss: 0.0728 - val_accuracy: 0.9630\n",
            "Epoch 27/100\n",
            "27/27 [==============================] - 10s 380ms/step - loss: 0.2566 - accuracy: 0.6009 - val_loss: 0.0727 - val_accuracy: 1.0000\n",
            "Epoch 28/100\n",
            "27/27 [==============================] - 10s 375ms/step - loss: 0.2546 - accuracy: 0.6009 - val_loss: 0.0680 - val_accuracy: 1.0000\n",
            "Epoch 29/100\n",
            "27/27 [==============================] - 10s 374ms/step - loss: 0.2614 - accuracy: 0.5998 - val_loss: 0.0482 - val_accuracy: 1.0000\n",
            "Epoch 30/100\n",
            "27/27 [==============================] - 10s 376ms/step - loss: 0.2518 - accuracy: 0.6009 - val_loss: 0.0719 - val_accuracy: 1.0000\n",
            "Epoch 31/100\n",
            "27/27 [==============================] - 10s 376ms/step - loss: 0.2488 - accuracy: 0.6009 - val_loss: 0.0738 - val_accuracy: 0.9630\n",
            "Epoch 32/100\n",
            "27/27 [==============================] - 10s 376ms/step - loss: 0.2602 - accuracy: 0.6009 - val_loss: 0.0750 - val_accuracy: 0.9630\n",
            "Epoch 33/100\n",
            "27/27 [==============================] - 10s 375ms/step - loss: 0.2605 - accuracy: 0.6009 - val_loss: 0.0541 - val_accuracy: 1.0000\n",
            "Epoch 34/100\n",
            "27/27 [==============================] - 10s 376ms/step - loss: 0.2548 - accuracy: 0.6009 - val_loss: 0.0769 - val_accuracy: 0.9630\n",
            "Epoch 35/100\n",
            "27/27 [==============================] - 10s 378ms/step - loss: 0.2539 - accuracy: 0.6009 - val_loss: 0.0875 - val_accuracy: 0.9630\n",
            "Epoch 36/100\n",
            "27/27 [==============================] - 10s 377ms/step - loss: 0.2562 - accuracy: 0.6009 - val_loss: 0.0687 - val_accuracy: 0.9630\n",
            "Epoch 37/100\n",
            "27/27 [==============================] - 10s 376ms/step - loss: 0.2442 - accuracy: 0.6009 - val_loss: 0.0950 - val_accuracy: 0.9630\n",
            "Epoch 38/100\n",
            "27/27 [==============================] - 10s 378ms/step - loss: 0.2473 - accuracy: 0.6009 - val_loss: 0.0769 - val_accuracy: 0.9630\n",
            "2/2 [==============================] - 2s 123ms/step - loss: 0.1153 - accuracy: 0.9706\n",
            "Epoch 1/100\n",
            "28/28 [==============================] - 18s 428ms/step - loss: 0.5387 - accuracy: 0.4909 - val_loss: 0.7749 - val_accuracy: 0.7407\n",
            "Epoch 2/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.4023 - accuracy: 0.5582 - val_loss: 0.5843 - val_accuracy: 0.7778\n",
            "Epoch 3/100\n",
            "28/28 [==============================] - 10s 375ms/step - loss: 0.3613 - accuracy: 0.5605 - val_loss: 0.4529 - val_accuracy: 0.8148\n",
            "Epoch 4/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.3673 - accuracy: 0.5696 - val_loss: 0.4215 - val_accuracy: 0.8148\n",
            "Epoch 5/100\n",
            "28/28 [==============================] - 10s 374ms/step - loss: 0.3310 - accuracy: 0.5822 - val_loss: 0.4992 - val_accuracy: 0.8148\n",
            "Epoch 6/100\n",
            "28/28 [==============================] - 10s 375ms/step - loss: 0.3293 - accuracy: 0.5765 - val_loss: 0.3589 - val_accuracy: 0.8889\n",
            "Epoch 7/100\n",
            "28/28 [==============================] - 10s 376ms/step - loss: 0.3065 - accuracy: 0.5845 - val_loss: 0.3350 - val_accuracy: 0.8889\n",
            "Epoch 8/100\n",
            "28/28 [==============================] - 10s 375ms/step - loss: 0.2987 - accuracy: 0.5868 - val_loss: 0.3879 - val_accuracy: 0.8519\n",
            "Epoch 9/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.3114 - accuracy: 0.5845 - val_loss: 0.3175 - val_accuracy: 0.8889\n",
            "Epoch 10/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.2900 - accuracy: 0.5879 - val_loss: 0.2424 - val_accuracy: 0.8889\n",
            "Epoch 11/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2992 - accuracy: 0.5845 - val_loss: 0.1556 - val_accuracy: 0.9630\n",
            "Epoch 12/100\n",
            "28/28 [==============================] - 10s 374ms/step - loss: 0.2924 - accuracy: 0.5890 - val_loss: 0.1705 - val_accuracy: 0.9259\n",
            "Epoch 13/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.2934 - accuracy: 0.5890 - val_loss: 0.1073 - val_accuracy: 1.0000\n",
            "Epoch 14/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2817 - accuracy: 0.5879 - val_loss: 0.2446 - val_accuracy: 0.8889\n",
            "Epoch 15/100\n",
            "28/28 [==============================] - 10s 374ms/step - loss: 0.2827 - accuracy: 0.5879 - val_loss: 0.2711 - val_accuracy: 0.8889\n",
            "Epoch 16/100\n",
            "28/28 [==============================] - 11s 377ms/step - loss: 0.2694 - accuracy: 0.5890 - val_loss: 0.1829 - val_accuracy: 0.8889\n",
            "Epoch 17/100\n",
            "28/28 [==============================] - 11s 375ms/step - loss: 0.2844 - accuracy: 0.5868 - val_loss: 0.1430 - val_accuracy: 0.9630\n",
            "Epoch 18/100\n",
            "28/28 [==============================] - 10s 374ms/step - loss: 0.2759 - accuracy: 0.5879 - val_loss: 0.1664 - val_accuracy: 0.9259\n",
            "Epoch 19/100\n",
            "28/28 [==============================] - 10s 374ms/step - loss: 0.2689 - accuracy: 0.5890 - val_loss: 0.1748 - val_accuracy: 0.9630\n",
            "Epoch 20/100\n",
            "28/28 [==============================] - 10s 374ms/step - loss: 0.2760 - accuracy: 0.5868 - val_loss: 0.1816 - val_accuracy: 0.9259\n",
            "Epoch 21/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2673 - accuracy: 0.5890 - val_loss: 0.2095 - val_accuracy: 0.8889\n",
            "Epoch 22/100\n",
            "28/28 [==============================] - 10s 374ms/step - loss: 0.2712 - accuracy: 0.5890 - val_loss: 0.2285 - val_accuracy: 0.8889\n",
            "Epoch 23/100\n",
            "28/28 [==============================] - 10s 373ms/step - loss: 0.2632 - accuracy: 0.5890 - val_loss: 0.2382 - val_accuracy: 0.8889\n",
            "Epoch 24/100\n",
            "28/28 [==============================] - 10s 374ms/step - loss: 0.2791 - accuracy: 0.5845 - val_loss: 0.1687 - val_accuracy: 0.8889\n",
            "Epoch 25/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2710 - accuracy: 0.5890 - val_loss: 0.2568 - val_accuracy: 0.8889\n",
            "Epoch 26/100\n",
            "28/28 [==============================] - 10s 373ms/step - loss: 0.2593 - accuracy: 0.5890 - val_loss: 0.2347 - val_accuracy: 0.8889\n",
            "Epoch 27/100\n",
            "28/28 [==============================] - 10s 375ms/step - loss: 0.2663 - accuracy: 0.5856 - val_loss: 0.2943 - val_accuracy: 0.8889\n",
            "Epoch 28/100\n",
            "28/28 [==============================] - 10s 375ms/step - loss: 0.2696 - accuracy: 0.5890 - val_loss: 0.1004 - val_accuracy: 0.9630\n",
            "Epoch 29/100\n",
            "28/28 [==============================] - 10s 375ms/step - loss: 0.2639 - accuracy: 0.5890 - val_loss: 0.1285 - val_accuracy: 0.9630\n",
            "Epoch 30/100\n",
            "28/28 [==============================] - 11s 378ms/step - loss: 0.2557 - accuracy: 0.5890 - val_loss: 0.1494 - val_accuracy: 0.9630\n",
            "Epoch 31/100\n",
            "28/28 [==============================] - 11s 375ms/step - loss: 0.2635 - accuracy: 0.5879 - val_loss: 0.1679 - val_accuracy: 0.9630\n",
            "Epoch 32/100\n",
            "28/28 [==============================] - 10s 374ms/step - loss: 0.2564 - accuracy: 0.5890 - val_loss: 0.1311 - val_accuracy: 0.9630\n",
            "Epoch 33/100\n",
            "28/28 [==============================] - 10s 374ms/step - loss: 0.2563 - accuracy: 0.5890 - val_loss: 0.1218 - val_accuracy: 0.9630\n",
            "Epoch 34/100\n",
            "28/28 [==============================] - 11s 375ms/step - loss: 0.2603 - accuracy: 0.5879 - val_loss: 0.1150 - val_accuracy: 0.9630\n",
            "Epoch 35/100\n",
            "28/28 [==============================] - 10s 375ms/step - loss: 0.2663 - accuracy: 0.5890 - val_loss: 0.1498 - val_accuracy: 0.9630\n",
            "Epoch 36/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2520 - accuracy: 0.5890 - val_loss: 0.1405 - val_accuracy: 0.9630\n",
            "Epoch 37/100\n",
            "28/28 [==============================] - 10s 375ms/step - loss: 0.2557 - accuracy: 0.5890 - val_loss: 0.1638 - val_accuracy: 0.9630\n",
            "Epoch 38/100\n",
            "28/28 [==============================] - 10s 374ms/step - loss: 0.2572 - accuracy: 0.5890 - val_loss: 0.1034 - val_accuracy: 0.9630\n",
            "Epoch 39/100\n",
            "28/28 [==============================] - 10s 374ms/step - loss: 0.2548 - accuracy: 0.5890 - val_loss: 0.1234 - val_accuracy: 0.9630\n",
            "Epoch 40/100\n",
            "28/28 [==============================] - 11s 376ms/step - loss: 0.2577 - accuracy: 0.5890 - val_loss: 0.2589 - val_accuracy: 0.8889\n",
            "Epoch 41/100\n",
            "28/28 [==============================] - 10s 375ms/step - loss: 0.2587 - accuracy: 0.5890 - val_loss: 0.1817 - val_accuracy: 0.8889\n",
            "Epoch 42/100\n",
            "28/28 [==============================] - 10s 374ms/step - loss: 0.2554 - accuracy: 0.5890 - val_loss: 0.1830 - val_accuracy: 0.8889\n",
            "Epoch 43/100\n",
            "28/28 [==============================] - 11s 375ms/step - loss: 0.2543 - accuracy: 0.5890 - val_loss: 0.1789 - val_accuracy: 0.8889\n",
            "2/2 [==============================] - 2s 126ms/step - loss: 0.0793 - accuracy: 1.0000\n",
            "Epoch 1/100\n",
            "27/27 [==============================] - 17s 447ms/step - loss: 0.5209 - accuracy: 0.5150 - val_loss: 0.4808 - val_accuracy: 0.7778\n",
            "Epoch 2/100\n",
            "27/27 [==============================] - 10s 383ms/step - loss: 0.4040 - accuracy: 0.5637 - val_loss: 0.4600 - val_accuracy: 0.7778\n",
            "Epoch 3/100\n",
            "27/27 [==============================] - 10s 386ms/step - loss: 0.3796 - accuracy: 0.5741 - val_loss: 0.3230 - val_accuracy: 0.8519\n",
            "Epoch 4/100\n",
            "27/27 [==============================] - 10s 385ms/step - loss: 0.3433 - accuracy: 0.5856 - val_loss: 0.1367 - val_accuracy: 0.9630\n",
            "Epoch 5/100\n",
            "27/27 [==============================] - 10s 384ms/step - loss: 0.3402 - accuracy: 0.5868 - val_loss: 0.1302 - val_accuracy: 1.0000\n",
            "Epoch 6/100\n",
            "27/27 [==============================] - 10s 385ms/step - loss: 0.3236 - accuracy: 0.5891 - val_loss: 0.1279 - val_accuracy: 1.0000\n",
            "Epoch 7/100\n",
            "27/27 [==============================] - 10s 386ms/step - loss: 0.3067 - accuracy: 0.5938 - val_loss: 0.0995 - val_accuracy: 1.0000\n",
            "Epoch 8/100\n",
            "27/27 [==============================] - 10s 379ms/step - loss: 0.2973 - accuracy: 0.5995 - val_loss: 0.1130 - val_accuracy: 1.0000\n",
            "Epoch 9/100\n",
            "27/27 [==============================] - 10s 382ms/step - loss: 0.3030 - accuracy: 0.5961 - val_loss: 0.1163 - val_accuracy: 0.9630\n",
            "Epoch 10/100\n",
            "27/27 [==============================] - 10s 382ms/step - loss: 0.2817 - accuracy: 0.6007 - val_loss: 0.1031 - val_accuracy: 1.0000\n",
            "Epoch 11/100\n",
            "27/27 [==============================] - 10s 383ms/step - loss: 0.2908 - accuracy: 0.5984 - val_loss: 0.0898 - val_accuracy: 1.0000\n",
            "Epoch 12/100\n",
            "27/27 [==============================] - 10s 383ms/step - loss: 0.2821 - accuracy: 0.5995 - val_loss: 0.0765 - val_accuracy: 1.0000\n",
            "Epoch 13/100\n",
            "27/27 [==============================] - 10s 381ms/step - loss: 0.2792 - accuracy: 0.6019 - val_loss: 0.0876 - val_accuracy: 1.0000\n",
            "Epoch 14/100\n",
            "27/27 [==============================] - 10s 383ms/step - loss: 0.2749 - accuracy: 0.5995 - val_loss: 0.1163 - val_accuracy: 0.9630\n",
            "Epoch 15/100\n",
            "27/27 [==============================] - 10s 380ms/step - loss: 0.2736 - accuracy: 0.6007 - val_loss: 0.1210 - val_accuracy: 0.9630\n",
            "Epoch 16/100\n",
            "27/27 [==============================] - 10s 381ms/step - loss: 0.2674 - accuracy: 0.6007 - val_loss: 0.1061 - val_accuracy: 1.0000\n",
            "Epoch 17/100\n",
            "27/27 [==============================] - 10s 381ms/step - loss: 0.2699 - accuracy: 0.6019 - val_loss: 0.1243 - val_accuracy: 0.9630\n",
            "Epoch 18/100\n",
            "27/27 [==============================] - 10s 382ms/step - loss: 0.2688 - accuracy: 0.6019 - val_loss: 0.0991 - val_accuracy: 1.0000\n",
            "Epoch 19/100\n",
            "27/27 [==============================] - 10s 382ms/step - loss: 0.2621 - accuracy: 0.6019 - val_loss: 0.0890 - val_accuracy: 1.0000\n",
            "Epoch 20/100\n",
            "27/27 [==============================] - 10s 383ms/step - loss: 0.2566 - accuracy: 0.6007 - val_loss: 0.0835 - val_accuracy: 1.0000\n",
            "Epoch 21/100\n",
            "27/27 [==============================] - 10s 381ms/step - loss: 0.2640 - accuracy: 0.6019 - val_loss: 0.1006 - val_accuracy: 1.0000\n",
            "Epoch 22/100\n",
            "27/27 [==============================] - 10s 381ms/step - loss: 0.2571 - accuracy: 0.6019 - val_loss: 0.1327 - val_accuracy: 0.9630\n",
            "Epoch 23/100\n",
            "27/27 [==============================] - 10s 384ms/step - loss: 0.2673 - accuracy: 0.6007 - val_loss: 0.0903 - val_accuracy: 1.0000\n",
            "Epoch 24/100\n",
            "27/27 [==============================] - 10s 383ms/step - loss: 0.2685 - accuracy: 0.6007 - val_loss: 0.1971 - val_accuracy: 0.9630\n",
            "Epoch 25/100\n",
            "27/27 [==============================] - 10s 382ms/step - loss: 0.2652 - accuracy: 0.6019 - val_loss: 0.2053 - val_accuracy: 0.8889\n",
            "Epoch 26/100\n",
            "27/27 [==============================] - 10s 382ms/step - loss: 0.2567 - accuracy: 0.6019 - val_loss: 0.1580 - val_accuracy: 0.9259\n",
            "Epoch 27/100\n",
            "27/27 [==============================] - 10s 381ms/step - loss: 0.2519 - accuracy: 0.6019 - val_loss: 0.2035 - val_accuracy: 0.9259\n",
            "2/2 [==============================] - 2s 126ms/step - loss: 0.1329 - accuracy: 0.9706\n",
            "[0.9588235139846801, 0.9470588088035583, 0.9647058725357056, 0.9588235139846801, 0.970588219165802]\n",
            "[0.9507813140511734, 0.9385649310603057, 0.958319725121037, 0.9507813140511734, 0.9664525191120935]\n",
            "Mean test accuracy is 0.960, mean test f1 score is 0.953, max test accuracy is 0.971, max test f1 score is 0.966, min test accuracy is 0.947, min test f1 score is 0.939, std of test accuracy is 0.008, std of test f1 score is 0.009\n",
            "Time elapsed through all process: 10502.753, sec\n"
          ]
        }
      ],
      "source": [
        "t = time.time()\n",
        "# ---------- Parameters ----------------\n",
        "augmentation_enable = True\n",
        "normalize_inputs_enable = True\n",
        "num_folds = 5\n",
        "kfold = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state = None) # random_state = 1 ile split run'dan run'a sabit.\n",
        "test_accuracy_per_run = []\n",
        "f1_score_per_run = []\n",
        "epoch_number = 100\n",
        "batch_size = 32\n",
        "dense_size = 64\n",
        "dropout_prob_dense = 0.5 # 0.\n",
        "repeat_of_mixup = 5\n",
        "number_of_repeat = 5\n",
        "unit_number_of_lstm = 8 #8 32\n",
        "dense_unit_of_range_doppler_function = 256 #128 512\n",
        "dense_unit_of_spectrogram_function = 8\n",
        "decoder_dense_unit = 256\n",
        "for repeat_run_number in range(number_of_repeat):\n",
        "  test_accuracy_per_fold = []\n",
        "  f1_score_per_fold = []\n",
        "  if repeat_run_number > 0:\n",
        "    del range_doppler_concat_shuffle_test\n",
        "    del spectrogram_concat_shuffle_test\n",
        "    del range_doppler_augmented_image\n",
        "    del range_doppler_concat_shuffle_train\n",
        "    del spectrogram_concat_shuffle_train\n",
        "    del spectrogram_augmented_image\n",
        "   \n",
        "  for randomlist_for_train_indx, randomlist_for_test_indx in kfold.split(range_doppler_concat_shuffle,range_doppler_concat_label_shuffle):   \n",
        "    gc.collect()\n",
        "    K.clear_session()\n",
        "    \n",
        "    # test data\n",
        "    range_doppler_concat_shuffle_test = range_doppler_concat_shuffle[randomlist_for_test_indx,:,:,:]\n",
        "    spectrogram_concat_shuffle_test = spectrogram_concat_shuffle[randomlist_for_test_indx,:,:,:]\n",
        "    range_doppler_concat_label_shuffle_test = range_doppler_concat_label_shuffle[randomlist_for_test_indx,:]\n",
        "    #train data\n",
        "    range_doppler_concat_shuffle_train = range_doppler_concat_shuffle[randomlist_for_train_indx,:,:,:]\n",
        "    spectrogram_concat_shuffle_train = spectrogram_concat_shuffle[randomlist_for_train_indx,:,:,:]\n",
        "    spectrogram_concat_label_shuffle_train = spectrogram_concat_label_shuffle[randomlist_for_train_indx,:]\n",
        "      # ---------------- MixUp Augmentation ----------------\n",
        "    (spectrogram_augmented_image,range_doppler_augmented_image,spectrogram_concat_label_shuffle_concat,\\\n",
        "     validation_spectrogram,validation_range_doppler, spectrogram_validation_labels)  =\\\n",
        "      split_and_augmentation_of_training(spectrogram_concat_shuffle_train,range_doppler_concat_shuffle_train,\\\n",
        "                                         spectrogram_concat_label_shuffle_train,\\\n",
        "                                         repeat_of_mixup, augmentation_enable)\n",
        "    \n",
        "    # ---------------- Neural Network Architecture ----------------\n",
        "\n",
        "\n",
        "\n",
        "    def lstm_encoder_network_1(input_shape):\n",
        "        input = Input(shape=input_shape)\n",
        "        x = Bidirectional(LSTM(unit_number_of_lstm, return_sequences=True, dropout = 0.5))(input)\n",
        "        x = Flatten()(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Dropout(0.5)(x)\n",
        "        x = Dense(dense_unit_of_range_doppler_function)(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Activation('LeakyReLU')(x)\n",
        "        x = Dropout(dropout_prob_dense)(x)\n",
        "        return Model(input, x)\n",
        "\n",
        "    def lstm_encoder_network_2(input_shape):\n",
        "        input = Input(shape=input_shape)\n",
        "        x = Bidirectional(LSTM(unit_number_of_lstm, return_sequences=True, dropout = 0.5))(input)\n",
        "        x = Flatten()(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Dropout(0.5)(x)\n",
        "        x = Dense(dense_unit_of_spectrogram_function)(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Activation('LeakyReLU')(x)\n",
        "        x = Dropout(dropout_prob_dense)(x)\n",
        "        return Model(input, x)\n",
        "\n",
        "    def decoder_for_concat(input_shape):\n",
        "      input = Input(shape=input_shape)\n",
        "      x = Dense(decoder_dense_unit)(input)\n",
        "      x = BatchNormalization()(x)\n",
        "      x = Activation('LeakyReLU')(x)\n",
        "      x = Dropout(0.3)(x)\n",
        "      x = Dense(dense_size)(x)\n",
        "      # x = BatchNormalization()(x)\n",
        "      x = Activation('LeakyReLU')(x)\n",
        "      x = Dropout(dropout_prob_dense)(x)\n",
        "      x = Dense(1, activation=\"sigmoid\")(x)\n",
        "      return Model(input, x)\n",
        "\n",
        "    input_shape = range_doppler_concat_shuffle.shape[1:3]\n",
        "    base_network_lstm = lstm_encoder_network_1(input_shape)\n",
        "    range_doppler_input  = Input(shape=input_shape)\n",
        "    processed_range_doppler  = base_network_lstm(range_doppler_input)\n",
        "\n",
        "    input_shape = spectrogram_concat_shuffle_train.shape[1:3]\n",
        "    base_network_lstm_2 = lstm_encoder_network_2(input_shape)\n",
        "    spectrogram_input  = Input(shape=input_shape)\n",
        "    processed_spectrogram  = base_network_lstm_2(spectrogram_input)\n",
        "\n",
        "    concat_layer = Concatenate()([processed_range_doppler, processed_spectrogram])\n",
        "\n",
        "    base_decoder_network = decoder_for_concat((concat_layer.shape[1]))\n",
        "    out = base_decoder_network(concat_layer)\n",
        "\n",
        "    model = Model(inputs=[range_doppler_input, spectrogram_input], outputs=[out]) \n",
        "    if repeat_run_number == 0:\n",
        "      print(base_network_lstm.summary())\n",
        "      print(base_network_lstm_2.summary())\n",
        "      print(base_decoder_network.summary())\n",
        "    # ---------------- Compile and Fit ----------------\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    earlyStopping = EarlyStopping(monitor='val_loss', patience=15, verbose=0,restore_best_weights=True, mode='min')\n",
        "    history = model.fit((range_doppler_augmented_image, spectrogram_augmented_image),(spectrogram_concat_label_shuffle_concat),\n",
        "                    epochs=epoch_number,\n",
        "                    batch_size=batch_size,\n",
        "                    shuffle = True,\n",
        "                    callbacks=[earlyStopping],\n",
        "                    validation_data = ((validation_range_doppler, validation_spectrogram) , (spectrogram_validation_labels)))\n",
        "    test_loss, test_accuracy  = model.evaluate([range_doppler_concat_shuffle_test, spectrogram_concat_shuffle_test],\\\n",
        "                                               [range_doppler_concat_label_shuffle_test],\n",
        "                  batch_size=batch_size)\n",
        "    gc.collect()\n",
        "    # ---------------- Get Test Results ----------------\n",
        "    y_test_predicted = model.predict((range_doppler_concat_shuffle_test, spectrogram_concat_shuffle_test), batch_size=batch_size)\n",
        "    # ----- Binarize y_test_predicted values -----\n",
        "    y_test_predicted_binary = np.zeros(y_test_predicted.size)\n",
        "    for ii in range(y_test_predicted.size):\n",
        "      if y_test_predicted[ii] < 0.5:\n",
        "        y_test_predicted_binary[ii] = 0\n",
        "      else:\n",
        "        y_test_predicted_binary[ii] = 1\n",
        "    \n",
        "    test_precision, test_recall, test_f1_score, support = precision_recall_fscore_support(range_doppler_concat_label_shuffle_test, y_test_predicted_binary, average='macro')\n",
        "\n",
        "    test_accuracy_per_fold.append(test_accuracy)\n",
        "    f1_score_per_fold.append(test_f1_score)\n",
        "    del model\n",
        "  test_accuracy_per_run.append(sum(test_accuracy_per_fold)/num_folds)\n",
        "  f1_score_per_run.append(sum(f1_score_per_fold)/num_folds)\n",
        "  print(test_accuracy_per_run)\n",
        "  print(f1_score_per_run)\n",
        "print(f'Mean test accuracy is {\"{:.3f}\".format(sum(test_accuracy_per_run)/number_of_repeat)}, mean test f1 score is {\"{:.3f}\".format(sum(f1_score_per_run)/number_of_repeat)}, \\\n",
        "max test accuracy is {\"{:.3f}\".format(max(test_accuracy_per_run))}, max test f1 score is {\"{:.3f}\".format(max(f1_score_per_run))}, \\\n",
        "min test accuracy is {\"{:.3f}\".format(min(test_accuracy_per_run))}, min test f1 score is {\"{:.3f}\".format(min(f1_score_per_run))}, \\\n",
        "std of test accuracy is {\"{:.3f}\".format(np.std(test_accuracy_per_run, axis=0))}, std of test f1 score is {\"{:.3f}\".format(np.std(f1_score_per_run, axis=0))}')\n",
        "elapsed = time.time() - t\n",
        "print(f'Time elapsed through all process: {\"{:.3f}\".format(elapsed)}, sec')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0N7v4PDP4Dv2",
        "outputId": "a6cd8318-6ecb-4c82-b847-e030da3ee403"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean test accuracy is 0.960, mean test f1 score is 0.953, max test accuracy is 0.971, max test f1 score is 0.966, min test accuracy is 0.947, min test f1 score is 0.939, std of test accuracy is 0.008, std of test f1 score is 0.009\n",
            "Time elapsed through all process: 10502.753, sec\n"
          ]
        }
      ],
      "source": [
        "print(f'Mean test accuracy is {\"{:.3f}\".format(sum(test_accuracy_per_run)/number_of_repeat)}, mean test f1 score is {\"{:.3f}\".format(sum(f1_score_per_run)/number_of_repeat)}, \\\n",
        "max test accuracy is {\"{:.3f}\".format(max(test_accuracy_per_run))}, max test f1 score is {\"{:.3f}\".format(max(f1_score_per_run))}, \\\n",
        "min test accuracy is {\"{:.3f}\".format(min(test_accuracy_per_run))}, min test f1 score is {\"{:.3f}\".format(min(f1_score_per_run))}, \\\n",
        "std of test accuracy is {\"{:.3f}\".format(np.std(test_accuracy_per_run, axis=0))}, std of test f1 score is {\"{:.3f}\".format(np.std(f1_score_per_run, axis=0))}')\n",
        "print(f'Time elapsed through all process: {\"{:.3f}\".format(elapsed)}, sec')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "riGtxAo6hsO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "def createList(n):\n",
        "    lst = []\n",
        "    for i in range(n+1):\n",
        "        lst.append(i)\n",
        "    return(lst)\n",
        "\n",
        "\n",
        "folds = createList(4)\n",
        "values = [element * 100 for element in test_accuracy_per_fold]\n",
        "\n",
        "fig = plt.figure(figsize = (10, 5))\n",
        " \n",
        "# creating the bar plot\n",
        "plt.bar(folds, values, color ='maroon',\n",
        "        width = 0.4)\n",
        "plt.xlabel(\"Accuracy vs k-run\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.show()\n",
        "\n",
        "fig = plt.figure(figsize = (10, 5))\n",
        " \n",
        "# creating the bar plot\n",
        "plt.bar(folds, f1_score_per_fold, color ='maroon',\n",
        "        width = 0.4)\n",
        "plt.xlabel(\"F1 Score vs k-run\")\n",
        "plt.ylabel(\"F1 Score\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "id": "xz7CY0DhWKJV",
        "outputId": "946c7a3c-55db-4c4a-c8ee-e4862265abdd"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Range_Doppler_and_Spectrogram_LSTM_8hiddenunitnumberoflstm.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}