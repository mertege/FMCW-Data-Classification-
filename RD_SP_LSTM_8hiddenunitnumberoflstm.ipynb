{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mertege/FMCW-Data-Classification-/blob/Range-Doppler-Spectrogram-LSTM/RD_SP_LSTM_8hiddenunitnumberoflstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kN4ixvH39HW6"
      },
      "outputs": [],
      "source": [
        "# burada 8 hiddenunitoflstm \n",
        "#\n",
        "# Mean test accuracy is 0.947, mean test f1 score is 0.940, max test accuracy is 0.971, max test f1 score is 0.965, min test accuracy is 0.906, min test f1 score is 0.896, std of test accuracy is 0.022, std of test f1 score is 0.023\n",
        "#Time elapsed through all process: 10350.717, sec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lzJwN6GfkN8Z"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from keras.models import Model\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization, Normalization, Input, Conv2D, MaxPooling2D, Concatenate, GRU, LSTM, GRU, TimeDistributed, Bidirectional\n",
        "import tensorflow as tf\n",
        "import scipy.io\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from numpy.random import seed\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "import time\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from keras.callbacks import EarlyStopping\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from keras import backend as K \n",
        "import gc\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FERVnWrkrwE",
        "outputId": "57f2ab1c-62b8-41b8-875d-c98721edc25e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "o19JHieQ81cS"
      },
      "outputs": [],
      "source": [
        "# Get Range-Doppler data from\n",
        "range_doppler_fast_resized = scipy.io.loadmat('/content/drive/MyDrive/data/range_doppler_fast_resized.mat')\n",
        "range_doppler_fast_resized = range_doppler_fast_resized['range_doppler_fast_resized']\n",
        "range_doppler_fast_resized = np.transpose(range_doppler_fast_resized, (2, 0, 1))\n",
        "# range_doppler_fast_resized = np.delete(range_doppler_fast_resized,(49), axis=0) # 50th row is deleted since there is no 50th row in spectrogram fast data.\n",
        "range_doppler_fast_label = scipy.io.loadmat('/content/drive/MyDrive/data/range_doppler_fast_label.mat')\n",
        "range_doppler_fast_label = range_doppler_fast_label['range_doppler_fast_label']  \n",
        "\n",
        "range_doppler_slow_resized = scipy.io.loadmat('/content/drive/MyDrive/data/range_doppler_slow_resized.mat')\n",
        "range_doppler_slow_resized = range_doppler_slow_resized['range_doppler_slow_resized']\n",
        "range_doppler_slow_resized = np.transpose(range_doppler_slow_resized, (2, 0, 1))\n",
        "range_doppler_slow_label = scipy.io.loadmat('/content/drive/MyDrive/data/range_doppler_slow_label.mat')\n",
        "range_doppler_slow_label = range_doppler_slow_label['range_doppler_slow_label']  \n",
        "\n",
        "range_doppler_slow_pocket_resized = scipy.io.loadmat('/content/drive/MyDrive/data/range_doppler_slow_pocket_resized.mat')\n",
        "range_doppler_slow_pocket_resized = range_doppler_slow_pocket_resized['range_doppler_slow_pocket_resized']\n",
        "range_doppler_slow_pocket_resized = np.transpose(range_doppler_slow_pocket_resized, (2, 0, 1))\n",
        "range_doppler_pocket_label = scipy.io.loadmat('/content/drive/MyDrive/data/range_doppler_pocket_label.mat')\n",
        "range_doppler_pocket_label = range_doppler_pocket_label['range_doppler_pocket_label']  \n",
        "# Get Range-Doppler data from\n",
        "spectrogram_fast_resized = scipy.io.loadmat('/content/drive/MyDrive/data/spectrogram_fast_resized.mat')\n",
        "spectrogram_fast_resized = spectrogram_fast_resized['spectrogram_fast_resized']\n",
        "spectrogram_fast_resized = np.transpose(spectrogram_fast_resized, (2, 0, 1))\n",
        "spectrogram_fast_label = scipy.io.loadmat('/content/drive/MyDrive/data/spectrogram_fast_label.mat')\n",
        "spectrogram_fast_label = spectrogram_fast_label['spectrogram_fast_label']  \n",
        "\n",
        "spectrogram_slow_resized = scipy.io.loadmat('/content/drive/MyDrive/data/spectrogram_slow_resized.mat')\n",
        "spectrogram_slow_resized = spectrogram_slow_resized['spectrogram_slow_resized']\n",
        "spectrogram_slow_resized = np.transpose(spectrogram_slow_resized, (2, 0, 1))\n",
        "spectrogram_slow_label = scipy.io.loadmat('/content/drive/MyDrive/data/spectrogram_slow_label.mat')\n",
        "spectrogram_slow_label = spectrogram_slow_label['spectrogram_slow_label']  \n",
        "\n",
        "spectrogram_slow_pocket_resized = scipy.io.loadmat('/content/drive/MyDrive/data/spectrogram_slow_pocket_resized.mat')\n",
        "spectrogram_slow_pocket_resized = spectrogram_slow_pocket_resized['spectrogram_slow_pocket_resized']\n",
        "spectrogram_slow_pocket_resized = np.transpose(spectrogram_slow_pocket_resized, (2, 0, 1))\n",
        "spectrogram_slow_pocket_label = scipy.io.loadmat('/content/drive/MyDrive/data/spectrogram_slow_pocket_label.mat')\n",
        "spectrogram_slow_pocket_label = spectrogram_slow_pocket_label['spectrogram_slow_pocket_label']  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "wFp_PErnMLN2"
      },
      "outputs": [],
      "source": [
        "# Concat range-doppler data\n",
        "range_doppler_concat = np.concatenate((range_doppler_fast_resized,range_doppler_slow_resized),axis=0)\n",
        "range_doppler_concat = np.concatenate((range_doppler_concat,range_doppler_slow_pocket_resized),axis=0)\n",
        "range_doppler_concat = range_doppler_concat[:,:,:,np.newaxis] \n",
        "range_doppler_concat_label = np.zeros((range_doppler_concat.shape[0],1))\n",
        "range_doppler_concat_label[:range_doppler_fast_resized.shape[0],:] = 1\n",
        "# Shuffle concat range doppler\n",
        "shuffle_indx = random.sample(range(0, range_doppler_concat.shape[0]), range_doppler_concat.shape[0]) # split validation data\n",
        "range_doppler_concat_shuffle = range_doppler_concat[shuffle_indx,:,:,:]\n",
        "range_doppler_concat_label_shuffle = range_doppler_concat_label[shuffle_indx,:]\n",
        "# Concat range-doppler data\n",
        "spectrogram_concat = np.concatenate((spectrogram_fast_resized,spectrogram_slow_resized),axis=0)\n",
        "spectrogram_concat = np.concatenate((spectrogram_concat,spectrogram_slow_pocket_resized),axis=0)\n",
        "spectrogram_concat = spectrogram_concat[:,:,:,np.newaxis] \n",
        "spectrogram_concat_label = np.zeros((spectrogram_concat.shape[0],1))\n",
        "spectrogram_concat_label[:spectrogram_fast_resized.shape[0],:] = 1\n",
        "# Shuffle concat range doppler\n",
        "# shuffle_indx = random.sample(range(0, spectrogram_concat.shape[0]), spectrogram_concat.shape[0]) # split validation data\n",
        "spectrogram_concat_shuffle = spectrogram_concat[shuffle_indx,:,:,:]\n",
        "spectrogram_concat_label_shuffle = spectrogram_concat_label[shuffle_indx,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_1aBNkjoLCvI"
      },
      "outputs": [],
      "source": [
        "# ---------------- Augmente and shuffle (train and test) data data ----------------\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "  layers.RandomRotation(0.1),\n",
        "])\n",
        "\n",
        "\n",
        "def mixup_augmentation(images,range_doppler_training_data, labels, repeat_of_mixup, alpha=0.2):\n",
        "    batch_size = images.shape[0]\n",
        "    concat_images = np.zeros((batch_size*(repeat_of_mixup+1),images.shape[1],images.shape[2],images.shape[3]))\n",
        "    concat_images_range_doppler = np.zeros((batch_size*(repeat_of_mixup+1),range_doppler_training_data.shape[1],\\\n",
        "                                            range_doppler_training_data.shape[2],range_doppler_training_data.shape[3]))\n",
        "    concat_label = np.zeros((batch_size*(repeat_of_mixup+1),labels.shape[1]))\n",
        "    for ii in range(repeat_of_mixup):\n",
        "      # shuffle train dataset\n",
        "      shuffle_indx_1 = random.sample(range(0, images.shape[0]), images.shape[0]) # split validation data\n",
        "      images_shuffled_1 = images[shuffle_indx_1,:,:,:]\n",
        "      range_doppler_training_data_shuffled_1 = range_doppler_training_data[shuffle_indx_1,:,:,:]\n",
        "      labels_shuffled_1 = labels[shuffle_indx_1,:]\n",
        "\n",
        "      shuffle_indx_2 = random.sample(range(0, images.shape[0]), images.shape[0]) # split validation data\n",
        "      images_shuffled_2 = images[shuffle_indx_2,:,:,:]\n",
        "      range_doppler_training_data_shuffled_2 = range_doppler_training_data[shuffle_indx_2,:,:,:]\n",
        "      labels_shuffled_2 = labels[shuffle_indx_2,:]\n",
        "\n",
        "      # Sample lambda and reshape it to do the mixup\n",
        "      gaussian_mean = 0.2\n",
        "      gaussian_std = 0.02\n",
        "      ll = np.random.normal(gaussian_mean, gaussian_std, (batch_size,1,1,1))\n",
        "      x_l = np.reshape(ll, (batch_size,1,1,1))\n",
        "      y_l = np.reshape(ll, (batch_size,1))\n",
        "      \n",
        "      # Perform mixup on both images and labels by combining a pair of images/labels\n",
        "      images_mixup = images_shuffled_1 * x_l + images_shuffled_2 * (1 - x_l)\n",
        "      images_mixup_range_doppler = range_doppler_training_data_shuffled_1 * x_l + range_doppler_training_data_shuffled_2 * (1 - x_l)\n",
        "      labels_mixup = labels_shuffled_1 * y_l + labels_shuffled_2 * (1 - y_l)\n",
        "      concat_images[ii*batch_size:(ii+1)*batch_size,:,:,:] = images_mixup\n",
        "      concat_images_range_doppler[ii*batch_size:(ii+1)*batch_size,:,:,:] = images_mixup_range_doppler\n",
        "      concat_label[ii*batch_size:(ii+1)*batch_size,:] = labels_mixup\n",
        "\n",
        "    concat_images[repeat_of_mixup*batch_size:,:,:,:] = images\n",
        "    concat_images_range_doppler[repeat_of_mixup*batch_size:,:,:,:] = range_doppler_training_data\n",
        "    concat_label[repeat_of_mixup*batch_size:,:] = labels\n",
        "    return (concat_images,concat_images_range_doppler, concat_label)\n",
        "def split_and_augmentation_of_training(spectrogram_concat_shuffle_train,range_doppler_concat_shuffle_train,range_doppler_concat_label_shuffle_train,\\\n",
        "                                       repeat_of_mixup, augmentation_enable):\n",
        "  # ---------------- Parameters ----------------\n",
        "  repeat_of_augmentation_for_fast = 1\n",
        "  repeat_of_augmentation_for_slow = np.floor(repeat_of_augmentation_for_fast/2)\n",
        "  repeat_of_augmentation_for_slow = int(repeat_of_augmentation_for_slow)\n",
        "  # size_of_validation = 30\n",
        "  alpha = 0.2\n",
        "  dummy_label = np.zeros((spectrogram_concat_shuffle_train.shape[0],1))\n",
        "  for randomlist_for_train_indx, randomlist_for_validation_indx in kfold.split(spectrogram_concat_shuffle_train,dummy_label):   \n",
        "    randomlist_for_validation_indx\n",
        "  # Split validation\n",
        "  # randomlist_for_validation_indx = random.sample(range(0, range_doppler_concat_shuffle_train.shape[0]), size_of_validation) # split validation data\n",
        "  # randomlist_for_train_indx = np.delete(range(0, range_doppler_concat_shuffle_train.shape[0]), randomlist_for_validation_indx) # split training data\n",
        "  # get validation data\n",
        "  spectrogram_validation_data = spectrogram_concat_shuffle_train[randomlist_for_validation_indx,:,:,:]\n",
        "  spectrogram_validation_labels = range_doppler_concat_label_shuffle_train[randomlist_for_validation_indx,:]\n",
        "  range_doppler_validation_data = range_doppler_concat_shuffle_train[randomlist_for_validation_indx,:,:,:]\n",
        "  # get training data\n",
        "  spectrogram_training_data = spectrogram_concat_shuffle_train[randomlist_for_train_indx,:,:,:]\n",
        "  spectrogram_training_labels = spectrogram_concat_label_shuffle_train[randomlist_for_train_indx,:]\n",
        "  range_doppler_training_data = range_doppler_concat_shuffle_train[randomlist_for_train_indx,:,:,:]\n",
        "\n",
        "  # Rotate Augmentation\n",
        "  # get slow and fast indexes of training data\n",
        "  slow_indexes = np.where(spectrogram_training_labels == 0)[0]\n",
        "  fast_indexes = np.delete(range(0, spectrogram_training_labels.shape[0]), slow_indexes)  \n",
        "\n",
        "  slow_spectrograms_train = spectrogram_training_data[slow_indexes,:,:,:]\n",
        "  size_of_samples_slow = slow_spectrograms_train.shape[0]\n",
        "\n",
        "  fast_spectrograms_train = spectrogram_training_data[fast_indexes,:,:,:]  \n",
        "  size_of_samples_fast = fast_spectrograms_train.shape[0]\n",
        "\n",
        "  slow_range_train = range_doppler_training_data[slow_indexes,:,:,:]\n",
        "  fast_range_train = range_doppler_training_data[fast_indexes,:,:,:]  \n",
        "\n",
        "  if augmentation_enable == True: \n",
        "    # ---------------- Augmente Train Data for Fast ----------------\n",
        "    augmented_image_fast = np.zeros((size_of_samples_fast*repeat_of_augmentation_for_fast,fast_spectrograms_train.shape[1],fast_spectrograms_train.shape[2],1))\n",
        "    spectrograms_fast_label = np.ones((size_of_samples_fast*(repeat_of_augmentation_for_fast+1),1))\n",
        "    # augmented_image_fast = np.flip(fast_spectrograms_train,axis=2)\n",
        "    for jj in range(repeat_of_augmentation_for_fast):\n",
        "      for ii in range(size_of_samples_fast):\n",
        "        augmented_image_fast[size_of_samples_fast*jj+ii,:,:,:] = data_augmentation(fast_spectrograms_train[ii,:,:,:])\n",
        "    augmented_image_fast = np.concatenate((augmented_image_fast,fast_spectrograms_train),axis=0)   \n",
        "\n",
        "    augmented_image_fast_range = np.zeros((size_of_samples_fast*repeat_of_augmentation_for_fast,fast_range_train.shape[1],fast_range_train.shape[2],1))\n",
        "    # augmented_image_fast_range  = np.flip(fast_range_train,axis=2)\n",
        "    for jj in range(repeat_of_augmentation_for_fast):\n",
        "      for ii in range(size_of_samples_fast):\n",
        "        augmented_image_fast_range[size_of_samples_fast*jj+ii,:,:,:]  =data_augmentation(fast_range_train[ii,:,:,:])\n",
        "    augmented_image_fast_range = np.concatenate((augmented_image_fast_range,fast_range_train),axis=0)   \n",
        "\n",
        "    # ---------------- Augmente Train Data for Slow ----------------\n",
        "    augmented_image_slow = slow_spectrograms_train\n",
        "    augmented_image_slow_range = slow_range_train\n",
        "\n",
        "  else:\n",
        "    augmented_image_fast = fast_spectrograms_train\n",
        "    augmented_image_slow = slow_spectrograms_train\n",
        "    augmented_image_fast_range = fast_range_train\n",
        "    augmented_image_slow_range = slow_range_train\n",
        "    spectrograms_fast_label = np.ones((size_of_samples_fast,1))\n",
        "    \n",
        "  spectrograms_slow_label = np.zeros((size_of_samples_slow,1))\n",
        "\n",
        "  spectrogram_training_data = np.concatenate((augmented_image_fast,augmented_image_slow),axis=0)\n",
        "  range_doppler_training_data = np.concatenate((augmented_image_fast_range,augmented_image_slow_range),axis=0)\n",
        "  spectrogram_training_labels = np.concatenate((spectrograms_fast_label,spectrograms_slow_label),axis=0)\n",
        "\n",
        "  (spectrogram_augmented_image,range_doppler_augmented_image,spectrograms_label)=\\\n",
        "   mixup_augmentation(spectrogram_training_data,range_doppler_training_data, spectrogram_training_labels, repeat_of_mixup, alpha=0.2)\n",
        "\n",
        "  return (spectrogram_augmented_image,range_doppler_augmented_image,spectrograms_label,\\\n",
        "     spectrogram_validation_data,range_doppler_validation_data, spectrogram_validation_labels)\n",
        "def normalize_inputs(range_doppler_concat_shuffle, normalize_inputs_enable):\n",
        "  # ---------------- Normalize Inputs ----------------\n",
        "  if normalize_inputs_enable == True:\n",
        "    layer = Normalization(axis=None)\n",
        "    layer.adapt(range_doppler_concat_shuffle)\n",
        "    range_doppler_concat_shuffle = layer(range_doppler_concat_shuffle)\n",
        "  else:\n",
        "    range_doppler_concat_shuffle = range_doppler_concat_shuffle\n",
        "  return(range_doppler_concat_shuffle)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "8CUvxggth7ZQ"
      },
      "outputs": [],
      "source": [
        "normalize_inputs_enable = 1\n",
        "range_doppler_concat_shuffle = normalize_inputs(range_doppler_concat_shuffle, normalize_inputs_enable)\n",
        "spectrogram_concat_shuffle = normalize_inputs(spectrogram_concat_shuffle, normalize_inputs_enable)\n",
        "range_doppler_concat_shuffle = np.float32(range_doppler_concat_shuffle)\n",
        "spectrogram_concat_shuffle = np.float32(spectrogram_concat_shuffle)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "38jkSYXM4aey"
      },
      "outputs": [],
      "source": [
        "n_features = range_doppler_concat_shuffle.shape[1]\n",
        "n_steps = range_doppler_concat_shuffle.shape[2]\n",
        "range_doppler_concat_shuffle = np.transpose(range_doppler_concat_shuffle, axes = (0,2,1,3)) \n",
        "spectrogram_concat_shuffle = np.transpose(spectrogram_concat_shuffle, axes = (0,2,1,3)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "rNpkBBIadpPo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4559b4d3-2888-4173-915b-545f1b4f40c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 5120, 52)]        0         \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 5120, 16)         3904      \n",
            " l)                                                              \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 81920)             0         \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 81920)            327680    \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 81920)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               20971776  \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 256)              1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation (Activation)     (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21,304,384\n",
            "Trainable params: 21,140,032\n",
            "Non-trainable params: 164,352\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 423, 52)]         0         \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 423, 16)          3904      \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 6768)              0         \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 6768)             27072     \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 6768)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 8)                 54152     \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 8)                32        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 8)                 0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 8)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 85,160\n",
            "Trainable params: 71,608\n",
            "Non-trainable params: 13,552\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 264)]             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               67840     \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 256)              1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 64)                16448     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 64)                0         \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 85,377\n",
            "Trainable params: 84,865\n",
            "Non-trainable params: 512\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "27/27 [==============================] - 19s 417ms/step - loss: 0.5196 - accuracy: 0.5197 - val_loss: 0.3196 - val_accuracy: 0.8148\n",
            "Epoch 2/100\n",
            "27/27 [==============================] - 10s 365ms/step - loss: 0.3925 - accuracy: 0.5694 - val_loss: 0.1841 - val_accuracy: 0.9259\n",
            "Epoch 3/100\n",
            "27/27 [==============================] - 10s 367ms/step - loss: 0.3485 - accuracy: 0.5903 - val_loss: 0.1553 - val_accuracy: 0.9630\n",
            "Epoch 4/100\n",
            "27/27 [==============================] - 10s 363ms/step - loss: 0.3293 - accuracy: 0.5949 - val_loss: 0.1358 - val_accuracy: 0.9630\n",
            "Epoch 5/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.3203 - accuracy: 0.5949 - val_loss: 0.1893 - val_accuracy: 0.8889\n",
            "Epoch 6/100\n",
            "27/27 [==============================] - 10s 363ms/step - loss: 0.3149 - accuracy: 0.6019 - val_loss: 0.1597 - val_accuracy: 0.9630\n",
            "Epoch 7/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.2899 - accuracy: 0.6019 - val_loss: 0.1415 - val_accuracy: 0.9630\n",
            "Epoch 8/100\n",
            "27/27 [==============================] - 10s 364ms/step - loss: 0.3022 - accuracy: 0.5984 - val_loss: 0.1614 - val_accuracy: 1.0000\n",
            "Epoch 9/100\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.2797 - accuracy: 0.6065 - val_loss: 0.1975 - val_accuracy: 0.9630\n",
            "Epoch 10/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.2754 - accuracy: 0.6053 - val_loss: 0.1499 - val_accuracy: 1.0000\n",
            "Epoch 11/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.2897 - accuracy: 0.6042 - val_loss: 0.1756 - val_accuracy: 0.9630\n",
            "Epoch 12/100\n",
            "27/27 [==============================] - 10s 363ms/step - loss: 0.2758 - accuracy: 0.6042 - val_loss: 0.1299 - val_accuracy: 0.9630\n",
            "Epoch 13/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.2660 - accuracy: 0.6053 - val_loss: 0.1446 - val_accuracy: 0.9630\n",
            "Epoch 14/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.2799 - accuracy: 0.6042 - val_loss: 0.1492 - val_accuracy: 1.0000\n",
            "Epoch 15/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.2655 - accuracy: 0.6042 - val_loss: 0.1434 - val_accuracy: 0.9630\n",
            "Epoch 16/100\n",
            "27/27 [==============================] - 10s 363ms/step - loss: 0.2693 - accuracy: 0.6053 - val_loss: 0.1775 - val_accuracy: 0.9630\n",
            "Epoch 17/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.2623 - accuracy: 0.6065 - val_loss: 0.2187 - val_accuracy: 0.8889\n",
            "Epoch 18/100\n",
            "27/27 [==============================] - 10s 363ms/step - loss: 0.2613 - accuracy: 0.6053 - val_loss: 0.1752 - val_accuracy: 0.9259\n",
            "Epoch 19/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.2667 - accuracy: 0.6053 - val_loss: 0.1762 - val_accuracy: 0.9630\n",
            "Epoch 20/100\n",
            "27/27 [==============================] - 10s 365ms/step - loss: 0.2610 - accuracy: 0.6065 - val_loss: 0.1281 - val_accuracy: 0.9630\n",
            "Epoch 21/100\n",
            "27/27 [==============================] - 10s 364ms/step - loss: 0.2611 - accuracy: 0.6065 - val_loss: 0.2293 - val_accuracy: 0.9259\n",
            "Epoch 22/100\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.2629 - accuracy: 0.6065 - val_loss: 0.1777 - val_accuracy: 0.9630\n",
            "Epoch 23/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.2610 - accuracy: 0.6053 - val_loss: 0.1675 - val_accuracy: 0.9630\n",
            "Epoch 24/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.2565 - accuracy: 0.6065 - val_loss: 0.1354 - val_accuracy: 0.9630\n",
            "Epoch 25/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.2513 - accuracy: 0.6065 - val_loss: 0.1383 - val_accuracy: 0.9630\n",
            "Epoch 26/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.2524 - accuracy: 0.6065 - val_loss: 0.1706 - val_accuracy: 1.0000\n",
            "Epoch 27/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.2491 - accuracy: 0.6065 - val_loss: 0.1733 - val_accuracy: 1.0000\n",
            "Epoch 28/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.2532 - accuracy: 0.6065 - val_loss: 0.1667 - val_accuracy: 0.9630\n",
            "Epoch 29/100\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.2480 - accuracy: 0.6065 - val_loss: 0.1689 - val_accuracy: 0.9630\n",
            "Epoch 30/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.2440 - accuracy: 0.6065 - val_loss: 0.2278 - val_accuracy: 0.9630\n",
            "Epoch 31/100\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.2507 - accuracy: 0.6053 - val_loss: 0.1979 - val_accuracy: 0.9259\n",
            "Epoch 32/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.2452 - accuracy: 0.6065 - val_loss: 0.1843 - val_accuracy: 0.9259\n",
            "Epoch 33/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.2477 - accuracy: 0.6065 - val_loss: 0.1878 - val_accuracy: 0.9259\n",
            "Epoch 34/100\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.2457 - accuracy: 0.6065 - val_loss: 0.2008 - val_accuracy: 0.9259\n",
            "Epoch 35/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.2542 - accuracy: 0.6053 - val_loss: 0.1737 - val_accuracy: 0.9630\n",
            "2/2 [==============================] - 2s 122ms/step - loss: 0.2053 - accuracy: 0.9412\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 5120, 52)]        0         \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 5120, 16)         3904      \n",
            " l)                                                              \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 81920)             0         \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 81920)            327680    \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 81920)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               20971776  \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 256)              1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation (Activation)     (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21,304,384\n",
            "Trainable params: 21,140,032\n",
            "Non-trainable params: 164,352\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 423, 52)]         0         \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 423, 16)          3904      \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 6768)              0         \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 6768)             27072     \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 6768)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 8)                 54152     \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 8)                32        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 8)                 0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 8)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 85,160\n",
            "Trainable params: 71,608\n",
            "Non-trainable params: 13,552\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 264)]             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               67840     \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 256)              1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 64)                16448     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 64)                0         \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 85,377\n",
            "Trainable params: 84,865\n",
            "Non-trainable params: 512\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "28/28 [==============================] - 17s 406ms/step - loss: 0.5954 - accuracy: 0.5034 - val_loss: 0.8824 - val_accuracy: 0.7407\n",
            "Epoch 2/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.4390 - accuracy: 0.5460 - val_loss: 0.1906 - val_accuracy: 0.9259\n",
            "Epoch 3/100\n",
            "28/28 [==============================] - 10s 356ms/step - loss: 0.3794 - accuracy: 0.5701 - val_loss: 0.1162 - val_accuracy: 0.9630\n",
            "Epoch 4/100\n",
            "28/28 [==============================] - 10s 351ms/step - loss: 0.3686 - accuracy: 0.5690 - val_loss: 0.1536 - val_accuracy: 0.9259\n",
            "Epoch 5/100\n",
            "28/28 [==============================] - 10s 355ms/step - loss: 0.3378 - accuracy: 0.5828 - val_loss: 0.1088 - val_accuracy: 0.9259\n",
            "Epoch 6/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.3177 - accuracy: 0.5897 - val_loss: 0.0830 - val_accuracy: 0.9630\n",
            "Epoch 7/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.3199 - accuracy: 0.5885 - val_loss: 0.0761 - val_accuracy: 0.9630\n",
            "Epoch 8/100\n",
            "28/28 [==============================] - 10s 356ms/step - loss: 0.3277 - accuracy: 0.5885 - val_loss: 0.0629 - val_accuracy: 1.0000\n",
            "Epoch 9/100\n",
            "28/28 [==============================] - 10s 352ms/step - loss: 0.3021 - accuracy: 0.5920 - val_loss: 0.0634 - val_accuracy: 1.0000\n",
            "Epoch 10/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2987 - accuracy: 0.5931 - val_loss: 0.0589 - val_accuracy: 1.0000\n",
            "Epoch 11/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.3048 - accuracy: 0.5897 - val_loss: 0.0571 - val_accuracy: 1.0000\n",
            "Epoch 12/100\n",
            "28/28 [==============================] - 10s 353ms/step - loss: 0.2838 - accuracy: 0.5943 - val_loss: 0.0545 - val_accuracy: 1.0000\n",
            "Epoch 13/100\n",
            "28/28 [==============================] - 10s 357ms/step - loss: 0.2982 - accuracy: 0.5862 - val_loss: 0.0369 - val_accuracy: 1.0000\n",
            "Epoch 14/100\n",
            "28/28 [==============================] - 10s 353ms/step - loss: 0.2990 - accuracy: 0.5897 - val_loss: 0.0460 - val_accuracy: 0.9630\n",
            "Epoch 15/100\n",
            "28/28 [==============================] - 10s 353ms/step - loss: 0.2844 - accuracy: 0.5943 - val_loss: 0.0504 - val_accuracy: 1.0000\n",
            "Epoch 16/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2880 - accuracy: 0.5920 - val_loss: 0.0460 - val_accuracy: 1.0000\n",
            "Epoch 17/100\n",
            "28/28 [==============================] - 10s 352ms/step - loss: 0.2775 - accuracy: 0.5943 - val_loss: 0.0427 - val_accuracy: 1.0000\n",
            "Epoch 18/100\n",
            "28/28 [==============================] - 10s 353ms/step - loss: 0.2844 - accuracy: 0.5943 - val_loss: 0.0481 - val_accuracy: 1.0000\n",
            "Epoch 19/100\n",
            "28/28 [==============================] - 10s 353ms/step - loss: 0.2802 - accuracy: 0.5931 - val_loss: 0.0445 - val_accuracy: 0.9630\n",
            "Epoch 20/100\n",
            "28/28 [==============================] - 10s 352ms/step - loss: 0.2784 - accuracy: 0.5954 - val_loss: 0.0460 - val_accuracy: 1.0000\n",
            "Epoch 21/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2883 - accuracy: 0.5920 - val_loss: 0.0306 - val_accuracy: 1.0000\n",
            "Epoch 22/100\n",
            "28/28 [==============================] - 10s 352ms/step - loss: 0.2707 - accuracy: 0.5931 - val_loss: 0.0735 - val_accuracy: 0.9630\n",
            "Epoch 23/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2715 - accuracy: 0.5954 - val_loss: 0.0419 - val_accuracy: 1.0000\n",
            "Epoch 24/100\n",
            "28/28 [==============================] - 10s 353ms/step - loss: 0.2782 - accuracy: 0.5954 - val_loss: 0.1336 - val_accuracy: 0.8889\n",
            "Epoch 25/100\n",
            "28/28 [==============================] - 10s 352ms/step - loss: 0.2604 - accuracy: 0.5954 - val_loss: 0.0837 - val_accuracy: 1.0000\n",
            "Epoch 26/100\n",
            "28/28 [==============================] - 10s 353ms/step - loss: 0.2753 - accuracy: 0.5954 - val_loss: 0.0806 - val_accuracy: 0.9630\n",
            "Epoch 27/100\n",
            "28/28 [==============================] - 10s 352ms/step - loss: 0.2720 - accuracy: 0.5954 - val_loss: 0.1172 - val_accuracy: 0.9259\n",
            "Epoch 28/100\n",
            "28/28 [==============================] - 10s 355ms/step - loss: 0.2658 - accuracy: 0.5943 - val_loss: 0.1255 - val_accuracy: 0.9259\n",
            "Epoch 29/100\n",
            "28/28 [==============================] - 10s 352ms/step - loss: 0.2770 - accuracy: 0.5954 - val_loss: 0.0498 - val_accuracy: 1.0000\n",
            "Epoch 30/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2657 - accuracy: 0.5954 - val_loss: 0.0743 - val_accuracy: 0.9630\n",
            "Epoch 31/100\n",
            "28/28 [==============================] - 10s 353ms/step - loss: 0.2626 - accuracy: 0.5954 - val_loss: 0.0945 - val_accuracy: 0.9630\n",
            "Epoch 32/100\n",
            "28/28 [==============================] - 10s 353ms/step - loss: 0.2647 - accuracy: 0.5954 - val_loss: 0.0577 - val_accuracy: 1.0000\n",
            "Epoch 33/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2582 - accuracy: 0.5954 - val_loss: 0.0962 - val_accuracy: 0.9259\n",
            "Epoch 34/100\n",
            "28/28 [==============================] - 10s 353ms/step - loss: 0.2657 - accuracy: 0.5954 - val_loss: 0.0478 - val_accuracy: 1.0000\n",
            "Epoch 35/100\n",
            "28/28 [==============================] - 10s 353ms/step - loss: 0.2669 - accuracy: 0.5954 - val_loss: 0.0474 - val_accuracy: 1.0000\n",
            "Epoch 36/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2680 - accuracy: 0.5954 - val_loss: 0.0651 - val_accuracy: 1.0000\n",
            "2/2 [==============================] - 2s 125ms/step - loss: 0.1034 - accuracy: 0.9118\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 5120, 52)]        0         \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 5120, 16)         3904      \n",
            " l)                                                              \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 81920)             0         \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 81920)            327680    \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 81920)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               20971776  \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 256)              1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation (Activation)     (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21,304,384\n",
            "Trainable params: 21,140,032\n",
            "Non-trainable params: 164,352\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 423, 52)]         0         \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 423, 16)          3904      \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 6768)              0         \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 6768)             27072     \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 6768)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 8)                 54152     \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 8)                32        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 8)                 0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 8)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 85,160\n",
            "Trainable params: 71,608\n",
            "Non-trainable params: 13,552\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 264)]             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               67840     \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 256)              1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 64)                16448     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 64)                0         \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 85,377\n",
            "Trainable params: 84,865\n",
            "Non-trainable params: 512\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "28/28 [==============================] - 17s 405ms/step - loss: 0.5321 - accuracy: 0.4989 - val_loss: 0.7657 - val_accuracy: 0.8148\n",
            "Epoch 2/100\n",
            "28/28 [==============================] - 10s 356ms/step - loss: 0.3866 - accuracy: 0.5605 - val_loss: 0.4453 - val_accuracy: 0.8148\n",
            "Epoch 3/100\n",
            "28/28 [==============================] - 10s 355ms/step - loss: 0.3685 - accuracy: 0.5696 - val_loss: 0.3682 - val_accuracy: 0.8148\n",
            "Epoch 4/100\n",
            "28/28 [==============================] - 10s 356ms/step - loss: 0.3356 - accuracy: 0.5776 - val_loss: 0.3082 - val_accuracy: 0.8889\n",
            "Epoch 5/100\n",
            "28/28 [==============================] - 10s 356ms/step - loss: 0.3130 - accuracy: 0.5845 - val_loss: 0.2409 - val_accuracy: 0.8889\n",
            "Epoch 6/100\n",
            "28/28 [==============================] - 10s 355ms/step - loss: 0.3150 - accuracy: 0.5811 - val_loss: 0.2152 - val_accuracy: 0.8889\n",
            "Epoch 7/100\n",
            "28/28 [==============================] - 10s 355ms/step - loss: 0.3145 - accuracy: 0.5833 - val_loss: 0.2116 - val_accuracy: 0.9259\n",
            "Epoch 8/100\n",
            "28/28 [==============================] - 10s 355ms/step - loss: 0.3006 - accuracy: 0.5845 - val_loss: 0.2246 - val_accuracy: 0.8889\n",
            "Epoch 9/100\n",
            "28/28 [==============================] - 10s 355ms/step - loss: 0.2955 - accuracy: 0.5879 - val_loss: 0.2249 - val_accuracy: 0.8889\n",
            "Epoch 10/100\n",
            "28/28 [==============================] - 10s 355ms/step - loss: 0.2927 - accuracy: 0.5845 - val_loss: 0.1722 - val_accuracy: 0.9630\n",
            "Epoch 11/100\n",
            "28/28 [==============================] - 10s 356ms/step - loss: 0.3018 - accuracy: 0.5845 - val_loss: 0.1692 - val_accuracy: 0.9630\n",
            "Epoch 12/100\n",
            "28/28 [==============================] - 10s 355ms/step - loss: 0.2861 - accuracy: 0.5890 - val_loss: 0.1497 - val_accuracy: 0.9630\n",
            "Epoch 13/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2836 - accuracy: 0.5879 - val_loss: 0.1415 - val_accuracy: 0.9630\n",
            "Epoch 14/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2812 - accuracy: 0.5879 - val_loss: 0.1465 - val_accuracy: 0.9259\n",
            "Epoch 15/100\n",
            "28/28 [==============================] - 10s 355ms/step - loss: 0.2780 - accuracy: 0.5890 - val_loss: 0.1572 - val_accuracy: 0.9259\n",
            "Epoch 16/100\n",
            "28/28 [==============================] - 10s 353ms/step - loss: 0.2785 - accuracy: 0.5879 - val_loss: 0.1670 - val_accuracy: 0.9259\n",
            "Epoch 17/100\n",
            "28/28 [==============================] - 10s 353ms/step - loss: 0.2697 - accuracy: 0.5890 - val_loss: 0.1679 - val_accuracy: 0.8889\n",
            "Epoch 18/100\n",
            "28/28 [==============================] - 10s 355ms/step - loss: 0.2701 - accuracy: 0.5890 - val_loss: 0.1337 - val_accuracy: 0.9630\n",
            "Epoch 19/100\n",
            "28/28 [==============================] - 10s 355ms/step - loss: 0.2827 - accuracy: 0.5879 - val_loss: 0.1498 - val_accuracy: 0.9259\n",
            "Epoch 20/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2766 - accuracy: 0.5879 - val_loss: 0.1623 - val_accuracy: 0.8889\n",
            "Epoch 21/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2699 - accuracy: 0.5890 - val_loss: 0.1584 - val_accuracy: 0.9259\n",
            "Epoch 22/100\n",
            "28/28 [==============================] - 10s 353ms/step - loss: 0.2681 - accuracy: 0.5890 - val_loss: 0.1459 - val_accuracy: 0.9630\n",
            "Epoch 23/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2720 - accuracy: 0.5890 - val_loss: 0.1641 - val_accuracy: 0.9630\n",
            "Epoch 24/100\n",
            "28/28 [==============================] - 10s 352ms/step - loss: 0.2595 - accuracy: 0.5890 - val_loss: 0.1368 - val_accuracy: 0.9630\n",
            "Epoch 25/100\n",
            "28/28 [==============================] - 10s 355ms/step - loss: 0.2615 - accuracy: 0.5890 - val_loss: 0.1504 - val_accuracy: 0.9259\n",
            "Epoch 26/100\n",
            "28/28 [==============================] - 10s 355ms/step - loss: 0.2642 - accuracy: 0.5890 - val_loss: 0.1284 - val_accuracy: 0.9630\n",
            "Epoch 27/100\n",
            "28/28 [==============================] - 10s 353ms/step - loss: 0.2711 - accuracy: 0.5879 - val_loss: 0.1962 - val_accuracy: 0.8889\n",
            "Epoch 28/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2707 - accuracy: 0.5890 - val_loss: 0.1769 - val_accuracy: 0.9630\n",
            "Epoch 29/100\n",
            "28/28 [==============================] - 10s 355ms/step - loss: 0.2609 - accuracy: 0.5890 - val_loss: 0.1547 - val_accuracy: 0.9259\n",
            "Epoch 30/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2625 - accuracy: 0.5890 - val_loss: 0.1838 - val_accuracy: 0.9259\n",
            "Epoch 31/100\n",
            "28/28 [==============================] - 10s 355ms/step - loss: 0.2645 - accuracy: 0.5879 - val_loss: 0.1382 - val_accuracy: 0.9630\n",
            "Epoch 32/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2649 - accuracy: 0.5890 - val_loss: 0.1530 - val_accuracy: 0.9259\n",
            "Epoch 33/100\n",
            "28/28 [==============================] - 10s 356ms/step - loss: 0.2647 - accuracy: 0.5890 - val_loss: 0.1774 - val_accuracy: 0.9259\n",
            "Epoch 34/100\n",
            "28/28 [==============================] - 10s 353ms/step - loss: 0.2669 - accuracy: 0.5890 - val_loss: 0.1683 - val_accuracy: 0.9259\n",
            "Epoch 35/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2558 - accuracy: 0.5890 - val_loss: 0.1535 - val_accuracy: 0.9630\n",
            "Epoch 36/100\n",
            "28/28 [==============================] - 10s 353ms/step - loss: 0.2554 - accuracy: 0.5890 - val_loss: 0.1554 - val_accuracy: 0.9259\n",
            "Epoch 37/100\n",
            "28/28 [==============================] - 10s 353ms/step - loss: 0.2580 - accuracy: 0.5890 - val_loss: 0.1407 - val_accuracy: 0.9630\n",
            "Epoch 38/100\n",
            "28/28 [==============================] - 10s 355ms/step - loss: 0.2549 - accuracy: 0.5890 - val_loss: 0.1690 - val_accuracy: 0.9259\n",
            "Epoch 39/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2542 - accuracy: 0.5890 - val_loss: 0.1579 - val_accuracy: 0.9630\n",
            "Epoch 40/100\n",
            "28/28 [==============================] - 10s 355ms/step - loss: 0.2618 - accuracy: 0.5890 - val_loss: 0.1664 - val_accuracy: 0.9259\n",
            "Epoch 41/100\n",
            "28/28 [==============================] - 10s 355ms/step - loss: 0.2568 - accuracy: 0.5890 - val_loss: 0.1471 - val_accuracy: 0.9259\n",
            "2/2 [==============================] - 2s 132ms/step - loss: 0.0815 - accuracy: 0.9706\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 5120, 52)]        0         \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 5120, 16)         3904      \n",
            " l)                                                              \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 81920)             0         \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 81920)            327680    \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 81920)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               20971776  \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 256)              1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation (Activation)     (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21,304,384\n",
            "Trainable params: 21,140,032\n",
            "Non-trainable params: 164,352\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 423, 52)]         0         \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 423, 16)          3904      \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 6768)              0         \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 6768)             27072     \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 6768)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 8)                 54152     \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 8)                32        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 8)                 0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 8)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 85,160\n",
            "Trainable params: 71,608\n",
            "Non-trainable params: 13,552\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 264)]             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               67840     \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 256)              1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 64)                16448     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 64)                0         \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 85,377\n",
            "Trainable params: 84,865\n",
            "Non-trainable params: 512\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "28/28 [==============================] - 17s 405ms/step - loss: 0.5214 - accuracy: 0.5103 - val_loss: 0.2481 - val_accuracy: 0.9259\n",
            "Epoch 2/100\n",
            "28/28 [==============================] - 10s 355ms/step - loss: 0.4146 - accuracy: 0.5552 - val_loss: 0.1716 - val_accuracy: 0.9630\n",
            "Epoch 3/100\n",
            "28/28 [==============================] - 10s 356ms/step - loss: 0.3683 - accuracy: 0.5632 - val_loss: 0.1377 - val_accuracy: 0.9630\n",
            "Epoch 4/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.3545 - accuracy: 0.5793 - val_loss: 0.1457 - val_accuracy: 0.9630\n",
            "Epoch 5/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.3372 - accuracy: 0.5793 - val_loss: 0.1608 - val_accuracy: 0.9630\n",
            "Epoch 6/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.3267 - accuracy: 0.5851 - val_loss: 0.1354 - val_accuracy: 0.9630\n",
            "Epoch 7/100\n",
            "28/28 [==============================] - 10s 355ms/step - loss: 0.3231 - accuracy: 0.5851 - val_loss: 0.1271 - val_accuracy: 0.9630\n",
            "Epoch 8/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.3119 - accuracy: 0.5862 - val_loss: 0.1298 - val_accuracy: 0.9630\n",
            "Epoch 9/100\n",
            "28/28 [==============================] - 10s 352ms/step - loss: 0.3072 - accuracy: 0.5862 - val_loss: 0.2686 - val_accuracy: 0.8148\n",
            "Epoch 10/100\n",
            "28/28 [==============================] - 10s 356ms/step - loss: 0.3046 - accuracy: 0.5874 - val_loss: 0.0866 - val_accuracy: 0.9630\n",
            "Epoch 11/100\n",
            "28/28 [==============================] - 10s 356ms/step - loss: 0.2935 - accuracy: 0.5885 - val_loss: 0.0728 - val_accuracy: 0.9630\n",
            "Epoch 12/100\n",
            "28/28 [==============================] - 10s 352ms/step - loss: 0.2904 - accuracy: 0.5908 - val_loss: 0.0843 - val_accuracy: 0.9630\n",
            "Epoch 13/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2875 - accuracy: 0.5931 - val_loss: 0.1112 - val_accuracy: 0.9630\n",
            "Epoch 14/100\n",
            "28/28 [==============================] - 10s 353ms/step - loss: 0.2820 - accuracy: 0.5920 - val_loss: 0.1033 - val_accuracy: 0.9630\n",
            "Epoch 15/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2801 - accuracy: 0.5920 - val_loss: 0.1345 - val_accuracy: 0.9630\n",
            "Epoch 16/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2746 - accuracy: 0.5931 - val_loss: 0.1667 - val_accuracy: 0.9259\n",
            "Epoch 17/100\n",
            "28/28 [==============================] - 10s 353ms/step - loss: 0.2727 - accuracy: 0.5908 - val_loss: 0.0966 - val_accuracy: 0.9630\n",
            "Epoch 18/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2772 - accuracy: 0.5931 - val_loss: 0.1090 - val_accuracy: 0.9630\n",
            "Epoch 19/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2785 - accuracy: 0.5920 - val_loss: 0.1374 - val_accuracy: 0.9259\n",
            "Epoch 20/100\n",
            "28/28 [==============================] - 10s 353ms/step - loss: 0.2774 - accuracy: 0.5931 - val_loss: 0.0803 - val_accuracy: 0.9630\n",
            "Epoch 21/100\n",
            "28/28 [==============================] - 10s 353ms/step - loss: 0.2743 - accuracy: 0.5920 - val_loss: 0.0907 - val_accuracy: 0.9630\n",
            "Epoch 22/100\n",
            "28/28 [==============================] - 10s 353ms/step - loss: 0.2832 - accuracy: 0.5920 - val_loss: 0.0892 - val_accuracy: 0.9630\n",
            "Epoch 23/100\n",
            "28/28 [==============================] - 10s 353ms/step - loss: 0.2695 - accuracy: 0.5931 - val_loss: 0.0801 - val_accuracy: 0.9630\n",
            "Epoch 24/100\n",
            "28/28 [==============================] - 10s 355ms/step - loss: 0.2743 - accuracy: 0.5920 - val_loss: 0.0537 - val_accuracy: 1.0000\n",
            "Epoch 25/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2717 - accuracy: 0.5920 - val_loss: 0.0887 - val_accuracy: 1.0000\n",
            "Epoch 26/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2673 - accuracy: 0.5931 - val_loss: 0.1018 - val_accuracy: 0.9630\n",
            "Epoch 27/100\n",
            "28/28 [==============================] - 10s 353ms/step - loss: 0.2736 - accuracy: 0.5931 - val_loss: 0.1136 - val_accuracy: 1.0000\n",
            "Epoch 28/100\n",
            "28/28 [==============================] - 10s 353ms/step - loss: 0.2612 - accuracy: 0.5920 - val_loss: 0.0896 - val_accuracy: 0.9630\n",
            "Epoch 29/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2638 - accuracy: 0.5931 - val_loss: 0.0895 - val_accuracy: 1.0000\n",
            "Epoch 30/100\n",
            "28/28 [==============================] - 10s 352ms/step - loss: 0.2731 - accuracy: 0.5920 - val_loss: 0.0955 - val_accuracy: 1.0000\n",
            "Epoch 31/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2597 - accuracy: 0.5931 - val_loss: 0.0853 - val_accuracy: 0.9630\n",
            "Epoch 32/100\n",
            "28/28 [==============================] - 10s 353ms/step - loss: 0.2527 - accuracy: 0.5931 - val_loss: 0.0888 - val_accuracy: 1.0000\n",
            "Epoch 33/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2613 - accuracy: 0.5931 - val_loss: 0.0771 - val_accuracy: 0.9630\n",
            "Epoch 34/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2584 - accuracy: 0.5920 - val_loss: 0.0744 - val_accuracy: 0.9630\n",
            "Epoch 35/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2558 - accuracy: 0.5931 - val_loss: 0.0953 - val_accuracy: 0.9630\n",
            "Epoch 36/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2565 - accuracy: 0.5931 - val_loss: 0.0887 - val_accuracy: 0.9630\n",
            "Epoch 37/100\n",
            "28/28 [==============================] - 10s 353ms/step - loss: 0.2572 - accuracy: 0.5931 - val_loss: 0.0732 - val_accuracy: 0.9630\n",
            "Epoch 38/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2590 - accuracy: 0.5931 - val_loss: 0.1244 - val_accuracy: 0.9630\n",
            "Epoch 39/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2695 - accuracy: 0.5920 - val_loss: 0.1162 - val_accuracy: 0.9630\n",
            "2/2 [==============================] - 2s 123ms/step - loss: 0.1421 - accuracy: 0.9412\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 5120, 52)]        0         \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 5120, 16)         3904      \n",
            " l)                                                              \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 81920)             0         \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 81920)            327680    \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 81920)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               20971776  \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 256)              1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation (Activation)     (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21,304,384\n",
            "Trainable params: 21,140,032\n",
            "Non-trainable params: 164,352\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 423, 52)]         0         \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 423, 16)          3904      \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 6768)              0         \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 6768)             27072     \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 6768)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 8)                 54152     \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 8)                32        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 8)                 0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 8)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 85,160\n",
            "Trainable params: 71,608\n",
            "Non-trainable params: 13,552\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 264)]             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               67840     \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 256)              1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 64)                16448     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 64)                0         \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 85,377\n",
            "Trainable params: 84,865\n",
            "Non-trainable params: 512\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "28/28 [==============================] - 17s 409ms/step - loss: 0.5280 - accuracy: 0.5034 - val_loss: 0.7083 - val_accuracy: 0.6296\n",
            "Epoch 2/100\n",
            "28/28 [==============================] - 10s 356ms/step - loss: 0.4205 - accuracy: 0.5394 - val_loss: 1.0557 - val_accuracy: 0.2963\n",
            "Epoch 3/100\n",
            "28/28 [==============================] - 10s 356ms/step - loss: 0.3889 - accuracy: 0.5597 - val_loss: 0.7312 - val_accuracy: 0.5926\n",
            "Epoch 4/100\n",
            "28/28 [==============================] - 10s 356ms/step - loss: 0.3727 - accuracy: 0.5687 - val_loss: 0.4792 - val_accuracy: 0.7407\n",
            "Epoch 5/100\n",
            "28/28 [==============================] - 10s 358ms/step - loss: 0.3323 - accuracy: 0.5811 - val_loss: 0.3084 - val_accuracy: 0.8519\n",
            "Epoch 6/100\n",
            "28/28 [==============================] - 10s 358ms/step - loss: 0.3181 - accuracy: 0.5845 - val_loss: 0.2123 - val_accuracy: 0.8889\n",
            "Epoch 7/100\n",
            "28/28 [==============================] - 10s 355ms/step - loss: 0.3163 - accuracy: 0.5833 - val_loss: 0.2397 - val_accuracy: 0.9259\n",
            "Epoch 8/100\n",
            "28/28 [==============================] - 10s 356ms/step - loss: 0.3129 - accuracy: 0.5878 - val_loss: 0.2304 - val_accuracy: 0.8889\n",
            "Epoch 9/100\n",
            "28/28 [==============================] - 10s 356ms/step - loss: 0.3001 - accuracy: 0.5878 - val_loss: 0.2207 - val_accuracy: 0.9259\n",
            "Epoch 10/100\n",
            "28/28 [==============================] - 10s 359ms/step - loss: 0.2942 - accuracy: 0.5867 - val_loss: 0.1801 - val_accuracy: 0.9630\n",
            "Epoch 11/100\n",
            "28/28 [==============================] - 10s 355ms/step - loss: 0.2936 - accuracy: 0.5890 - val_loss: 0.2184 - val_accuracy: 0.9630\n",
            "Epoch 12/100\n",
            "28/28 [==============================] - 10s 358ms/step - loss: 0.2926 - accuracy: 0.5856 - val_loss: 0.1073 - val_accuracy: 1.0000\n",
            "Epoch 13/100\n",
            "28/28 [==============================] - 10s 355ms/step - loss: 0.2894 - accuracy: 0.5878 - val_loss: 0.1384 - val_accuracy: 0.9259\n",
            "Epoch 14/100\n",
            "28/28 [==============================] - 10s 356ms/step - loss: 0.2855 - accuracy: 0.5878 - val_loss: 0.1476 - val_accuracy: 0.9630\n",
            "Epoch 15/100\n",
            "28/28 [==============================] - 10s 356ms/step - loss: 0.2800 - accuracy: 0.5890 - val_loss: 0.3694 - val_accuracy: 0.8519\n",
            "Epoch 16/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2830 - accuracy: 0.5878 - val_loss: 0.3259 - val_accuracy: 0.8519\n",
            "Epoch 17/100\n",
            "28/28 [==============================] - 10s 356ms/step - loss: 0.2738 - accuracy: 0.5901 - val_loss: 0.4413 - val_accuracy: 0.7778\n",
            "Epoch 18/100\n",
            "28/28 [==============================] - 10s 356ms/step - loss: 0.2786 - accuracy: 0.5890 - val_loss: 0.2550 - val_accuracy: 0.8889\n",
            "Epoch 19/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2693 - accuracy: 0.5901 - val_loss: 0.3670 - val_accuracy: 0.8519\n",
            "Epoch 20/100\n",
            "28/28 [==============================] - 10s 355ms/step - loss: 0.2811 - accuracy: 0.5890 - val_loss: 0.2329 - val_accuracy: 0.8889\n",
            "Epoch 21/100\n",
            "28/28 [==============================] - 10s 355ms/step - loss: 0.2667 - accuracy: 0.5901 - val_loss: 0.5816 - val_accuracy: 0.7407\n",
            "Epoch 22/100\n",
            "28/28 [==============================] - 10s 356ms/step - loss: 0.2659 - accuracy: 0.5901 - val_loss: 0.2222 - val_accuracy: 0.9259\n",
            "Epoch 23/100\n",
            "28/28 [==============================] - 10s 358ms/step - loss: 0.2673 - accuracy: 0.5890 - val_loss: 0.2288 - val_accuracy: 0.9259\n",
            "Epoch 24/100\n",
            "28/28 [==============================] - 10s 356ms/step - loss: 0.2675 - accuracy: 0.5901 - val_loss: 0.3019 - val_accuracy: 0.8889\n",
            "Epoch 25/100\n",
            "28/28 [==============================] - 10s 355ms/step - loss: 0.2628 - accuracy: 0.5901 - val_loss: 0.3084 - val_accuracy: 0.8519\n",
            "Epoch 26/100\n",
            "28/28 [==============================] - 10s 357ms/step - loss: 0.2626 - accuracy: 0.5901 - val_loss: 0.2260 - val_accuracy: 0.9259\n",
            "Epoch 27/100\n",
            "28/28 [==============================] - 10s 356ms/step - loss: 0.2683 - accuracy: 0.5890 - val_loss: 0.1780 - val_accuracy: 0.9259\n",
            "2/2 [==============================] - 2s 129ms/step - loss: 0.0960 - accuracy: 0.9706\n",
            "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3f73bc8290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[0.9470588088035583]\n",
            "[0.9386747079624046]\n",
            "Epoch 1/100\n",
            "27/27 [==============================] - 17s 428ms/step - loss: 0.5030 - accuracy: 0.5081 - val_loss: 0.6015 - val_accuracy: 0.7407\n",
            "Epoch 2/100\n",
            "27/27 [==============================] - 10s 364ms/step - loss: 0.3807 - accuracy: 0.5694 - val_loss: 0.5338 - val_accuracy: 0.7407\n",
            "Epoch 3/100\n",
            "27/27 [==============================] - 10s 364ms/step - loss: 0.3577 - accuracy: 0.5845 - val_loss: 0.3742 - val_accuracy: 0.8148\n",
            "Epoch 4/100\n",
            "27/27 [==============================] - 10s 365ms/step - loss: 0.3464 - accuracy: 0.5706 - val_loss: 0.2045 - val_accuracy: 0.8889\n",
            "Epoch 5/100\n",
            "27/27 [==============================] - 10s 364ms/step - loss: 0.3208 - accuracy: 0.5914 - val_loss: 0.1579 - val_accuracy: 0.9630\n",
            "Epoch 6/100\n",
            "27/27 [==============================] - 10s 363ms/step - loss: 0.3129 - accuracy: 0.5891 - val_loss: 0.1017 - val_accuracy: 1.0000\n",
            "Epoch 7/100\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.3066 - accuracy: 0.5926 - val_loss: 0.1133 - val_accuracy: 1.0000\n",
            "Epoch 8/100\n",
            "27/27 [==============================] - 10s 360ms/step - loss: 0.3070 - accuracy: 0.5891 - val_loss: 0.1092 - val_accuracy: 1.0000\n",
            "Epoch 9/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.2941 - accuracy: 0.5880 - val_loss: 0.1073 - val_accuracy: 0.9630\n",
            "Epoch 10/100\n",
            "27/27 [==============================] - 10s 364ms/step - loss: 0.2927 - accuracy: 0.5926 - val_loss: 0.0628 - val_accuracy: 1.0000\n",
            "Epoch 11/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.2884 - accuracy: 0.5938 - val_loss: 0.0616 - val_accuracy: 1.0000\n",
            "Epoch 12/100\n",
            "27/27 [==============================] - 10s 360ms/step - loss: 0.2820 - accuracy: 0.5938 - val_loss: 0.0716 - val_accuracy: 0.9630\n",
            "Epoch 13/100\n",
            "27/27 [==============================] - 10s 360ms/step - loss: 0.2809 - accuracy: 0.5949 - val_loss: 0.0928 - val_accuracy: 0.9630\n",
            "Epoch 14/100\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.2742 - accuracy: 0.5938 - val_loss: 0.0706 - val_accuracy: 0.9630\n",
            "Epoch 15/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.2738 - accuracy: 0.5914 - val_loss: 0.1628 - val_accuracy: 0.9630\n",
            "Epoch 16/100\n",
            "27/27 [==============================] - 10s 360ms/step - loss: 0.2838 - accuracy: 0.5949 - val_loss: 0.1576 - val_accuracy: 0.9259\n",
            "Epoch 17/100\n",
            "27/27 [==============================] - 10s 360ms/step - loss: 0.2658 - accuracy: 0.5938 - val_loss: 0.0914 - val_accuracy: 0.9630\n",
            "Epoch 18/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.2683 - accuracy: 0.5938 - val_loss: 0.1316 - val_accuracy: 0.9630\n",
            "Epoch 19/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.2767 - accuracy: 0.5938 - val_loss: 0.0990 - val_accuracy: 0.9630\n",
            "Epoch 20/100\n",
            "27/27 [==============================] - 10s 360ms/step - loss: 0.2646 - accuracy: 0.5949 - val_loss: 0.0651 - val_accuracy: 0.9630\n",
            "Epoch 21/100\n",
            "27/27 [==============================] - 10s 360ms/step - loss: 0.2689 - accuracy: 0.5949 - val_loss: 0.0887 - val_accuracy: 0.9630\n",
            "Epoch 22/100\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.2683 - accuracy: 0.5949 - val_loss: 0.0793 - val_accuracy: 0.9630\n",
            "Epoch 23/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.2694 - accuracy: 0.5938 - val_loss: 0.1350 - val_accuracy: 0.9630\n",
            "Epoch 24/100\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.2657 - accuracy: 0.5949 - val_loss: 0.1029 - val_accuracy: 0.9630\n",
            "Epoch 25/100\n",
            "27/27 [==============================] - 10s 364ms/step - loss: 0.2612 - accuracy: 0.5949 - val_loss: 0.0478 - val_accuracy: 1.0000\n",
            "Epoch 26/100\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.2663 - accuracy: 0.5938 - val_loss: 0.0576 - val_accuracy: 0.9630\n",
            "Epoch 27/100\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.2641 - accuracy: 0.5949 - val_loss: 0.0794 - val_accuracy: 0.9630\n",
            "Epoch 28/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.2610 - accuracy: 0.5949 - val_loss: 0.1071 - val_accuracy: 0.9630\n",
            "Epoch 29/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.2568 - accuracy: 0.5949 - val_loss: 0.0517 - val_accuracy: 1.0000\n",
            "Epoch 30/100\n",
            "27/27 [==============================] - 10s 360ms/step - loss: 0.2630 - accuracy: 0.5949 - val_loss: 0.0871 - val_accuracy: 0.9630\n",
            "Epoch 31/100\n",
            "27/27 [==============================] - 10s 363ms/step - loss: 0.2561 - accuracy: 0.5949 - val_loss: 0.0627 - val_accuracy: 0.9630\n",
            "Epoch 32/100\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.2562 - accuracy: 0.5938 - val_loss: 0.1017 - val_accuracy: 0.9630\n",
            "Epoch 33/100\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.2614 - accuracy: 0.5949 - val_loss: 0.0919 - val_accuracy: 0.9630\n",
            "Epoch 34/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.2531 - accuracy: 0.5949 - val_loss: 0.0863 - val_accuracy: 0.9630\n",
            "Epoch 35/100\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.2509 - accuracy: 0.5949 - val_loss: 0.0804 - val_accuracy: 0.9630\n",
            "Epoch 36/100\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.2566 - accuracy: 0.5949 - val_loss: 0.0749 - val_accuracy: 0.9630\n",
            "Epoch 37/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.2570 - accuracy: 0.5949 - val_loss: 0.1034 - val_accuracy: 0.9630\n",
            "Epoch 38/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.2555 - accuracy: 0.5949 - val_loss: 0.0888 - val_accuracy: 0.9630\n",
            "Epoch 39/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.2527 - accuracy: 0.5949 - val_loss: 0.0934 - val_accuracy: 0.9630\n",
            "Epoch 40/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.2523 - accuracy: 0.5938 - val_loss: 0.0746 - val_accuracy: 0.9630\n",
            "2/2 [==============================] - 2s 136ms/step - loss: 0.2290 - accuracy: 0.9118\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f401881ce60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Epoch 1/100\n",
            "27/27 [==============================] - 17s 428ms/step - loss: 0.5199 - accuracy: 0.4850 - val_loss: 1.0262 - val_accuracy: 0.6667\n",
            "Epoch 2/100\n",
            "27/27 [==============================] - 10s 364ms/step - loss: 0.4168 - accuracy: 0.5370 - val_loss: 0.7473 - val_accuracy: 0.6667\n",
            "Epoch 3/100\n",
            "27/27 [==============================] - 10s 366ms/step - loss: 0.3782 - accuracy: 0.5463 - val_loss: 0.3676 - val_accuracy: 0.8889\n",
            "Epoch 4/100\n",
            "27/27 [==============================] - 10s 363ms/step - loss: 0.3609 - accuracy: 0.5567 - val_loss: 0.2314 - val_accuracy: 0.9630\n",
            "Epoch 5/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.3296 - accuracy: 0.5637 - val_loss: 0.3097 - val_accuracy: 0.8889\n",
            "Epoch 6/100\n",
            "27/27 [==============================] - 10s 360ms/step - loss: 0.3294 - accuracy: 0.5590 - val_loss: 0.2844 - val_accuracy: 0.8889\n",
            "Epoch 7/100\n",
            "27/27 [==============================] - 10s 360ms/step - loss: 0.3149 - accuracy: 0.5683 - val_loss: 0.3190 - val_accuracy: 0.8889\n",
            "Epoch 8/100\n",
            "27/27 [==============================] - 10s 364ms/step - loss: 0.3145 - accuracy: 0.5648 - val_loss: 0.2247 - val_accuracy: 0.9630\n",
            "Epoch 9/100\n",
            "27/27 [==============================] - 10s 363ms/step - loss: 0.3081 - accuracy: 0.5648 - val_loss: 0.2660 - val_accuracy: 0.8889\n",
            "Epoch 10/100\n",
            "27/27 [==============================] - 10s 364ms/step - loss: 0.3070 - accuracy: 0.5683 - val_loss: 0.2049 - val_accuracy: 0.9259\n",
            "Epoch 11/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.3001 - accuracy: 0.5671 - val_loss: 0.2891 - val_accuracy: 0.8519\n",
            "Epoch 12/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.3018 - accuracy: 0.5671 - val_loss: 0.2379 - val_accuracy: 0.8889\n",
            "Epoch 13/100\n",
            "27/27 [==============================] - 10s 360ms/step - loss: 0.2901 - accuracy: 0.5683 - val_loss: 0.2598 - val_accuracy: 0.8889\n",
            "Epoch 14/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.2977 - accuracy: 0.5648 - val_loss: 0.2639 - val_accuracy: 0.9259\n",
            "Epoch 15/100\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.2985 - accuracy: 0.5671 - val_loss: 0.3376 - val_accuracy: 0.8519\n",
            "Epoch 16/100\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.2887 - accuracy: 0.5694 - val_loss: 0.2072 - val_accuracy: 0.9259\n",
            "Epoch 17/100\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.2882 - accuracy: 0.5683 - val_loss: 0.2733 - val_accuracy: 0.8889\n",
            "Epoch 18/100\n",
            "27/27 [==============================] - 10s 360ms/step - loss: 0.2932 - accuracy: 0.5694 - val_loss: 0.3077 - val_accuracy: 0.8889\n",
            "Epoch 19/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.2779 - accuracy: 0.5683 - val_loss: 0.2840 - val_accuracy: 0.8889\n",
            "Epoch 20/100\n",
            "27/27 [==============================] - 10s 360ms/step - loss: 0.2840 - accuracy: 0.5683 - val_loss: 0.2540 - val_accuracy: 0.8889\n",
            "Epoch 21/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.2839 - accuracy: 0.5694 - val_loss: 0.3074 - val_accuracy: 0.8519\n",
            "Epoch 22/100\n",
            "27/27 [==============================] - 10s 359ms/step - loss: 0.2808 - accuracy: 0.5671 - val_loss: 0.2964 - val_accuracy: 0.9259\n",
            "Epoch 23/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.2720 - accuracy: 0.5694 - val_loss: 0.3919 - val_accuracy: 0.8519\n",
            "Epoch 24/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.2778 - accuracy: 0.5694 - val_loss: 0.3308 - val_accuracy: 0.8889\n",
            "Epoch 25/100\n",
            "27/27 [==============================] - 10s 363ms/step - loss: 0.2834 - accuracy: 0.5694 - val_loss: 0.4295 - val_accuracy: 0.8519\n",
            "2/2 [==============================] - 2s 124ms/step - loss: 0.1566 - accuracy: 0.9412\n",
            "Epoch 1/100\n",
            "28/28 [==============================] - 18s 407ms/step - loss: 0.5143 - accuracy: 0.4920 - val_loss: 0.7411 - val_accuracy: 0.7407\n",
            "Epoch 2/100\n",
            "28/28 [==============================] - 10s 356ms/step - loss: 0.4099 - accuracy: 0.5514 - val_loss: 0.3413 - val_accuracy: 0.8519\n",
            "Epoch 3/100\n",
            "28/28 [==============================] - 10s 357ms/step - loss: 0.3745 - accuracy: 0.5605 - val_loss: 0.2727 - val_accuracy: 0.8148\n",
            "Epoch 4/100\n",
            "28/28 [==============================] - 10s 355ms/step - loss: 0.3366 - accuracy: 0.5742 - val_loss: 0.3113 - val_accuracy: 0.8519\n",
            "Epoch 5/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.3291 - accuracy: 0.5685 - val_loss: 0.2808 - val_accuracy: 0.8519\n",
            "Epoch 6/100\n",
            "28/28 [==============================] - 10s 355ms/step - loss: 0.3282 - accuracy: 0.5753 - val_loss: 0.2941 - val_accuracy: 0.8519\n",
            "Epoch 7/100\n",
            "28/28 [==============================] - 10s 356ms/step - loss: 0.3127 - accuracy: 0.5833 - val_loss: 0.2963 - val_accuracy: 0.8889\n",
            "Epoch 8/100\n",
            "28/28 [==============================] - 10s 355ms/step - loss: 0.3074 - accuracy: 0.5833 - val_loss: 0.1645 - val_accuracy: 0.9259\n",
            "Epoch 9/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.3016 - accuracy: 0.5811 - val_loss: 0.1759 - val_accuracy: 0.8889\n",
            "Epoch 10/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2972 - accuracy: 0.5822 - val_loss: 0.1427 - val_accuracy: 0.9259\n",
            "Epoch 11/100\n",
            "28/28 [==============================] - 10s 358ms/step - loss: 0.2969 - accuracy: 0.5833 - val_loss: 0.1332 - val_accuracy: 0.9630\n",
            "Epoch 12/100\n",
            "28/28 [==============================] - 10s 352ms/step - loss: 0.2827 - accuracy: 0.5833 - val_loss: 0.1459 - val_accuracy: 0.9259\n",
            "Epoch 13/100\n",
            "28/28 [==============================] - 10s 353ms/step - loss: 0.2912 - accuracy: 0.5833 - val_loss: 0.1295 - val_accuracy: 0.9630\n",
            "Epoch 14/100\n",
            "28/28 [==============================] - 10s 357ms/step - loss: 0.2825 - accuracy: 0.5822 - val_loss: 0.0970 - val_accuracy: 0.9630\n",
            "Epoch 15/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2857 - accuracy: 0.5845 - val_loss: 0.1227 - val_accuracy: 1.0000\n",
            "Epoch 16/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2806 - accuracy: 0.5833 - val_loss: 0.1126 - val_accuracy: 0.9630\n",
            "Epoch 17/100\n",
            "28/28 [==============================] - 10s 353ms/step - loss: 0.2835 - accuracy: 0.5833 - val_loss: 0.1429 - val_accuracy: 0.9259\n",
            "Epoch 18/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2773 - accuracy: 0.5822 - val_loss: 0.1685 - val_accuracy: 0.8889\n",
            "Epoch 19/100\n",
            "28/28 [==============================] - 10s 353ms/step - loss: 0.2788 - accuracy: 0.5822 - val_loss: 0.1375 - val_accuracy: 0.9259\n",
            "Epoch 20/100\n",
            "28/28 [==============================] - 10s 353ms/step - loss: 0.2765 - accuracy: 0.5845 - val_loss: 0.1334 - val_accuracy: 0.9259\n",
            "Epoch 21/100\n",
            "28/28 [==============================] - 10s 353ms/step - loss: 0.2792 - accuracy: 0.5822 - val_loss: 0.1021 - val_accuracy: 1.0000\n",
            "Epoch 22/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2714 - accuracy: 0.5845 - val_loss: 0.1164 - val_accuracy: 0.9630\n",
            "Epoch 23/100\n",
            "28/28 [==============================] - 10s 352ms/step - loss: 0.2681 - accuracy: 0.5845 - val_loss: 0.1047 - val_accuracy: 1.0000\n",
            "Epoch 24/100\n",
            "28/28 [==============================] - 10s 355ms/step - loss: 0.2711 - accuracy: 0.5845 - val_loss: 0.1011 - val_accuracy: 1.0000\n",
            "Epoch 25/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2642 - accuracy: 0.5845 - val_loss: 0.1486 - val_accuracy: 0.9630\n",
            "Epoch 26/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2696 - accuracy: 0.5845 - val_loss: 0.1664 - val_accuracy: 0.9259\n",
            "Epoch 27/100\n",
            "28/28 [==============================] - 10s 353ms/step - loss: 0.2606 - accuracy: 0.5845 - val_loss: 0.1282 - val_accuracy: 0.9630\n",
            "Epoch 28/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2638 - accuracy: 0.5845 - val_loss: 0.1350 - val_accuracy: 0.9630\n",
            "Epoch 29/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2657 - accuracy: 0.5845 - val_loss: 0.1465 - val_accuracy: 0.9630\n",
            "2/2 [==============================] - 2s 121ms/step - loss: 0.0263 - accuracy: 1.0000\n",
            "Epoch 1/100\n",
            "27/27 [==============================] - 17s 413ms/step - loss: 0.5236 - accuracy: 0.5082 - val_loss: 0.6055 - val_accuracy: 0.7778\n",
            "Epoch 2/100\n",
            "27/27 [==============================] - 10s 359ms/step - loss: 0.4232 - accuracy: 0.5385 - val_loss: 0.3719 - val_accuracy: 0.8519\n",
            "Epoch 3/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.3808 - accuracy: 0.5571 - val_loss: 0.3724 - val_accuracy: 0.8519\n",
            "Epoch 4/100\n",
            "27/27 [==============================] - 10s 360ms/step - loss: 0.3540 - accuracy: 0.5688 - val_loss: 0.3118 - val_accuracy: 0.8889\n",
            "Epoch 5/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.3401 - accuracy: 0.5711 - val_loss: 0.3157 - val_accuracy: 0.8889\n",
            "Epoch 6/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.3290 - accuracy: 0.5676 - val_loss: 0.3586 - val_accuracy: 0.8519\n",
            "Epoch 7/100\n",
            "27/27 [==============================] - 10s 358ms/step - loss: 0.3132 - accuracy: 0.5758 - val_loss: 0.2364 - val_accuracy: 0.9259\n",
            "Epoch 8/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.2968 - accuracy: 0.5781 - val_loss: 0.2298 - val_accuracy: 0.9259\n",
            "Epoch 9/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.3113 - accuracy: 0.5769 - val_loss: 0.2591 - val_accuracy: 0.9259\n",
            "Epoch 10/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.3020 - accuracy: 0.5769 - val_loss: 0.2376 - val_accuracy: 0.9259\n",
            "Epoch 11/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2913 - accuracy: 0.5769 - val_loss: 0.2487 - val_accuracy: 0.9259\n",
            "Epoch 12/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2861 - accuracy: 0.5769 - val_loss: 0.2512 - val_accuracy: 0.9259\n",
            "Epoch 13/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.2845 - accuracy: 0.5769 - val_loss: 0.2895 - val_accuracy: 0.8889\n",
            "Epoch 14/100\n",
            "27/27 [==============================] - 10s 358ms/step - loss: 0.2898 - accuracy: 0.5746 - val_loss: 0.2739 - val_accuracy: 0.8889\n",
            "Epoch 15/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2854 - accuracy: 0.5769 - val_loss: 0.2504 - val_accuracy: 0.9630\n",
            "Epoch 16/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2803 - accuracy: 0.5781 - val_loss: 0.2857 - val_accuracy: 0.9259\n",
            "Epoch 17/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2793 - accuracy: 0.5781 - val_loss: 0.2351 - val_accuracy: 0.9259\n",
            "Epoch 18/100\n",
            "27/27 [==============================] - 10s 358ms/step - loss: 0.2823 - accuracy: 0.5781 - val_loss: 0.2250 - val_accuracy: 0.9630\n",
            "Epoch 19/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.2807 - accuracy: 0.5769 - val_loss: 0.2372 - val_accuracy: 0.9630\n",
            "Epoch 20/100\n",
            "27/27 [==============================] - 10s 358ms/step - loss: 0.2712 - accuracy: 0.5781 - val_loss: 0.2648 - val_accuracy: 0.9259\n",
            "Epoch 21/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.2740 - accuracy: 0.5781 - val_loss: 0.2587 - val_accuracy: 0.9630\n",
            "Epoch 22/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2715 - accuracy: 0.5781 - val_loss: 0.2644 - val_accuracy: 0.9259\n",
            "Epoch 23/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2674 - accuracy: 0.5781 - val_loss: 0.2769 - val_accuracy: 0.9259\n",
            "Epoch 24/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.2593 - accuracy: 0.5781 - val_loss: 0.3066 - val_accuracy: 0.8889\n",
            "Epoch 25/100\n",
            "27/27 [==============================] - 10s 358ms/step - loss: 0.2705 - accuracy: 0.5769 - val_loss: 0.2590 - val_accuracy: 0.9259\n",
            "Epoch 26/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.2688 - accuracy: 0.5781 - val_loss: 0.2883 - val_accuracy: 0.9630\n",
            "Epoch 27/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.2684 - accuracy: 0.5781 - val_loss: 0.2612 - val_accuracy: 0.9259\n",
            "Epoch 28/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.2655 - accuracy: 0.5781 - val_loss: 0.2651 - val_accuracy: 0.9259\n",
            "Epoch 29/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.2655 - accuracy: 0.5781 - val_loss: 0.2692 - val_accuracy: 0.9259\n",
            "Epoch 30/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.2683 - accuracy: 0.5781 - val_loss: 0.2806 - val_accuracy: 0.9259\n",
            "Epoch 31/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.2637 - accuracy: 0.5781 - val_loss: 0.3072 - val_accuracy: 0.9259\n",
            "Epoch 32/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2624 - accuracy: 0.5769 - val_loss: 0.2890 - val_accuracy: 0.9259\n",
            "Epoch 33/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2658 - accuracy: 0.5781 - val_loss: 0.3087 - val_accuracy: 0.9259\n",
            "2/2 [==============================] - 2s 120ms/step - loss: 0.1579 - accuracy: 0.9412\n",
            "Epoch 1/100\n",
            "27/27 [==============================] - 17s 430ms/step - loss: 0.4929 - accuracy: 0.5127 - val_loss: 0.9194 - val_accuracy: 0.8148\n",
            "Epoch 2/100\n",
            "27/27 [==============================] - 10s 364ms/step - loss: 0.3816 - accuracy: 0.5590 - val_loss: 0.7919 - val_accuracy: 0.7407\n",
            "Epoch 3/100\n",
            "27/27 [==============================] - 10s 365ms/step - loss: 0.3542 - accuracy: 0.5625 - val_loss: 0.6701 - val_accuracy: 0.8148\n",
            "Epoch 4/100\n",
            "27/27 [==============================] - 10s 364ms/step - loss: 0.3508 - accuracy: 0.5694 - val_loss: 0.4873 - val_accuracy: 0.8148\n",
            "Epoch 5/100\n",
            "27/27 [==============================] - 10s 363ms/step - loss: 0.3495 - accuracy: 0.5660 - val_loss: 0.4013 - val_accuracy: 0.8148\n",
            "Epoch 6/100\n",
            "27/27 [==============================] - 10s 364ms/step - loss: 0.3293 - accuracy: 0.5671 - val_loss: 0.3850 - val_accuracy: 0.8148\n",
            "Epoch 7/100\n",
            "27/27 [==============================] - 10s 364ms/step - loss: 0.3150 - accuracy: 0.5764 - val_loss: 0.3151 - val_accuracy: 0.8889\n",
            "Epoch 8/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.3016 - accuracy: 0.5752 - val_loss: 0.2706 - val_accuracy: 0.8889\n",
            "Epoch 9/100\n",
            "27/27 [==============================] - 10s 363ms/step - loss: 0.3035 - accuracy: 0.5741 - val_loss: 0.2306 - val_accuracy: 0.8889\n",
            "Epoch 10/100\n",
            "27/27 [==============================] - 10s 363ms/step - loss: 0.2896 - accuracy: 0.5764 - val_loss: 0.3218 - val_accuracy: 0.8519\n",
            "Epoch 11/100\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.2910 - accuracy: 0.5764 - val_loss: 0.3007 - val_accuracy: 0.8889\n",
            "Epoch 12/100\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.2898 - accuracy: 0.5718 - val_loss: 0.2438 - val_accuracy: 0.8889\n",
            "Epoch 13/100\n",
            "27/27 [==============================] - 10s 365ms/step - loss: 0.2880 - accuracy: 0.5752 - val_loss: 0.2201 - val_accuracy: 0.8889\n",
            "Epoch 14/100\n",
            "27/27 [==============================] - 10s 363ms/step - loss: 0.2816 - accuracy: 0.5764 - val_loss: 0.2072 - val_accuracy: 0.8889\n",
            "Epoch 15/100\n",
            "27/27 [==============================] - 10s 363ms/step - loss: 0.2770 - accuracy: 0.5764 - val_loss: 0.1822 - val_accuracy: 0.9259\n",
            "Epoch 16/100\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.2952 - accuracy: 0.5764 - val_loss: 0.2649 - val_accuracy: 0.8889\n",
            "Epoch 17/100\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.2833 - accuracy: 0.5764 - val_loss: 0.2441 - val_accuracy: 0.8889\n",
            "Epoch 18/100\n",
            "27/27 [==============================] - 10s 359ms/step - loss: 0.2746 - accuracy: 0.5752 - val_loss: 0.1855 - val_accuracy: 0.9259\n",
            "Epoch 19/100\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.2721 - accuracy: 0.5764 - val_loss: 0.1909 - val_accuracy: 0.9259\n",
            "Epoch 20/100\n",
            "27/27 [==============================] - 10s 360ms/step - loss: 0.2695 - accuracy: 0.5764 - val_loss: 0.2035 - val_accuracy: 0.9259\n",
            "Epoch 21/100\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.2743 - accuracy: 0.5764 - val_loss: 0.2627 - val_accuracy: 0.8889\n",
            "Epoch 22/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.2731 - accuracy: 0.5764 - val_loss: 0.2776 - val_accuracy: 0.8889\n",
            "Epoch 23/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.2747 - accuracy: 0.5752 - val_loss: 0.1935 - val_accuracy: 0.9259\n",
            "Epoch 24/100\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.2661 - accuracy: 0.5752 - val_loss: 0.2258 - val_accuracy: 0.9259\n",
            "Epoch 25/100\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.2669 - accuracy: 0.5752 - val_loss: 0.1971 - val_accuracy: 0.9259\n",
            "Epoch 26/100\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.2732 - accuracy: 0.5764 - val_loss: 0.2289 - val_accuracy: 0.9259\n",
            "Epoch 27/100\n",
            "27/27 [==============================] - 10s 363ms/step - loss: 0.2612 - accuracy: 0.5764 - val_loss: 0.1770 - val_accuracy: 0.9259\n",
            "Epoch 28/100\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.2705 - accuracy: 0.5764 - val_loss: 0.2034 - val_accuracy: 0.9259\n",
            "Epoch 29/100\n",
            "27/27 [==============================] - 10s 363ms/step - loss: 0.2661 - accuracy: 0.5764 - val_loss: 0.2084 - val_accuracy: 0.9259\n",
            "Epoch 30/100\n",
            "27/27 [==============================] - 10s 360ms/step - loss: 0.2711 - accuracy: 0.5752 - val_loss: 0.2017 - val_accuracy: 0.9259\n",
            "Epoch 31/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.2596 - accuracy: 0.5764 - val_loss: 0.2009 - val_accuracy: 0.9259\n",
            "Epoch 32/100\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.2607 - accuracy: 0.5764 - val_loss: 0.2091 - val_accuracy: 0.8889\n",
            "Epoch 33/100\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.2641 - accuracy: 0.5764 - val_loss: 0.1878 - val_accuracy: 0.9259\n",
            "Epoch 34/100\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.2601 - accuracy: 0.5764 - val_loss: 0.1984 - val_accuracy: 0.9259\n",
            "Epoch 35/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.2581 - accuracy: 0.5764 - val_loss: 0.2238 - val_accuracy: 0.8889\n",
            "Epoch 36/100\n",
            "27/27 [==============================] - 10s 360ms/step - loss: 0.2612 - accuracy: 0.5764 - val_loss: 0.2002 - val_accuracy: 0.8889\n",
            "Epoch 37/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.2686 - accuracy: 0.5764 - val_loss: 0.2012 - val_accuracy: 0.9259\n",
            "Epoch 38/100\n",
            "27/27 [==============================] - 10s 363ms/step - loss: 0.2683 - accuracy: 0.5764 - val_loss: 0.1750 - val_accuracy: 0.8889\n",
            "Epoch 39/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.2603 - accuracy: 0.5764 - val_loss: 0.1567 - val_accuracy: 0.9259\n",
            "Epoch 40/100\n",
            "27/27 [==============================] - 10s 363ms/step - loss: 0.2533 - accuracy: 0.5764 - val_loss: 0.1925 - val_accuracy: 0.8889\n",
            "Epoch 41/100\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.2590 - accuracy: 0.5752 - val_loss: 0.1743 - val_accuracy: 0.9630\n",
            "Epoch 42/100\n",
            "27/27 [==============================] - 10s 360ms/step - loss: 0.2581 - accuracy: 0.5764 - val_loss: 0.1908 - val_accuracy: 0.8889\n",
            "Epoch 43/100\n",
            "27/27 [==============================] - 10s 360ms/step - loss: 0.2639 - accuracy: 0.5752 - val_loss: 0.1884 - val_accuracy: 0.9259\n",
            "Epoch 44/100\n",
            "27/27 [==============================] - 10s 359ms/step - loss: 0.2551 - accuracy: 0.5764 - val_loss: 0.1780 - val_accuracy: 0.9259\n",
            "Epoch 45/100\n",
            "27/27 [==============================] - 10s 360ms/step - loss: 0.2513 - accuracy: 0.5764 - val_loss: 0.1969 - val_accuracy: 0.8889\n",
            "Epoch 46/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.2597 - accuracy: 0.5764 - val_loss: 0.2135 - val_accuracy: 0.8889\n",
            "Epoch 47/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.2511 - accuracy: 0.5764 - val_loss: 0.1868 - val_accuracy: 0.8889\n",
            "Epoch 48/100\n",
            "27/27 [==============================] - 10s 360ms/step - loss: 0.2571 - accuracy: 0.5764 - val_loss: 0.1732 - val_accuracy: 0.9259\n",
            "Epoch 49/100\n",
            "27/27 [==============================] - 10s 363ms/step - loss: 0.2516 - accuracy: 0.5764 - val_loss: 0.1846 - val_accuracy: 0.9630\n",
            "Epoch 50/100\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.2551 - accuracy: 0.5764 - val_loss: 0.1713 - val_accuracy: 0.9630\n",
            "Epoch 51/100\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.2515 - accuracy: 0.5764 - val_loss: 0.1800 - val_accuracy: 0.9259\n",
            "Epoch 52/100\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.2528 - accuracy: 0.5764 - val_loss: 0.2293 - val_accuracy: 0.8889\n",
            "Epoch 53/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.2545 - accuracy: 0.5764 - val_loss: 0.1991 - val_accuracy: 0.8889\n",
            "Epoch 54/100\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.2596 - accuracy: 0.5764 - val_loss: 0.2014 - val_accuracy: 0.8889\n",
            "2/2 [==============================] - 2s 111ms/step - loss: 0.1552 - accuracy: 0.9706\n",
            "[0.9470588088035583, 0.9529411673545838]\n",
            "[0.9386747079624046, 0.9458003581442472]\n",
            "Epoch 1/100\n",
            "27/27 [==============================] - 17s 430ms/step - loss: 0.4632 - accuracy: 0.5243 - val_loss: 0.6569 - val_accuracy: 0.8148\n",
            "Epoch 2/100\n",
            "27/27 [==============================] - 10s 364ms/step - loss: 0.3976 - accuracy: 0.5637 - val_loss: 0.5107 - val_accuracy: 0.8148\n",
            "Epoch 3/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.3714 - accuracy: 0.5752 - val_loss: 0.3278 - val_accuracy: 0.8148\n",
            "Epoch 4/100\n",
            "27/27 [==============================] - 10s 364ms/step - loss: 0.3299 - accuracy: 0.5880 - val_loss: 0.3172 - val_accuracy: 0.8519\n",
            "Epoch 5/100\n",
            "27/27 [==============================] - 10s 363ms/step - loss: 0.3183 - accuracy: 0.5856 - val_loss: 0.3533 - val_accuracy: 0.8148\n",
            "Epoch 6/100\n",
            "27/27 [==============================] - 10s 363ms/step - loss: 0.3130 - accuracy: 0.5880 - val_loss: 0.3780 - val_accuracy: 0.8148\n",
            "Epoch 7/100\n",
            "27/27 [==============================] - 10s 363ms/step - loss: 0.3066 - accuracy: 0.5880 - val_loss: 0.2868 - val_accuracy: 0.8148\n",
            "Epoch 8/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.3043 - accuracy: 0.5880 - val_loss: 0.3674 - val_accuracy: 0.8148\n",
            "Epoch 9/100\n",
            "27/27 [==============================] - 10s 365ms/step - loss: 0.2982 - accuracy: 0.5914 - val_loss: 0.2687 - val_accuracy: 0.8519\n",
            "Epoch 10/100\n",
            "27/27 [==============================] - 10s 363ms/step - loss: 0.2933 - accuracy: 0.5926 - val_loss: 0.2463 - val_accuracy: 0.8889\n",
            "Epoch 11/100\n",
            "27/27 [==============================] - 10s 364ms/step - loss: 0.2928 - accuracy: 0.5891 - val_loss: 0.2265 - val_accuracy: 0.8889\n",
            "Epoch 12/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.2732 - accuracy: 0.5926 - val_loss: 0.4272 - val_accuracy: 0.8519\n",
            "Epoch 13/100\n",
            "27/27 [==============================] - 10s 363ms/step - loss: 0.2820 - accuracy: 0.5914 - val_loss: 0.4692 - val_accuracy: 0.8148\n",
            "Epoch 14/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.2720 - accuracy: 0.5926 - val_loss: 0.2543 - val_accuracy: 0.8519\n",
            "Epoch 15/100\n",
            "27/27 [==============================] - 10s 365ms/step - loss: 0.2733 - accuracy: 0.5926 - val_loss: 0.2015 - val_accuracy: 0.8889\n",
            "Epoch 16/100\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.2769 - accuracy: 0.5926 - val_loss: 0.2084 - val_accuracy: 0.8889\n",
            "Epoch 17/100\n",
            "27/27 [==============================] - 10s 363ms/step - loss: 0.2720 - accuracy: 0.5914 - val_loss: 0.3951 - val_accuracy: 0.8148\n",
            "Epoch 18/100\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.2607 - accuracy: 0.5926 - val_loss: 0.2738 - val_accuracy: 0.8519\n",
            "Epoch 19/100\n",
            "27/27 [==============================] - 10s 363ms/step - loss: 0.2640 - accuracy: 0.5926 - val_loss: 0.2215 - val_accuracy: 0.8889\n",
            "Epoch 20/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.2712 - accuracy: 0.5926 - val_loss: 0.4092 - val_accuracy: 0.8148\n",
            "Epoch 21/100\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.2646 - accuracy: 0.5926 - val_loss: 0.3849 - val_accuracy: 0.8519\n",
            "Epoch 22/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.2751 - accuracy: 0.5903 - val_loss: 0.2782 - val_accuracy: 0.8889\n",
            "Epoch 23/100\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.2659 - accuracy: 0.5926 - val_loss: 0.3325 - val_accuracy: 0.8519\n",
            "Epoch 24/100\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.2693 - accuracy: 0.5914 - val_loss: 0.3929 - val_accuracy: 0.8519\n",
            "Epoch 25/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.2668 - accuracy: 0.5926 - val_loss: 0.2531 - val_accuracy: 0.8519\n",
            "Epoch 26/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.2712 - accuracy: 0.5926 - val_loss: 0.4221 - val_accuracy: 0.8519\n",
            "Epoch 27/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.2565 - accuracy: 0.5926 - val_loss: 0.3825 - val_accuracy: 0.8148\n",
            "Epoch 28/100\n",
            "27/27 [==============================] - 10s 363ms/step - loss: 0.2558 - accuracy: 0.5926 - val_loss: 0.3667 - val_accuracy: 0.8519\n",
            "Epoch 29/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.2594 - accuracy: 0.5926 - val_loss: 0.4383 - val_accuracy: 0.8519\n",
            "Epoch 30/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.2595 - accuracy: 0.5926 - val_loss: 0.5347 - val_accuracy: 0.8148\n",
            "2/2 [==============================] - 2s 125ms/step - loss: 0.1437 - accuracy: 0.9412\n",
            "Epoch 1/100\n",
            "28/28 [==============================] - 18s 407ms/step - loss: 0.5034 - accuracy: 0.5103 - val_loss: 0.4974 - val_accuracy: 0.7778\n",
            "Epoch 2/100\n",
            "28/28 [==============================] - 10s 358ms/step - loss: 0.4056 - accuracy: 0.5571 - val_loss: 0.1263 - val_accuracy: 0.9259\n",
            "Epoch 3/100\n",
            "28/28 [==============================] - 10s 356ms/step - loss: 0.3912 - accuracy: 0.5605 - val_loss: 0.1015 - val_accuracy: 1.0000\n",
            "Epoch 4/100\n",
            "28/28 [==============================] - 10s 358ms/step - loss: 0.3620 - accuracy: 0.5719 - val_loss: 0.0573 - val_accuracy: 1.0000\n",
            "Epoch 5/100\n",
            "28/28 [==============================] - 10s 356ms/step - loss: 0.3333 - accuracy: 0.5833 - val_loss: 0.1145 - val_accuracy: 1.0000\n",
            "Epoch 6/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.3278 - accuracy: 0.5788 - val_loss: 0.0875 - val_accuracy: 1.0000\n",
            "Epoch 7/100\n",
            "28/28 [==============================] - 10s 356ms/step - loss: 0.3158 - accuracy: 0.5845 - val_loss: 0.1564 - val_accuracy: 0.9259\n",
            "Epoch 8/100\n",
            "28/28 [==============================] - 10s 356ms/step - loss: 0.3072 - accuracy: 0.5868 - val_loss: 0.2132 - val_accuracy: 0.9259\n",
            "Epoch 9/100\n",
            "28/28 [==============================] - 10s 355ms/step - loss: 0.3002 - accuracy: 0.5845 - val_loss: 0.1911 - val_accuracy: 0.9259\n",
            "Epoch 10/100\n",
            "28/28 [==============================] - 10s 355ms/step - loss: 0.2939 - accuracy: 0.5890 - val_loss: 0.3944 - val_accuracy: 0.8148\n",
            "Epoch 11/100\n",
            "28/28 [==============================] - 10s 357ms/step - loss: 0.2855 - accuracy: 0.5879 - val_loss: 0.2220 - val_accuracy: 0.8889\n",
            "Epoch 12/100\n",
            "28/28 [==============================] - 10s 357ms/step - loss: 0.2844 - accuracy: 0.5890 - val_loss: 0.2260 - val_accuracy: 0.8519\n",
            "Epoch 13/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2859 - accuracy: 0.5890 - val_loss: 0.1157 - val_accuracy: 0.9630\n",
            "Epoch 14/100\n",
            "28/28 [==============================] - 10s 356ms/step - loss: 0.2767 - accuracy: 0.5879 - val_loss: 0.0888 - val_accuracy: 1.0000\n",
            "Epoch 15/100\n",
            "28/28 [==============================] - 10s 355ms/step - loss: 0.2814 - accuracy: 0.5868 - val_loss: 0.0701 - val_accuracy: 1.0000\n",
            "Epoch 16/100\n",
            "28/28 [==============================] - 10s 355ms/step - loss: 0.2719 - accuracy: 0.5868 - val_loss: 0.1118 - val_accuracy: 1.0000\n",
            "Epoch 17/100\n",
            "28/28 [==============================] - 10s 357ms/step - loss: 0.2773 - accuracy: 0.5890 - val_loss: 0.0749 - val_accuracy: 1.0000\n",
            "Epoch 18/100\n",
            "28/28 [==============================] - 10s 356ms/step - loss: 0.2673 - accuracy: 0.5890 - val_loss: 0.0958 - val_accuracy: 1.0000\n",
            "Epoch 19/100\n",
            "28/28 [==============================] - 10s 357ms/step - loss: 0.2666 - accuracy: 0.5879 - val_loss: 0.0662 - val_accuracy: 1.0000\n",
            "2/2 [==============================] - 2s 131ms/step - loss: 0.0597 - accuracy: 1.0000\n",
            "Epoch 1/100\n",
            "27/27 [==============================] - 17s 410ms/step - loss: 0.5144 - accuracy: 0.5154 - val_loss: 2.5279 - val_accuracy: 0.5185\n",
            "Epoch 2/100\n",
            "27/27 [==============================] - 10s 358ms/step - loss: 0.4145 - accuracy: 0.5532 - val_loss: 1.3491 - val_accuracy: 0.5556\n",
            "Epoch 3/100\n",
            "27/27 [==============================] - 10s 358ms/step - loss: 0.3684 - accuracy: 0.5674 - val_loss: 0.7226 - val_accuracy: 0.6667\n",
            "Epoch 4/100\n",
            "27/27 [==============================] - 10s 358ms/step - loss: 0.3777 - accuracy: 0.5745 - val_loss: 0.6241 - val_accuracy: 0.6667\n",
            "Epoch 5/100\n",
            "27/27 [==============================] - 10s 358ms/step - loss: 0.3399 - accuracy: 0.5780 - val_loss: 0.3796 - val_accuracy: 0.7778\n",
            "Epoch 6/100\n",
            "27/27 [==============================] - 10s 358ms/step - loss: 0.3301 - accuracy: 0.5827 - val_loss: 0.2879 - val_accuracy: 0.8889\n",
            "Epoch 7/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.3125 - accuracy: 0.5887 - val_loss: 0.2798 - val_accuracy: 0.8519\n",
            "Epoch 8/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.3085 - accuracy: 0.5851 - val_loss: 0.2310 - val_accuracy: 0.8148\n",
            "Epoch 9/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.2966 - accuracy: 0.5910 - val_loss: 0.2050 - val_accuracy: 0.8889\n",
            "Epoch 10/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.3035 - accuracy: 0.5875 - val_loss: 0.2118 - val_accuracy: 0.8889\n",
            "Epoch 11/100\n",
            "27/27 [==============================] - 10s 354ms/step - loss: 0.2958 - accuracy: 0.5910 - val_loss: 0.3016 - val_accuracy: 0.8519\n",
            "Epoch 12/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.2864 - accuracy: 0.5922 - val_loss: 0.1992 - val_accuracy: 0.8889\n",
            "Epoch 13/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.2896 - accuracy: 0.5922 - val_loss: 0.2159 - val_accuracy: 0.8889\n",
            "Epoch 14/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.2827 - accuracy: 0.5922 - val_loss: 0.1929 - val_accuracy: 0.8889\n",
            "Epoch 15/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2775 - accuracy: 0.5934 - val_loss: 0.2612 - val_accuracy: 0.8889\n",
            "Epoch 16/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2918 - accuracy: 0.5922 - val_loss: 0.2765 - val_accuracy: 0.8519\n",
            "Epoch 17/100\n",
            "27/27 [==============================] - 10s 354ms/step - loss: 0.2745 - accuracy: 0.5934 - val_loss: 0.2165 - val_accuracy: 0.8889\n",
            "Epoch 18/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.2803 - accuracy: 0.5922 - val_loss: 0.2531 - val_accuracy: 0.8148\n",
            "Epoch 19/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2732 - accuracy: 0.5922 - val_loss: 0.2649 - val_accuracy: 0.9630\n",
            "Epoch 20/100\n",
            "27/27 [==============================] - 10s 354ms/step - loss: 0.2677 - accuracy: 0.5922 - val_loss: 0.2212 - val_accuracy: 0.8889\n",
            "Epoch 21/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.2835 - accuracy: 0.5922 - val_loss: 0.2735 - val_accuracy: 0.8148\n",
            "Epoch 22/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2700 - accuracy: 0.5934 - val_loss: 0.2270 - val_accuracy: 0.8889\n",
            "Epoch 23/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2639 - accuracy: 0.5934 - val_loss: 0.1709 - val_accuracy: 0.8889\n",
            "Epoch 24/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.2663 - accuracy: 0.5934 - val_loss: 0.1919 - val_accuracy: 0.9259\n",
            "Epoch 25/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.2727 - accuracy: 0.5934 - val_loss: 0.1863 - val_accuracy: 0.9259\n",
            "Epoch 26/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.2659 - accuracy: 0.5934 - val_loss: 0.2077 - val_accuracy: 0.8889\n",
            "Epoch 27/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.2587 - accuracy: 0.5934 - val_loss: 0.3276 - val_accuracy: 0.8519\n",
            "Epoch 28/100\n",
            "27/27 [==============================] - 10s 353ms/step - loss: 0.2738 - accuracy: 0.5934 - val_loss: 0.1839 - val_accuracy: 0.8889\n",
            "Epoch 29/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.2597 - accuracy: 0.5934 - val_loss: 0.2239 - val_accuracy: 0.9259\n",
            "Epoch 30/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.2712 - accuracy: 0.5934 - val_loss: 0.2000 - val_accuracy: 0.8889\n",
            "Epoch 31/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.2630 - accuracy: 0.5934 - val_loss: 0.2157 - val_accuracy: 0.8519\n",
            "Epoch 32/100\n",
            "27/27 [==============================] - 10s 354ms/step - loss: 0.2647 - accuracy: 0.5934 - val_loss: 0.1972 - val_accuracy: 0.8889\n",
            "Epoch 33/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2650 - accuracy: 0.5934 - val_loss: 0.1884 - val_accuracy: 0.8889\n",
            "Epoch 34/100\n",
            "27/27 [==============================] - 10s 354ms/step - loss: 0.2649 - accuracy: 0.5922 - val_loss: 0.2144 - val_accuracy: 0.8519\n",
            "Epoch 35/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.2561 - accuracy: 0.5934 - val_loss: 0.1652 - val_accuracy: 0.8889\n",
            "Epoch 36/100\n",
            "27/27 [==============================] - 10s 354ms/step - loss: 0.2621 - accuracy: 0.5934 - val_loss: 0.2275 - val_accuracy: 0.8889\n",
            "Epoch 37/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.2565 - accuracy: 0.5934 - val_loss: 0.2505 - val_accuracy: 0.8889\n",
            "Epoch 38/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2546 - accuracy: 0.5934 - val_loss: 0.2267 - val_accuracy: 0.8889\n",
            "Epoch 39/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2544 - accuracy: 0.5934 - val_loss: 0.1873 - val_accuracy: 0.8889\n",
            "Epoch 40/100\n",
            "27/27 [==============================] - 10s 354ms/step - loss: 0.2512 - accuracy: 0.5934 - val_loss: 0.2780 - val_accuracy: 0.8519\n",
            "Epoch 41/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2519 - accuracy: 0.5934 - val_loss: 0.2276 - val_accuracy: 0.8889\n",
            "Epoch 42/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2535 - accuracy: 0.5934 - val_loss: 0.1926 - val_accuracy: 0.8889\n",
            "Epoch 43/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2521 - accuracy: 0.5934 - val_loss: 0.2613 - val_accuracy: 0.8148\n",
            "Epoch 44/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.2558 - accuracy: 0.5934 - val_loss: 0.3121 - val_accuracy: 0.8148\n",
            "Epoch 45/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2483 - accuracy: 0.5934 - val_loss: 0.1925 - val_accuracy: 0.8889\n",
            "Epoch 46/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2519 - accuracy: 0.5934 - val_loss: 0.2391 - val_accuracy: 0.8889\n",
            "Epoch 47/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.2483 - accuracy: 0.5934 - val_loss: 0.3068 - val_accuracy: 0.8889\n",
            "Epoch 48/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2545 - accuracy: 0.5934 - val_loss: 0.3040 - val_accuracy: 0.8519\n",
            "Epoch 49/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.2534 - accuracy: 0.5934 - val_loss: 0.4173 - val_accuracy: 0.8519\n",
            "Epoch 50/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.2474 - accuracy: 0.5934 - val_loss: 0.2656 - val_accuracy: 0.8519\n",
            "2/2 [==============================] - 2s 121ms/step - loss: 0.2226 - accuracy: 0.8529\n",
            "Epoch 1/100\n",
            "27/27 [==============================] - 17s 429ms/step - loss: 0.4763 - accuracy: 0.5116 - val_loss: 1.5241 - val_accuracy: 0.6667\n",
            "Epoch 2/100\n",
            "27/27 [==============================] - 10s 364ms/step - loss: 0.3715 - accuracy: 0.5521 - val_loss: 0.4531 - val_accuracy: 0.7407\n",
            "Epoch 3/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.3468 - accuracy: 0.5613 - val_loss: 0.5097 - val_accuracy: 0.7407\n",
            "Epoch 4/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.3438 - accuracy: 0.5613 - val_loss: 0.3397 - val_accuracy: 0.8519\n",
            "Epoch 5/100\n",
            "27/27 [==============================] - 10s 359ms/step - loss: 0.3353 - accuracy: 0.5660 - val_loss: 0.4101 - val_accuracy: 0.7778\n",
            "Epoch 6/100\n",
            "27/27 [==============================] - 10s 363ms/step - loss: 0.3261 - accuracy: 0.5706 - val_loss: 0.1974 - val_accuracy: 0.8889\n",
            "Epoch 7/100\n",
            "27/27 [==============================] - 10s 364ms/step - loss: 0.3128 - accuracy: 0.5683 - val_loss: 0.1937 - val_accuracy: 0.8889\n",
            "Epoch 8/100\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.2967 - accuracy: 0.5729 - val_loss: 0.1443 - val_accuracy: 0.9630\n",
            "Epoch 9/100\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.2975 - accuracy: 0.5718 - val_loss: 0.1547 - val_accuracy: 0.9630\n",
            "Epoch 10/100\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.2930 - accuracy: 0.5741 - val_loss: 0.1503 - val_accuracy: 0.9259\n",
            "Epoch 11/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.2898 - accuracy: 0.5718 - val_loss: 0.2111 - val_accuracy: 0.8889\n",
            "Epoch 12/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.2859 - accuracy: 0.5718 - val_loss: 0.1863 - val_accuracy: 0.9259\n",
            "Epoch 13/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.2768 - accuracy: 0.5741 - val_loss: 0.1846 - val_accuracy: 0.9259\n",
            "Epoch 14/100\n",
            "27/27 [==============================] - 10s 360ms/step - loss: 0.2802 - accuracy: 0.5741 - val_loss: 0.1627 - val_accuracy: 0.9259\n",
            "Epoch 15/100\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.2824 - accuracy: 0.5741 - val_loss: 0.1517 - val_accuracy: 0.9259\n",
            "Epoch 16/100\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.2720 - accuracy: 0.5741 - val_loss: 0.1677 - val_accuracy: 0.9259\n",
            "Epoch 17/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.2760 - accuracy: 0.5741 - val_loss: 0.1565 - val_accuracy: 0.9630\n",
            "Epoch 18/100\n",
            "27/27 [==============================] - 10s 360ms/step - loss: 0.2764 - accuracy: 0.5741 - val_loss: 0.1612 - val_accuracy: 0.9259\n",
            "Epoch 19/100\n",
            "27/27 [==============================] - 10s 360ms/step - loss: 0.2674 - accuracy: 0.5741 - val_loss: 0.1531 - val_accuracy: 0.9630\n",
            "Epoch 20/100\n",
            "27/27 [==============================] - 10s 365ms/step - loss: 0.2749 - accuracy: 0.5741 - val_loss: 0.1399 - val_accuracy: 0.9630\n",
            "Epoch 21/100\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.2790 - accuracy: 0.5729 - val_loss: 0.1543 - val_accuracy: 0.9259\n",
            "Epoch 22/100\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.2660 - accuracy: 0.5741 - val_loss: 0.1887 - val_accuracy: 0.9259\n",
            "Epoch 23/100\n",
            "27/27 [==============================] - 10s 363ms/step - loss: 0.2627 - accuracy: 0.5741 - val_loss: 0.1878 - val_accuracy: 0.9259\n",
            "Epoch 24/100\n",
            "27/27 [==============================] - 10s 360ms/step - loss: 0.2707 - accuracy: 0.5741 - val_loss: 0.1998 - val_accuracy: 0.9259\n",
            "Epoch 25/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.2647 - accuracy: 0.5741 - val_loss: 0.1801 - val_accuracy: 0.9630\n",
            "Epoch 26/100\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.2661 - accuracy: 0.5741 - val_loss: 0.1441 - val_accuracy: 0.9630\n",
            "Epoch 27/100\n",
            "27/27 [==============================] - 10s 360ms/step - loss: 0.2579 - accuracy: 0.5741 - val_loss: 0.1969 - val_accuracy: 0.9630\n",
            "Epoch 28/100\n",
            "27/27 [==============================] - 10s 358ms/step - loss: 0.2618 - accuracy: 0.5741 - val_loss: 0.1947 - val_accuracy: 0.9630\n",
            "Epoch 29/100\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.2606 - accuracy: 0.5741 - val_loss: 0.2006 - val_accuracy: 0.9630\n",
            "Epoch 30/100\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.2647 - accuracy: 0.5741 - val_loss: 0.1821 - val_accuracy: 0.9259\n",
            "Epoch 31/100\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.2602 - accuracy: 0.5741 - val_loss: 0.1928 - val_accuracy: 0.9259\n",
            "Epoch 32/100\n",
            "27/27 [==============================] - 10s 359ms/step - loss: 0.2594 - accuracy: 0.5741 - val_loss: 0.1670 - val_accuracy: 0.9630\n",
            "Epoch 33/100\n",
            "27/27 [==============================] - 10s 363ms/step - loss: 0.2630 - accuracy: 0.5741 - val_loss: 0.1260 - val_accuracy: 0.9630\n",
            "Epoch 34/100\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.2647 - accuracy: 0.5741 - val_loss: 0.1767 - val_accuracy: 0.9259\n",
            "Epoch 35/100\n",
            "27/27 [==============================] - 10s 363ms/step - loss: 0.2609 - accuracy: 0.5741 - val_loss: 0.1672 - val_accuracy: 0.9259\n",
            "Epoch 36/100\n",
            "27/27 [==============================] - 10s 359ms/step - loss: 0.2576 - accuracy: 0.5741 - val_loss: 0.1760 - val_accuracy: 0.9259\n",
            "Epoch 37/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.2553 - accuracy: 0.5741 - val_loss: 0.1958 - val_accuracy: 0.9259\n",
            "Epoch 38/100\n",
            "27/27 [==============================] - 10s 360ms/step - loss: 0.2617 - accuracy: 0.5741 - val_loss: 0.1865 - val_accuracy: 0.9259\n",
            "Epoch 39/100\n",
            "27/27 [==============================] - 10s 360ms/step - loss: 0.2540 - accuracy: 0.5741 - val_loss: 0.1934 - val_accuracy: 0.9259\n",
            "Epoch 40/100\n",
            "27/27 [==============================] - 10s 360ms/step - loss: 0.2641 - accuracy: 0.5741 - val_loss: 0.1978 - val_accuracy: 0.9259\n",
            "Epoch 41/100\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.2513 - accuracy: 0.5741 - val_loss: 0.2008 - val_accuracy: 0.9630\n",
            "Epoch 42/100\n",
            "27/27 [==============================] - 10s 359ms/step - loss: 0.2571 - accuracy: 0.5741 - val_loss: 0.1825 - val_accuracy: 0.9630\n",
            "Epoch 43/100\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.2545 - accuracy: 0.5741 - val_loss: 0.2129 - val_accuracy: 0.9259\n",
            "Epoch 44/100\n",
            "27/27 [==============================] - 10s 359ms/step - loss: 0.2571 - accuracy: 0.5741 - val_loss: 0.1922 - val_accuracy: 0.9259\n",
            "Epoch 45/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.2575 - accuracy: 0.5729 - val_loss: 0.1894 - val_accuracy: 0.9630\n",
            "Epoch 46/100\n",
            "27/27 [==============================] - 10s 359ms/step - loss: 0.2513 - accuracy: 0.5741 - val_loss: 0.1655 - val_accuracy: 0.9259\n",
            "Epoch 47/100\n",
            "27/27 [==============================] - 10s 360ms/step - loss: 0.2513 - accuracy: 0.5741 - val_loss: 0.2269 - val_accuracy: 0.9259\n",
            "Epoch 48/100\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.2593 - accuracy: 0.5741 - val_loss: 0.2062 - val_accuracy: 0.9259\n",
            "2/2 [==============================] - 2s 124ms/step - loss: 0.3028 - accuracy: 0.7941\n",
            "Epoch 1/100\n",
            "27/27 [==============================] - 17s 407ms/step - loss: 0.5383 - accuracy: 0.4604 - val_loss: 1.0634 - val_accuracy: 0.6667\n",
            "Epoch 2/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.4319 - accuracy: 0.5175 - val_loss: 0.4673 - val_accuracy: 0.8148\n",
            "Epoch 3/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.3847 - accuracy: 0.5326 - val_loss: 0.3260 - val_accuracy: 0.8519\n",
            "Epoch 4/100\n",
            "27/27 [==============================] - 10s 359ms/step - loss: 0.3671 - accuracy: 0.5408 - val_loss: 0.3221 - val_accuracy: 0.8148\n",
            "Epoch 5/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.3460 - accuracy: 0.5408 - val_loss: 0.2209 - val_accuracy: 0.9259\n",
            "Epoch 6/100\n",
            "27/27 [==============================] - 10s 358ms/step - loss: 0.3320 - accuracy: 0.5490 - val_loss: 0.1967 - val_accuracy: 0.9259\n",
            "Epoch 7/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.3287 - accuracy: 0.5466 - val_loss: 0.2403 - val_accuracy: 0.8889\n",
            "Epoch 8/100\n",
            "27/27 [==============================] - 10s 359ms/step - loss: 0.3224 - accuracy: 0.5513 - val_loss: 0.1775 - val_accuracy: 0.9630\n",
            "Epoch 9/100\n",
            "27/27 [==============================] - 10s 359ms/step - loss: 0.3142 - accuracy: 0.5524 - val_loss: 0.1694 - val_accuracy: 0.9259\n",
            "Epoch 10/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.3172 - accuracy: 0.5490 - val_loss: 0.1868 - val_accuracy: 0.9630\n",
            "Epoch 11/100\n",
            "27/27 [==============================] - 10s 359ms/step - loss: 0.3040 - accuracy: 0.5501 - val_loss: 0.1508 - val_accuracy: 0.9630\n",
            "Epoch 12/100\n",
            "27/27 [==============================] - 10s 353ms/step - loss: 0.3047 - accuracy: 0.5513 - val_loss: 0.1575 - val_accuracy: 0.9630\n",
            "Epoch 13/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.3070 - accuracy: 0.5524 - val_loss: 0.1873 - val_accuracy: 0.9259\n",
            "Epoch 14/100\n",
            "27/27 [==============================] - 10s 354ms/step - loss: 0.3021 - accuracy: 0.5513 - val_loss: 0.1665 - val_accuracy: 0.9630\n",
            "Epoch 15/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2976 - accuracy: 0.5524 - val_loss: 0.1895 - val_accuracy: 0.9630\n",
            "Epoch 16/100\n",
            "27/27 [==============================] - 10s 354ms/step - loss: 0.2979 - accuracy: 0.5513 - val_loss: 0.1907 - val_accuracy: 0.9630\n",
            "Epoch 17/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.2898 - accuracy: 0.5524 - val_loss: 0.1915 - val_accuracy: 0.9630\n",
            "Epoch 18/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2943 - accuracy: 0.5524 - val_loss: 0.1868 - val_accuracy: 0.9630\n",
            "Epoch 19/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2868 - accuracy: 0.5524 - val_loss: 0.1722 - val_accuracy: 0.9630\n",
            "Epoch 20/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.2965 - accuracy: 0.5478 - val_loss: 0.1692 - val_accuracy: 0.9630\n",
            "Epoch 21/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.2873 - accuracy: 0.5524 - val_loss: 0.1493 - val_accuracy: 0.9630\n",
            "Epoch 22/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.2835 - accuracy: 0.5524 - val_loss: 0.1587 - val_accuracy: 0.9630\n",
            "Epoch 23/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.2834 - accuracy: 0.5513 - val_loss: 0.1740 - val_accuracy: 0.9630\n",
            "Epoch 24/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.2852 - accuracy: 0.5524 - val_loss: 0.2130 - val_accuracy: 0.9630\n",
            "Epoch 25/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2957 - accuracy: 0.5524 - val_loss: 0.1769 - val_accuracy: 0.9630\n",
            "Epoch 26/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.2820 - accuracy: 0.5513 - val_loss: 0.2117 - val_accuracy: 0.9630\n",
            "Epoch 27/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.2817 - accuracy: 0.5524 - val_loss: 0.1893 - val_accuracy: 0.8889\n",
            "Epoch 28/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.3086 - accuracy: 0.5513 - val_loss: 0.1511 - val_accuracy: 0.9630\n",
            "Epoch 29/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.2894 - accuracy: 0.5524 - val_loss: 0.1699 - val_accuracy: 0.9630\n",
            "Epoch 30/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2772 - accuracy: 0.5524 - val_loss: 0.1643 - val_accuracy: 0.9630\n",
            "Epoch 31/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.2766 - accuracy: 0.5524 - val_loss: 0.1509 - val_accuracy: 0.9630\n",
            "Epoch 32/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.2754 - accuracy: 0.5513 - val_loss: 0.2213 - val_accuracy: 0.9630\n",
            "Epoch 33/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.2732 - accuracy: 0.5524 - val_loss: 0.1456 - val_accuracy: 0.9630\n",
            "Epoch 34/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.2729 - accuracy: 0.5524 - val_loss: 0.1675 - val_accuracy: 0.9630\n",
            "Epoch 35/100\n",
            "27/27 [==============================] - 10s 354ms/step - loss: 0.2840 - accuracy: 0.5524 - val_loss: 0.1844 - val_accuracy: 0.9630\n",
            "Epoch 36/100\n",
            "27/27 [==============================] - 10s 358ms/step - loss: 0.2727 - accuracy: 0.5524 - val_loss: 0.1452 - val_accuracy: 0.9630\n",
            "Epoch 37/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2684 - accuracy: 0.5524 - val_loss: 0.1924 - val_accuracy: 0.9630\n",
            "Epoch 38/100\n",
            "27/27 [==============================] - 10s 358ms/step - loss: 0.2716 - accuracy: 0.5524 - val_loss: 0.1569 - val_accuracy: 0.9630\n",
            "Epoch 39/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2758 - accuracy: 0.5524 - val_loss: 0.1607 - val_accuracy: 0.9630\n",
            "Epoch 40/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2707 - accuracy: 0.5524 - val_loss: 0.1578 - val_accuracy: 0.9630\n",
            "Epoch 41/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.2746 - accuracy: 0.5524 - val_loss: 0.1897 - val_accuracy: 0.9630\n",
            "Epoch 42/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2701 - accuracy: 0.5524 - val_loss: 0.1748 - val_accuracy: 0.9630\n",
            "Epoch 43/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2718 - accuracy: 0.5524 - val_loss: 0.1749 - val_accuracy: 0.9630\n",
            "Epoch 44/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.2718 - accuracy: 0.5524 - val_loss: 0.1727 - val_accuracy: 0.9630\n",
            "Epoch 45/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.2759 - accuracy: 0.5524 - val_loss: 0.2008 - val_accuracy: 0.9630\n",
            "Epoch 46/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.2729 - accuracy: 0.5524 - val_loss: 0.1886 - val_accuracy: 0.9630\n",
            "Epoch 47/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2723 - accuracy: 0.5524 - val_loss: 0.1873 - val_accuracy: 0.9630\n",
            "Epoch 48/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2637 - accuracy: 0.5524 - val_loss: 0.2165 - val_accuracy: 0.9630\n",
            "Epoch 49/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.2621 - accuracy: 0.5524 - val_loss: 0.2172 - val_accuracy: 0.9630\n",
            "Epoch 50/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.2728 - accuracy: 0.5524 - val_loss: 0.1656 - val_accuracy: 0.9630\n",
            "Epoch 51/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.2698 - accuracy: 0.5524 - val_loss: 0.1978 - val_accuracy: 0.9630\n",
            "2/2 [==============================] - 2s 124ms/step - loss: 0.1989 - accuracy: 0.9412\n",
            "[0.9470588088035583, 0.9529411673545838, 0.9058823466300965]\n",
            "[0.9386747079624046, 0.9458003581442472, 0.8964876214112817]\n",
            "Epoch 1/100\n",
            "28/28 [==============================] - 18s 407ms/step - loss: 0.5426 - accuracy: 0.4726 - val_loss: 0.2989 - val_accuracy: 0.8889\n",
            "Epoch 2/100\n",
            "28/28 [==============================] - 10s 356ms/step - loss: 0.4256 - accuracy: 0.5308 - val_loss: 0.2843 - val_accuracy: 0.8889\n",
            "Epoch 3/100\n",
            "28/28 [==============================] - 10s 356ms/step - loss: 0.3978 - accuracy: 0.5342 - val_loss: 0.1726 - val_accuracy: 0.9259\n",
            "Epoch 4/100\n",
            "28/28 [==============================] - 10s 356ms/step - loss: 0.3751 - accuracy: 0.5400 - val_loss: 0.2346 - val_accuracy: 0.9259\n",
            "Epoch 5/100\n",
            "28/28 [==============================] - 10s 357ms/step - loss: 0.3613 - accuracy: 0.5457 - val_loss: 0.1487 - val_accuracy: 0.9259\n",
            "Epoch 6/100\n",
            "28/28 [==============================] - 10s 357ms/step - loss: 0.3432 - accuracy: 0.5571 - val_loss: 0.1279 - val_accuracy: 0.9259\n",
            "Epoch 7/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.3460 - accuracy: 0.5457 - val_loss: 0.1877 - val_accuracy: 0.9630\n",
            "Epoch 8/100\n",
            "28/28 [==============================] - 10s 355ms/step - loss: 0.3424 - accuracy: 0.5514 - val_loss: 0.2661 - val_accuracy: 0.8889\n",
            "Epoch 9/100\n",
            "28/28 [==============================] - 10s 355ms/step - loss: 0.3215 - accuracy: 0.5594 - val_loss: 0.1479 - val_accuracy: 0.9259\n",
            "Epoch 10/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.3165 - accuracy: 0.5559 - val_loss: 0.1721 - val_accuracy: 0.9259\n",
            "Epoch 11/100\n",
            "28/28 [==============================] - 10s 355ms/step - loss: 0.3104 - accuracy: 0.5582 - val_loss: 0.2158 - val_accuracy: 0.8889\n",
            "Epoch 12/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2991 - accuracy: 0.5616 - val_loss: 0.1517 - val_accuracy: 0.9259\n",
            "Epoch 13/100\n",
            "28/28 [==============================] - 10s 358ms/step - loss: 0.3105 - accuracy: 0.5605 - val_loss: 0.0778 - val_accuracy: 1.0000\n",
            "Epoch 14/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2986 - accuracy: 0.5594 - val_loss: 0.1393 - val_accuracy: 0.9259\n",
            "Epoch 15/100\n",
            "28/28 [==============================] - 10s 355ms/step - loss: 0.2989 - accuracy: 0.5616 - val_loss: 0.1334 - val_accuracy: 1.0000\n",
            "Epoch 16/100\n",
            "28/28 [==============================] - 10s 356ms/step - loss: 0.2940 - accuracy: 0.5616 - val_loss: 0.2412 - val_accuracy: 0.8519\n",
            "Epoch 17/100\n",
            "28/28 [==============================] - 10s 356ms/step - loss: 0.2998 - accuracy: 0.5594 - val_loss: 0.1219 - val_accuracy: 0.9259\n",
            "Epoch 18/100\n",
            "28/28 [==============================] - 10s 356ms/step - loss: 0.2860 - accuracy: 0.5616 - val_loss: 0.1873 - val_accuracy: 0.9259\n",
            "Epoch 19/100\n",
            "28/28 [==============================] - 10s 356ms/step - loss: 0.2922 - accuracy: 0.5605 - val_loss: 0.2014 - val_accuracy: 0.8889\n",
            "Epoch 20/100\n",
            "28/28 [==============================] - 10s 355ms/step - loss: 0.2898 - accuracy: 0.5616 - val_loss: 0.1658 - val_accuracy: 0.9259\n",
            "Epoch 21/100\n",
            "28/28 [==============================] - 10s 355ms/step - loss: 0.2881 - accuracy: 0.5616 - val_loss: 0.3110 - val_accuracy: 0.8519\n",
            "Epoch 22/100\n",
            "28/28 [==============================] - 10s 355ms/step - loss: 0.2927 - accuracy: 0.5616 - val_loss: 0.2179 - val_accuracy: 0.8889\n",
            "Epoch 23/100\n",
            "28/28 [==============================] - 10s 356ms/step - loss: 0.2901 - accuracy: 0.5616 - val_loss: 0.1419 - val_accuracy: 0.9259\n",
            "Epoch 24/100\n",
            "28/28 [==============================] - 10s 355ms/step - loss: 0.2893 - accuracy: 0.5616 - val_loss: 0.1798 - val_accuracy: 0.8889\n",
            "Epoch 25/100\n",
            "28/28 [==============================] - 10s 356ms/step - loss: 0.2845 - accuracy: 0.5605 - val_loss: 0.1665 - val_accuracy: 0.8889\n",
            "Epoch 26/100\n",
            "28/28 [==============================] - 10s 353ms/step - loss: 0.2863 - accuracy: 0.5616 - val_loss: 0.3244 - val_accuracy: 0.8519\n",
            "Epoch 27/100\n",
            "28/28 [==============================] - 10s 353ms/step - loss: 0.2819 - accuracy: 0.5605 - val_loss: 0.1700 - val_accuracy: 0.9630\n",
            "Epoch 28/100\n",
            "28/28 [==============================] - 10s 356ms/step - loss: 0.2919 - accuracy: 0.5616 - val_loss: 0.1537 - val_accuracy: 0.9259\n",
            "2/2 [==============================] - 2s 122ms/step - loss: 0.1004 - accuracy: 0.9706\n",
            "Epoch 1/100\n",
            "28/28 [==============================] - 18s 407ms/step - loss: 0.4963 - accuracy: 0.5310 - val_loss: 0.3709 - val_accuracy: 0.7778\n",
            "Epoch 2/100\n",
            "28/28 [==============================] - 10s 352ms/step - loss: 0.4150 - accuracy: 0.5621 - val_loss: 0.4257 - val_accuracy: 0.7778\n",
            "Epoch 3/100\n",
            "28/28 [==============================] - 10s 357ms/step - loss: 0.3553 - accuracy: 0.5793 - val_loss: 0.3231 - val_accuracy: 0.8519\n",
            "Epoch 4/100\n",
            "28/28 [==============================] - 10s 355ms/step - loss: 0.3439 - accuracy: 0.5828 - val_loss: 0.1960 - val_accuracy: 0.9630\n",
            "Epoch 5/100\n",
            "28/28 [==============================] - 10s 352ms/step - loss: 0.3220 - accuracy: 0.5966 - val_loss: 0.1983 - val_accuracy: 0.9630\n",
            "Epoch 6/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.3098 - accuracy: 0.5908 - val_loss: 0.2175 - val_accuracy: 0.9259\n",
            "Epoch 7/100\n",
            "28/28 [==============================] - 10s 356ms/step - loss: 0.2975 - accuracy: 0.6000 - val_loss: 0.1593 - val_accuracy: 0.9259\n",
            "Epoch 8/100\n",
            "28/28 [==============================] - 10s 355ms/step - loss: 0.3081 - accuracy: 0.5954 - val_loss: 0.2941 - val_accuracy: 0.8889\n",
            "Epoch 9/100\n",
            "28/28 [==============================] - 10s 357ms/step - loss: 0.3032 - accuracy: 0.5977 - val_loss: 0.1256 - val_accuracy: 0.9630\n",
            "Epoch 10/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2955 - accuracy: 0.5989 - val_loss: 0.1645 - val_accuracy: 0.9259\n",
            "Epoch 11/100\n",
            "28/28 [==============================] - 10s 355ms/step - loss: 0.2968 - accuracy: 0.5954 - val_loss: 0.1348 - val_accuracy: 0.9630\n",
            "Epoch 12/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2782 - accuracy: 0.6011 - val_loss: 0.1784 - val_accuracy: 0.8889\n",
            "Epoch 13/100\n",
            "28/28 [==============================] - 10s 353ms/step - loss: 0.2800 - accuracy: 0.6023 - val_loss: 0.1311 - val_accuracy: 0.9630\n",
            "Epoch 14/100\n",
            "28/28 [==============================] - 10s 356ms/step - loss: 0.2817 - accuracy: 0.6000 - val_loss: 0.1107 - val_accuracy: 0.9630\n",
            "Epoch 15/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2867 - accuracy: 0.6000 - val_loss: 0.1228 - val_accuracy: 0.9630\n",
            "Epoch 16/100\n",
            "28/28 [==============================] - 10s 356ms/step - loss: 0.2782 - accuracy: 0.6000 - val_loss: 0.0744 - val_accuracy: 1.0000\n",
            "Epoch 17/100\n",
            "28/28 [==============================] - 10s 356ms/step - loss: 0.2927 - accuracy: 0.6000 - val_loss: 0.1136 - val_accuracy: 0.9630\n",
            "Epoch 18/100\n",
            "28/28 [==============================] - 10s 353ms/step - loss: 0.2737 - accuracy: 0.6023 - val_loss: 0.1091 - val_accuracy: 0.9630\n",
            "Epoch 19/100\n",
            "28/28 [==============================] - 10s 355ms/step - loss: 0.2637 - accuracy: 0.6023 - val_loss: 0.0950 - val_accuracy: 0.9630\n",
            "Epoch 20/100\n",
            "28/28 [==============================] - 10s 353ms/step - loss: 0.2717 - accuracy: 0.6011 - val_loss: 0.1030 - val_accuracy: 1.0000\n",
            "Epoch 21/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2714 - accuracy: 0.6023 - val_loss: 0.1524 - val_accuracy: 0.9259\n",
            "Epoch 22/100\n",
            "28/28 [==============================] - 10s 355ms/step - loss: 0.2647 - accuracy: 0.6011 - val_loss: 0.0946 - val_accuracy: 1.0000\n",
            "Epoch 23/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2678 - accuracy: 0.6011 - val_loss: 0.0956 - val_accuracy: 0.9630\n",
            "Epoch 24/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2683 - accuracy: 0.6011 - val_loss: 0.0861 - val_accuracy: 0.9630\n",
            "Epoch 25/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2616 - accuracy: 0.6011 - val_loss: 0.1119 - val_accuracy: 0.9630\n",
            "Epoch 26/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2666 - accuracy: 0.6023 - val_loss: 0.1122 - val_accuracy: 1.0000\n",
            "Epoch 27/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2641 - accuracy: 0.6011 - val_loss: 0.1324 - val_accuracy: 0.9630\n",
            "Epoch 28/100\n",
            "28/28 [==============================] - 10s 353ms/step - loss: 0.2686 - accuracy: 0.6000 - val_loss: 0.1013 - val_accuracy: 1.0000\n",
            "Epoch 29/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2802 - accuracy: 0.6000 - val_loss: 0.1132 - val_accuracy: 0.9630\n",
            "Epoch 30/100\n",
            "28/28 [==============================] - 10s 355ms/step - loss: 0.2686 - accuracy: 0.6023 - val_loss: 0.0651 - val_accuracy: 1.0000\n",
            "Epoch 31/100\n",
            "28/28 [==============================] - 10s 351ms/step - loss: 0.2657 - accuracy: 0.6000 - val_loss: 0.0784 - val_accuracy: 1.0000\n",
            "Epoch 32/100\n",
            "28/28 [==============================] - 10s 353ms/step - loss: 0.2611 - accuracy: 0.6023 - val_loss: 0.1150 - val_accuracy: 0.9630\n",
            "Epoch 33/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2577 - accuracy: 0.6023 - val_loss: 0.1182 - val_accuracy: 0.9259\n",
            "Epoch 34/100\n",
            "28/28 [==============================] - 10s 355ms/step - loss: 0.2490 - accuracy: 0.6023 - val_loss: 0.1245 - val_accuracy: 0.9259\n",
            "Epoch 35/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2587 - accuracy: 0.6023 - val_loss: 0.1060 - val_accuracy: 0.9630\n",
            "Epoch 36/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2557 - accuracy: 0.6023 - val_loss: 0.0975 - val_accuracy: 1.0000\n",
            "Epoch 37/100\n",
            "28/28 [==============================] - 10s 355ms/step - loss: 0.2579 - accuracy: 0.6023 - val_loss: 0.1259 - val_accuracy: 0.9630\n",
            "Epoch 38/100\n",
            "28/28 [==============================] - 10s 355ms/step - loss: 0.2579 - accuracy: 0.6011 - val_loss: 0.1787 - val_accuracy: 0.9259\n",
            "Epoch 39/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2514 - accuracy: 0.6023 - val_loss: 0.1694 - val_accuracy: 0.8889\n",
            "Epoch 40/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2461 - accuracy: 0.6023 - val_loss: 0.1084 - val_accuracy: 0.9630\n",
            "Epoch 41/100\n",
            "28/28 [==============================] - 10s 355ms/step - loss: 0.2471 - accuracy: 0.6023 - val_loss: 0.1173 - val_accuracy: 0.9259\n",
            "Epoch 42/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2452 - accuracy: 0.6023 - val_loss: 0.1121 - val_accuracy: 0.9630\n",
            "Epoch 43/100\n",
            "28/28 [==============================] - 10s 353ms/step - loss: 0.2439 - accuracy: 0.6023 - val_loss: 0.1081 - val_accuracy: 0.9630\n",
            "Epoch 44/100\n",
            "28/28 [==============================] - 10s 355ms/step - loss: 0.2493 - accuracy: 0.6011 - val_loss: 0.1695 - val_accuracy: 0.8889\n",
            "Epoch 45/100\n",
            "28/28 [==============================] - 10s 355ms/step - loss: 0.2618 - accuracy: 0.6000 - val_loss: 0.1363 - val_accuracy: 0.9259\n",
            "2/2 [==============================] - 2s 121ms/step - loss: 0.1458 - accuracy: 0.9118\n",
            "Epoch 1/100\n",
            "28/28 [==============================] - 18s 408ms/step - loss: 0.5445 - accuracy: 0.4698 - val_loss: 0.1597 - val_accuracy: 0.9630\n",
            "Epoch 2/100\n",
            "28/28 [==============================] - 10s 357ms/step - loss: 0.4233 - accuracy: 0.5190 - val_loss: 0.1789 - val_accuracy: 0.9630\n",
            "Epoch 3/100\n",
            "28/28 [==============================] - 10s 360ms/step - loss: 0.3669 - accuracy: 0.5481 - val_loss: 0.1488 - val_accuracy: 0.9630\n",
            "Epoch 4/100\n",
            "28/28 [==============================] - 10s 357ms/step - loss: 0.3456 - accuracy: 0.5503 - val_loss: 0.1792 - val_accuracy: 0.9259\n",
            "Epoch 5/100\n",
            "28/28 [==============================] - 10s 358ms/step - loss: 0.3413 - accuracy: 0.5526 - val_loss: 0.1323 - val_accuracy: 0.9630\n",
            "Epoch 6/100\n",
            "28/28 [==============================] - 10s 357ms/step - loss: 0.3308 - accuracy: 0.5537 - val_loss: 0.1429 - val_accuracy: 0.9259\n",
            "Epoch 7/100\n",
            "28/28 [==============================] - 10s 356ms/step - loss: 0.3207 - accuracy: 0.5582 - val_loss: 0.1366 - val_accuracy: 0.9630\n",
            "Epoch 8/100\n",
            "28/28 [==============================] - 10s 358ms/step - loss: 0.3203 - accuracy: 0.5582 - val_loss: 0.1261 - val_accuracy: 0.9630\n",
            "Epoch 9/100\n",
            "28/28 [==============================] - 10s 360ms/step - loss: 0.3089 - accuracy: 0.5604 - val_loss: 0.1053 - val_accuracy: 0.9630\n",
            "Epoch 10/100\n",
            "28/28 [==============================] - 10s 357ms/step - loss: 0.3179 - accuracy: 0.5570 - val_loss: 0.1095 - val_accuracy: 0.9630\n",
            "Epoch 11/100\n",
            "28/28 [==============================] - 10s 357ms/step - loss: 0.3022 - accuracy: 0.5615 - val_loss: 0.0951 - val_accuracy: 0.9630\n",
            "Epoch 12/100\n",
            "28/28 [==============================] - 10s 356ms/step - loss: 0.3029 - accuracy: 0.5593 - val_loss: 0.1191 - val_accuracy: 0.9630\n",
            "Epoch 13/100\n",
            "28/28 [==============================] - 10s 358ms/step - loss: 0.3081 - accuracy: 0.5604 - val_loss: 0.0888 - val_accuracy: 0.9630\n",
            "Epoch 14/100\n",
            "28/28 [==============================] - 10s 358ms/step - loss: 0.2960 - accuracy: 0.5604 - val_loss: 0.0727 - val_accuracy: 0.9630\n",
            "Epoch 15/100\n",
            "28/28 [==============================] - 10s 357ms/step - loss: 0.2929 - accuracy: 0.5604 - val_loss: 0.0882 - val_accuracy: 0.9630\n",
            "Epoch 16/100\n",
            "28/28 [==============================] - 10s 356ms/step - loss: 0.2928 - accuracy: 0.5593 - val_loss: 0.0845 - val_accuracy: 0.9630\n",
            "Epoch 17/100\n",
            "28/28 [==============================] - 10s 357ms/step - loss: 0.2921 - accuracy: 0.5604 - val_loss: 0.0840 - val_accuracy: 0.9630\n",
            "Epoch 18/100\n",
            "28/28 [==============================] - 10s 358ms/step - loss: 0.2894 - accuracy: 0.5604 - val_loss: 0.0980 - val_accuracy: 0.9630\n",
            "Epoch 19/100\n",
            "28/28 [==============================] - 10s 358ms/step - loss: 0.2884 - accuracy: 0.5615 - val_loss: 0.0865 - val_accuracy: 0.9630\n",
            "Epoch 20/100\n",
            "28/28 [==============================] - 10s 356ms/step - loss: 0.2874 - accuracy: 0.5615 - val_loss: 0.0861 - val_accuracy: 0.9630\n",
            "Epoch 21/100\n",
            "28/28 [==============================] - 10s 355ms/step - loss: 0.2884 - accuracy: 0.5615 - val_loss: 0.0870 - val_accuracy: 0.9630\n",
            "Epoch 22/100\n",
            "28/28 [==============================] - 10s 356ms/step - loss: 0.2724 - accuracy: 0.5615 - val_loss: 0.0781 - val_accuracy: 0.9630\n",
            "Epoch 23/100\n",
            "28/28 [==============================] - 10s 356ms/step - loss: 0.2788 - accuracy: 0.5615 - val_loss: 0.1021 - val_accuracy: 0.9630\n",
            "Epoch 24/100\n",
            "28/28 [==============================] - 10s 357ms/step - loss: 0.2813 - accuracy: 0.5615 - val_loss: 0.1081 - val_accuracy: 0.9630\n",
            "Epoch 25/100\n",
            "28/28 [==============================] - 10s 358ms/step - loss: 0.2796 - accuracy: 0.5615 - val_loss: 0.0892 - val_accuracy: 0.9630\n",
            "Epoch 26/100\n",
            "28/28 [==============================] - 10s 358ms/step - loss: 0.2750 - accuracy: 0.5615 - val_loss: 0.0706 - val_accuracy: 0.9630\n",
            "Epoch 27/100\n",
            "28/28 [==============================] - 10s 357ms/step - loss: 0.2750 - accuracy: 0.5615 - val_loss: 0.0826 - val_accuracy: 0.9630\n",
            "Epoch 28/100\n",
            "28/28 [==============================] - 10s 358ms/step - loss: 0.2764 - accuracy: 0.5615 - val_loss: 0.0857 - val_accuracy: 0.9630\n",
            "Epoch 29/100\n",
            "28/28 [==============================] - 10s 356ms/step - loss: 0.2748 - accuracy: 0.5615 - val_loss: 0.0916 - val_accuracy: 0.9630\n",
            "Epoch 30/100\n",
            "28/28 [==============================] - 10s 356ms/step - loss: 0.2723 - accuracy: 0.5615 - val_loss: 0.0908 - val_accuracy: 0.9630\n",
            "Epoch 31/100\n",
            "28/28 [==============================] - 10s 357ms/step - loss: 0.2755 - accuracy: 0.5615 - val_loss: 0.0812 - val_accuracy: 0.9630\n",
            "Epoch 32/100\n",
            "28/28 [==============================] - 10s 357ms/step - loss: 0.2730 - accuracy: 0.5615 - val_loss: 0.0901 - val_accuracy: 0.9630\n",
            "Epoch 33/100\n",
            "28/28 [==============================] - 10s 359ms/step - loss: 0.2703 - accuracy: 0.5615 - val_loss: 0.0599 - val_accuracy: 1.0000\n",
            "Epoch 34/100\n",
            "28/28 [==============================] - 10s 358ms/step - loss: 0.2697 - accuracy: 0.5615 - val_loss: 0.1230 - val_accuracy: 1.0000\n",
            "Epoch 35/100\n",
            "28/28 [==============================] - 10s 357ms/step - loss: 0.2683 - accuracy: 0.5615 - val_loss: 0.0913 - val_accuracy: 0.9630\n",
            "Epoch 36/100\n",
            "28/28 [==============================] - 10s 356ms/step - loss: 0.2695 - accuracy: 0.5615 - val_loss: 0.1025 - val_accuracy: 0.9630\n",
            "Epoch 37/100\n",
            "28/28 [==============================] - 10s 357ms/step - loss: 0.2714 - accuracy: 0.5615 - val_loss: 0.0878 - val_accuracy: 0.9630\n",
            "Epoch 38/100\n",
            "28/28 [==============================] - 10s 357ms/step - loss: 0.2680 - accuracy: 0.5615 - val_loss: 0.1010 - val_accuracy: 0.9630\n",
            "Epoch 39/100\n",
            "28/28 [==============================] - 10s 355ms/step - loss: 0.2629 - accuracy: 0.5615 - val_loss: 0.0815 - val_accuracy: 0.9630\n",
            "Epoch 40/100\n",
            "28/28 [==============================] - 10s 357ms/step - loss: 0.2664 - accuracy: 0.5615 - val_loss: 0.0837 - val_accuracy: 0.9630\n",
            "Epoch 41/100\n",
            "28/28 [==============================] - 10s 356ms/step - loss: 0.2703 - accuracy: 0.5615 - val_loss: 0.0799 - val_accuracy: 0.9630\n",
            "Epoch 42/100\n",
            "28/28 [==============================] - 10s 355ms/step - loss: 0.2717 - accuracy: 0.5615 - val_loss: 0.0840 - val_accuracy: 0.9630\n",
            "Epoch 43/100\n",
            "28/28 [==============================] - 10s 358ms/step - loss: 0.2693 - accuracy: 0.5615 - val_loss: 0.1007 - val_accuracy: 0.9630\n",
            "Epoch 44/100\n",
            "28/28 [==============================] - 10s 357ms/step - loss: 0.2666 - accuracy: 0.5615 - val_loss: 0.1229 - val_accuracy: 0.9630\n",
            "Epoch 45/100\n",
            "28/28 [==============================] - 10s 357ms/step - loss: 0.2654 - accuracy: 0.5615 - val_loss: 0.1012 - val_accuracy: 1.0000\n",
            "Epoch 46/100\n",
            "28/28 [==============================] - 10s 356ms/step - loss: 0.2650 - accuracy: 0.5615 - val_loss: 0.0897 - val_accuracy: 0.9630\n",
            "Epoch 47/100\n",
            "28/28 [==============================] - 10s 356ms/step - loss: 0.2652 - accuracy: 0.5615 - val_loss: 0.1265 - val_accuracy: 0.9630\n",
            "Epoch 48/100\n",
            "28/28 [==============================] - 10s 357ms/step - loss: 0.2615 - accuracy: 0.5615 - val_loss: 0.1059 - val_accuracy: 0.9630\n",
            "2/2 [==============================] - 2s 135ms/step - loss: 0.0718 - accuracy: 1.0000\n",
            "Epoch 1/100\n",
            "27/27 [==============================] - 17s 411ms/step - loss: 0.5119 - accuracy: 0.5128 - val_loss: 0.2609 - val_accuracy: 0.8148\n",
            "Epoch 2/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.4106 - accuracy: 0.5385 - val_loss: 0.2843 - val_accuracy: 0.8519\n",
            "Epoch 3/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.3649 - accuracy: 0.5559 - val_loss: 0.5428 - val_accuracy: 0.7407\n",
            "Epoch 4/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.3646 - accuracy: 0.5536 - val_loss: 0.4132 - val_accuracy: 0.7778\n",
            "Epoch 5/100\n",
            "27/27 [==============================] - 10s 358ms/step - loss: 0.3301 - accuracy: 0.5688 - val_loss: 0.2160 - val_accuracy: 0.8889\n",
            "Epoch 6/100\n",
            "27/27 [==============================] - 10s 354ms/step - loss: 0.3143 - accuracy: 0.5734 - val_loss: 0.2357 - val_accuracy: 0.8889\n",
            "Epoch 7/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.3067 - accuracy: 0.5758 - val_loss: 0.3561 - val_accuracy: 0.8148\n",
            "Epoch 8/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.3061 - accuracy: 0.5711 - val_loss: 0.2787 - val_accuracy: 0.8519\n",
            "Epoch 9/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.3045 - accuracy: 0.5746 - val_loss: 0.2392 - val_accuracy: 0.8889\n",
            "Epoch 10/100\n",
            "27/27 [==============================] - 10s 358ms/step - loss: 0.2997 - accuracy: 0.5711 - val_loss: 0.1833 - val_accuracy: 0.9259\n",
            "Epoch 11/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2970 - accuracy: 0.5746 - val_loss: 0.2190 - val_accuracy: 0.9259\n",
            "Epoch 12/100\n",
            "27/27 [==============================] - 10s 359ms/step - loss: 0.2944 - accuracy: 0.5746 - val_loss: 0.1380 - val_accuracy: 0.9259\n",
            "Epoch 13/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2902 - accuracy: 0.5758 - val_loss: 0.3500 - val_accuracy: 0.7778\n",
            "Epoch 14/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.2811 - accuracy: 0.5746 - val_loss: 0.1506 - val_accuracy: 0.9259\n",
            "Epoch 15/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2838 - accuracy: 0.5758 - val_loss: 0.2077 - val_accuracy: 0.9259\n",
            "Epoch 16/100\n",
            "27/27 [==============================] - 10s 358ms/step - loss: 0.2725 - accuracy: 0.5758 - val_loss: 0.2934 - val_accuracy: 0.8519\n",
            "Epoch 17/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2807 - accuracy: 0.5758 - val_loss: 0.2891 - val_accuracy: 0.8889\n",
            "Epoch 18/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2781 - accuracy: 0.5758 - val_loss: 0.3151 - val_accuracy: 0.8519\n",
            "Epoch 19/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2846 - accuracy: 0.5758 - val_loss: 0.1996 - val_accuracy: 0.9259\n",
            "Epoch 20/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.2778 - accuracy: 0.5758 - val_loss: 0.2186 - val_accuracy: 0.8889\n",
            "Epoch 21/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2711 - accuracy: 0.5758 - val_loss: 0.2457 - val_accuracy: 0.8519\n",
            "Epoch 22/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.2770 - accuracy: 0.5746 - val_loss: 0.1599 - val_accuracy: 0.9259\n",
            "Epoch 23/100\n",
            "27/27 [==============================] - 10s 358ms/step - loss: 0.2761 - accuracy: 0.5734 - val_loss: 0.1319 - val_accuracy: 0.9630\n",
            "Epoch 24/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2705 - accuracy: 0.5758 - val_loss: 0.2533 - val_accuracy: 0.8519\n",
            "Epoch 25/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.2707 - accuracy: 0.5758 - val_loss: 0.1362 - val_accuracy: 0.9259\n",
            "Epoch 26/100\n",
            "27/27 [==============================] - 10s 358ms/step - loss: 0.2707 - accuracy: 0.5758 - val_loss: 0.2869 - val_accuracy: 0.8889\n",
            "Epoch 27/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.2670 - accuracy: 0.5758 - val_loss: 0.3602 - val_accuracy: 0.8148\n",
            "Epoch 28/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2731 - accuracy: 0.5758 - val_loss: 0.1961 - val_accuracy: 0.9259\n",
            "Epoch 29/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2712 - accuracy: 0.5758 - val_loss: 0.3006 - val_accuracy: 0.7778\n",
            "Epoch 30/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.2737 - accuracy: 0.5758 - val_loss: 0.2260 - val_accuracy: 0.9259\n",
            "Epoch 31/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2705 - accuracy: 0.5758 - val_loss: 0.1463 - val_accuracy: 0.9259\n",
            "Epoch 32/100\n",
            "27/27 [==============================] - 10s 354ms/step - loss: 0.2616 - accuracy: 0.5758 - val_loss: 0.2417 - val_accuracy: 0.8889\n",
            "Epoch 33/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.2683 - accuracy: 0.5758 - val_loss: 0.2382 - val_accuracy: 0.8889\n",
            "Epoch 34/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.2604 - accuracy: 0.5758 - val_loss: 0.1826 - val_accuracy: 0.8889\n",
            "Epoch 35/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.2665 - accuracy: 0.5758 - val_loss: 0.2524 - val_accuracy: 0.8889\n",
            "Epoch 36/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2572 - accuracy: 0.5758 - val_loss: 0.2732 - val_accuracy: 0.8889\n",
            "Epoch 37/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2682 - accuracy: 0.5758 - val_loss: 0.2072 - val_accuracy: 0.9259\n",
            "Epoch 38/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.2611 - accuracy: 0.5746 - val_loss: 0.1298 - val_accuracy: 0.9630\n",
            "Epoch 39/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.2642 - accuracy: 0.5746 - val_loss: 0.2458 - val_accuracy: 0.9259\n",
            "Epoch 40/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2613 - accuracy: 0.5758 - val_loss: 0.3188 - val_accuracy: 0.8519\n",
            "Epoch 41/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.2624 - accuracy: 0.5746 - val_loss: 0.2378 - val_accuracy: 0.8889\n",
            "Epoch 42/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.2536 - accuracy: 0.5758 - val_loss: 0.3056 - val_accuracy: 0.8519\n",
            "Epoch 43/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.2573 - accuracy: 0.5758 - val_loss: 0.1255 - val_accuracy: 0.9630\n",
            "Epoch 44/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.2626 - accuracy: 0.5746 - val_loss: 0.2506 - val_accuracy: 0.8889\n",
            "Epoch 45/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2545 - accuracy: 0.5758 - val_loss: 0.2082 - val_accuracy: 0.9259\n",
            "Epoch 46/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2574 - accuracy: 0.5758 - val_loss: 0.1665 - val_accuracy: 0.9259\n",
            "Epoch 47/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2609 - accuracy: 0.5746 - val_loss: 0.1978 - val_accuracy: 0.9259\n",
            "Epoch 48/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.2567 - accuracy: 0.5758 - val_loss: 0.2515 - val_accuracy: 0.9259\n",
            "Epoch 49/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.2569 - accuracy: 0.5758 - val_loss: 0.1481 - val_accuracy: 0.9259\n",
            "Epoch 50/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.2618 - accuracy: 0.5758 - val_loss: 0.3428 - val_accuracy: 0.8148\n",
            "Epoch 51/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2535 - accuracy: 0.5758 - val_loss: 0.1840 - val_accuracy: 0.9259\n",
            "Epoch 52/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.2560 - accuracy: 0.5758 - val_loss: 0.3071 - val_accuracy: 0.8519\n",
            "Epoch 53/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2524 - accuracy: 0.5758 - val_loss: 0.2256 - val_accuracy: 0.9259\n",
            "Epoch 54/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.2504 - accuracy: 0.5758 - val_loss: 0.1716 - val_accuracy: 0.9259\n",
            "Epoch 55/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.2528 - accuracy: 0.5758 - val_loss: 0.1659 - val_accuracy: 0.9259\n",
            "Epoch 56/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.2573 - accuracy: 0.5758 - val_loss: 0.1843 - val_accuracy: 0.9259\n",
            "Epoch 57/100\n",
            "27/27 [==============================] - 10s 354ms/step - loss: 0.2593 - accuracy: 0.5758 - val_loss: 0.2476 - val_accuracy: 0.8889\n",
            "Epoch 58/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.2539 - accuracy: 0.5758 - val_loss: 0.2075 - val_accuracy: 0.9259\n",
            "2/2 [==============================] - 2s 118ms/step - loss: 0.0834 - accuracy: 0.9706\n",
            "Epoch 1/100\n",
            "27/27 [==============================] - 17s 410ms/step - loss: 0.5258 - accuracy: 0.5012 - val_loss: 1.3806 - val_accuracy: 0.6667\n",
            "Epoch 2/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.4111 - accuracy: 0.5434 - val_loss: 0.4567 - val_accuracy: 0.8519\n",
            "Epoch 3/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.3778 - accuracy: 0.5540 - val_loss: 0.2932 - val_accuracy: 0.8889\n",
            "Epoch 4/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.3588 - accuracy: 0.5575 - val_loss: 0.2210 - val_accuracy: 0.9259\n",
            "Epoch 5/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.3421 - accuracy: 0.5657 - val_loss: 0.1662 - val_accuracy: 0.9259\n",
            "Epoch 6/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.3200 - accuracy: 0.5728 - val_loss: 0.1728 - val_accuracy: 0.8889\n",
            "Epoch 7/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.3218 - accuracy: 0.5728 - val_loss: 0.1697 - val_accuracy: 0.9259\n",
            "Epoch 8/100\n",
            "27/27 [==============================] - 10s 354ms/step - loss: 0.3130 - accuracy: 0.5775 - val_loss: 0.1094 - val_accuracy: 0.9630\n",
            "Epoch 9/100\n",
            "27/27 [==============================] - 10s 353ms/step - loss: 0.3109 - accuracy: 0.5775 - val_loss: 0.1343 - val_accuracy: 0.9259\n",
            "Epoch 10/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2999 - accuracy: 0.5786 - val_loss: 0.0820 - val_accuracy: 1.0000\n",
            "Epoch 11/100\n",
            "27/27 [==============================] - 10s 352ms/step - loss: 0.2925 - accuracy: 0.5786 - val_loss: 0.1217 - val_accuracy: 0.9630\n",
            "Epoch 12/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.2899 - accuracy: 0.5798 - val_loss: 0.1041 - val_accuracy: 0.9630\n",
            "Epoch 13/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.2895 - accuracy: 0.5798 - val_loss: 0.0867 - val_accuracy: 0.9630\n",
            "Epoch 14/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.2796 - accuracy: 0.5798 - val_loss: 0.0946 - val_accuracy: 0.9630\n",
            "Epoch 15/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.2826 - accuracy: 0.5786 - val_loss: 0.0995 - val_accuracy: 0.9259\n",
            "Epoch 16/100\n",
            "27/27 [==============================] - 10s 354ms/step - loss: 0.2794 - accuracy: 0.5786 - val_loss: 0.2921 - val_accuracy: 0.8889\n",
            "Epoch 17/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.2899 - accuracy: 0.5786 - val_loss: 0.1163 - val_accuracy: 0.9630\n",
            "Epoch 18/100\n",
            "27/27 [==============================] - 10s 354ms/step - loss: 0.2794 - accuracy: 0.5798 - val_loss: 0.1147 - val_accuracy: 0.9259\n",
            "Epoch 19/100\n",
            "27/27 [==============================] - 10s 354ms/step - loss: 0.2765 - accuracy: 0.5798 - val_loss: 0.0923 - val_accuracy: 0.9630\n",
            "Epoch 20/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2728 - accuracy: 0.5786 - val_loss: 0.0840 - val_accuracy: 0.9630\n",
            "Epoch 21/100\n",
            "27/27 [==============================] - 10s 354ms/step - loss: 0.2644 - accuracy: 0.5798 - val_loss: 0.1410 - val_accuracy: 0.9259\n",
            "Epoch 22/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2766 - accuracy: 0.5798 - val_loss: 0.1041 - val_accuracy: 0.9259\n",
            "Epoch 23/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.2745 - accuracy: 0.5798 - val_loss: 0.0910 - val_accuracy: 0.9259\n",
            "Epoch 24/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2909 - accuracy: 0.5798 - val_loss: 0.1079 - val_accuracy: 0.9630\n",
            "Epoch 25/100\n",
            "27/27 [==============================] - 10s 359ms/step - loss: 0.2748 - accuracy: 0.5786 - val_loss: 0.0819 - val_accuracy: 0.9630\n",
            "Epoch 26/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.2668 - accuracy: 0.5798 - val_loss: 0.0828 - val_accuracy: 0.9630\n",
            "Epoch 27/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.2606 - accuracy: 0.5798 - val_loss: 0.0751 - val_accuracy: 0.9630\n",
            "Epoch 28/100\n",
            "27/27 [==============================] - 10s 354ms/step - loss: 0.2698 - accuracy: 0.5798 - val_loss: 0.0827 - val_accuracy: 0.9630\n",
            "Epoch 29/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.2668 - accuracy: 0.5798 - val_loss: 0.1014 - val_accuracy: 0.9630\n",
            "Epoch 30/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2619 - accuracy: 0.5798 - val_loss: 0.1187 - val_accuracy: 0.9630\n",
            "Epoch 31/100\n",
            "27/27 [==============================] - 10s 358ms/step - loss: 0.2687 - accuracy: 0.5798 - val_loss: 0.0534 - val_accuracy: 1.0000\n",
            "Epoch 32/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.2746 - accuracy: 0.5798 - val_loss: 0.0989 - val_accuracy: 0.9630\n",
            "Epoch 33/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2613 - accuracy: 0.5798 - val_loss: 0.0826 - val_accuracy: 0.9630\n",
            "Epoch 34/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2610 - accuracy: 0.5798 - val_loss: 0.0829 - val_accuracy: 0.9630\n",
            "Epoch 35/100\n",
            "27/27 [==============================] - 10s 354ms/step - loss: 0.2674 - accuracy: 0.5798 - val_loss: 0.2096 - val_accuracy: 0.9259\n",
            "Epoch 36/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.2797 - accuracy: 0.5798 - val_loss: 0.0848 - val_accuracy: 1.0000\n",
            "Epoch 37/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2617 - accuracy: 0.5786 - val_loss: 0.0858 - val_accuracy: 0.9630\n",
            "Epoch 38/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.2636 - accuracy: 0.5798 - val_loss: 0.0690 - val_accuracy: 0.9630\n",
            "Epoch 39/100\n",
            "27/27 [==============================] - 10s 354ms/step - loss: 0.2613 - accuracy: 0.5798 - val_loss: 0.0771 - val_accuracy: 0.9630\n",
            "Epoch 40/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.2623 - accuracy: 0.5786 - val_loss: 0.1012 - val_accuracy: 0.9630\n",
            "Epoch 41/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2610 - accuracy: 0.5798 - val_loss: 0.0878 - val_accuracy: 0.9630\n",
            "Epoch 42/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.2632 - accuracy: 0.5798 - val_loss: 0.0971 - val_accuracy: 0.9630\n",
            "Epoch 43/100\n",
            "27/27 [==============================] - 10s 354ms/step - loss: 0.2590 - accuracy: 0.5798 - val_loss: 0.0671 - val_accuracy: 1.0000\n",
            "Epoch 44/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.2604 - accuracy: 0.5798 - val_loss: 0.0877 - val_accuracy: 0.9630\n",
            "Epoch 45/100\n",
            "27/27 [==============================] - 10s 354ms/step - loss: 0.2592 - accuracy: 0.5798 - val_loss: 0.1100 - val_accuracy: 0.9630\n",
            "Epoch 46/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.2558 - accuracy: 0.5798 - val_loss: 0.1110 - val_accuracy: 0.9630\n",
            "2/2 [==============================] - 2s 122ms/step - loss: 0.0754 - accuracy: 1.0000\n",
            "[0.9470588088035583, 0.9529411673545838, 0.9058823466300965, 0.970588219165802]\n",
            "[0.9386747079624046, 0.9458003581442472, 0.8964876214112817, 0.964872931604476]\n",
            "Epoch 1/100\n",
            "27/27 [==============================] - 17s 410ms/step - loss: 0.5259 - accuracy: 0.4929 - val_loss: 1.3625 - val_accuracy: 0.5926\n",
            "Epoch 2/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.4218 - accuracy: 0.5319 - val_loss: 0.5650 - val_accuracy: 0.7778\n",
            "Epoch 3/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.3919 - accuracy: 0.5437 - val_loss: 0.5464 - val_accuracy: 0.7407\n",
            "Epoch 4/100\n",
            "27/27 [==============================] - 10s 354ms/step - loss: 0.3507 - accuracy: 0.5532 - val_loss: 0.7174 - val_accuracy: 0.7778\n",
            "Epoch 5/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.3326 - accuracy: 0.5579 - val_loss: 0.4163 - val_accuracy: 0.8148\n",
            "Epoch 6/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.3300 - accuracy: 0.5603 - val_loss: 0.2432 - val_accuracy: 0.8519\n",
            "Epoch 7/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.3099 - accuracy: 0.5615 - val_loss: 0.3633 - val_accuracy: 0.8519\n",
            "Epoch 8/100\n",
            "27/27 [==============================] - 10s 358ms/step - loss: 0.3206 - accuracy: 0.5626 - val_loss: 0.1673 - val_accuracy: 0.9630\n",
            "Epoch 9/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.2946 - accuracy: 0.5674 - val_loss: 0.2274 - val_accuracy: 0.8519\n",
            "Epoch 10/100\n",
            "27/27 [==============================] - 10s 354ms/step - loss: 0.3037 - accuracy: 0.5626 - val_loss: 0.2716 - val_accuracy: 0.8519\n",
            "Epoch 11/100\n",
            "27/27 [==============================] - 10s 353ms/step - loss: 0.2877 - accuracy: 0.5662 - val_loss: 0.2523 - val_accuracy: 0.8889\n",
            "Epoch 12/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.3015 - accuracy: 0.5638 - val_loss: 0.2198 - val_accuracy: 0.8519\n",
            "Epoch 13/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2965 - accuracy: 0.5638 - val_loss: 0.2215 - val_accuracy: 0.8889\n",
            "Epoch 14/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2822 - accuracy: 0.5674 - val_loss: 0.1459 - val_accuracy: 0.9259\n",
            "Epoch 15/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.3016 - accuracy: 0.5650 - val_loss: 0.1694 - val_accuracy: 0.8889\n",
            "Epoch 16/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2914 - accuracy: 0.5674 - val_loss: 0.1733 - val_accuracy: 0.9259\n",
            "Epoch 17/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.2956 - accuracy: 0.5650 - val_loss: 0.2553 - val_accuracy: 0.8519\n",
            "Epoch 18/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.2887 - accuracy: 0.5662 - val_loss: 0.2140 - val_accuracy: 0.8889\n",
            "Epoch 19/100\n",
            "27/27 [==============================] - 10s 352ms/step - loss: 0.2808 - accuracy: 0.5674 - val_loss: 0.1541 - val_accuracy: 0.9630\n",
            "Epoch 20/100\n",
            "27/27 [==============================] - 10s 353ms/step - loss: 0.2803 - accuracy: 0.5674 - val_loss: 0.1583 - val_accuracy: 0.9259\n",
            "Epoch 21/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.2788 - accuracy: 0.5674 - val_loss: 0.2093 - val_accuracy: 0.8889\n",
            "Epoch 22/100\n",
            "27/27 [==============================] - 10s 354ms/step - loss: 0.2773 - accuracy: 0.5674 - val_loss: 0.3202 - val_accuracy: 0.8519\n",
            "Epoch 23/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2778 - accuracy: 0.5674 - val_loss: 0.1905 - val_accuracy: 0.9259\n",
            "Epoch 24/100\n",
            "27/27 [==============================] - 10s 354ms/step - loss: 0.2738 - accuracy: 0.5674 - val_loss: 0.2237 - val_accuracy: 0.8519\n",
            "Epoch 25/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2714 - accuracy: 0.5674 - val_loss: 0.1970 - val_accuracy: 0.9630\n",
            "Epoch 26/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.2723 - accuracy: 0.5674 - val_loss: 0.2298 - val_accuracy: 0.8519\n",
            "Epoch 27/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.2661 - accuracy: 0.5674 - val_loss: 0.1928 - val_accuracy: 0.8889\n",
            "Epoch 28/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.2736 - accuracy: 0.5674 - val_loss: 0.1373 - val_accuracy: 0.9630\n",
            "Epoch 29/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.2744 - accuracy: 0.5674 - val_loss: 0.2371 - val_accuracy: 0.8519\n",
            "Epoch 30/100\n",
            "27/27 [==============================] - 10s 354ms/step - loss: 0.2748 - accuracy: 0.5674 - val_loss: 0.2893 - val_accuracy: 0.8519\n",
            "Epoch 31/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.2723 - accuracy: 0.5674 - val_loss: 0.2318 - val_accuracy: 0.8519\n",
            "Epoch 32/100\n",
            "27/27 [==============================] - 10s 353ms/step - loss: 0.2630 - accuracy: 0.5674 - val_loss: 0.2758 - val_accuracy: 0.8519\n",
            "Epoch 33/100\n",
            "27/27 [==============================] - 10s 354ms/step - loss: 0.2608 - accuracy: 0.5674 - val_loss: 0.3309 - val_accuracy: 0.8519\n",
            "Epoch 34/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.2637 - accuracy: 0.5674 - val_loss: 0.2249 - val_accuracy: 0.8519\n",
            "Epoch 35/100\n",
            "27/27 [==============================] - 10s 354ms/step - loss: 0.2666 - accuracy: 0.5674 - val_loss: 0.2201 - val_accuracy: 0.8519\n",
            "Epoch 36/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.2699 - accuracy: 0.5674 - val_loss: 0.1711 - val_accuracy: 0.9630\n",
            "Epoch 37/100\n",
            "27/27 [==============================] - 10s 353ms/step - loss: 0.2590 - accuracy: 0.5674 - val_loss: 0.2964 - val_accuracy: 0.8519\n",
            "Epoch 38/100\n",
            "27/27 [==============================] - 10s 354ms/step - loss: 0.2704 - accuracy: 0.5674 - val_loss: 0.2477 - val_accuracy: 0.8519\n",
            "Epoch 39/100\n",
            "27/27 [==============================] - 9s 352ms/step - loss: 0.2650 - accuracy: 0.5674 - val_loss: 0.3837 - val_accuracy: 0.8519\n",
            "Epoch 40/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.2650 - accuracy: 0.5674 - val_loss: 0.2360 - val_accuracy: 0.8519\n",
            "Epoch 41/100\n",
            "27/27 [==============================] - 10s 353ms/step - loss: 0.2629 - accuracy: 0.5674 - val_loss: 0.2769 - val_accuracy: 0.8519\n",
            "Epoch 42/100\n",
            "27/27 [==============================] - 9s 352ms/step - loss: 0.2603 - accuracy: 0.5674 - val_loss: 0.3637 - val_accuracy: 0.8519\n",
            "Epoch 43/100\n",
            "27/27 [==============================] - 10s 353ms/step - loss: 0.2590 - accuracy: 0.5674 - val_loss: 0.3850 - val_accuracy: 0.8519\n",
            "2/2 [==============================] - 2s 124ms/step - loss: 0.0804 - accuracy: 1.0000\n",
            "Epoch 1/100\n",
            "28/28 [==============================] - 17s 406ms/step - loss: 0.5340 - accuracy: 0.5184 - val_loss: 0.5287 - val_accuracy: 0.8148\n",
            "Epoch 2/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.4115 - accuracy: 0.5678 - val_loss: 0.2365 - val_accuracy: 0.8519\n",
            "Epoch 3/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.3661 - accuracy: 0.5862 - val_loss: 0.2048 - val_accuracy: 0.8889\n",
            "Epoch 4/100\n",
            "28/28 [==============================] - 10s 356ms/step - loss: 0.3415 - accuracy: 0.5931 - val_loss: 0.1881 - val_accuracy: 0.9630\n",
            "Epoch 5/100\n",
            "28/28 [==============================] - 10s 351ms/step - loss: 0.3222 - accuracy: 0.5966 - val_loss: 0.2276 - val_accuracy: 0.8519\n",
            "Epoch 6/100\n",
            "28/28 [==============================] - 10s 353ms/step - loss: 0.3270 - accuracy: 0.5966 - val_loss: 0.2261 - val_accuracy: 0.8519\n",
            "Epoch 7/100\n",
            "28/28 [==============================] - 10s 353ms/step - loss: 0.3093 - accuracy: 0.6000 - val_loss: 0.1678 - val_accuracy: 0.9630\n",
            "Epoch 8/100\n",
            "28/28 [==============================] - 10s 355ms/step - loss: 0.3052 - accuracy: 0.6011 - val_loss: 0.1613 - val_accuracy: 0.9630\n",
            "Epoch 9/100\n",
            "28/28 [==============================] - 10s 353ms/step - loss: 0.3185 - accuracy: 0.5931 - val_loss: 0.2127 - val_accuracy: 0.9259\n",
            "Epoch 10/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2870 - accuracy: 0.6069 - val_loss: 0.1615 - val_accuracy: 0.9259\n",
            "Epoch 11/100\n",
            "28/28 [==============================] - 10s 352ms/step - loss: 0.2914 - accuracy: 0.6069 - val_loss: 0.1912 - val_accuracy: 0.9259\n",
            "Epoch 12/100\n",
            "28/28 [==============================] - 10s 351ms/step - loss: 0.2999 - accuracy: 0.6011 - val_loss: 0.3145 - val_accuracy: 0.8889\n",
            "Epoch 13/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2899 - accuracy: 0.6046 - val_loss: 0.1272 - val_accuracy: 0.9259\n",
            "Epoch 14/100\n",
            "28/28 [==============================] - 10s 353ms/step - loss: 0.2930 - accuracy: 0.6046 - val_loss: 0.1618 - val_accuracy: 0.9630\n",
            "Epoch 15/100\n",
            "28/28 [==============================] - 10s 352ms/step - loss: 0.2903 - accuracy: 0.6034 - val_loss: 0.1411 - val_accuracy: 0.9630\n",
            "Epoch 16/100\n",
            "28/28 [==============================] - 10s 353ms/step - loss: 0.2761 - accuracy: 0.6057 - val_loss: 0.1784 - val_accuracy: 0.9259\n",
            "Epoch 17/100\n",
            "28/28 [==============================] - 10s 352ms/step - loss: 0.2677 - accuracy: 0.6034 - val_loss: 0.1387 - val_accuracy: 0.9259\n",
            "Epoch 18/100\n",
            "28/28 [==============================] - 10s 355ms/step - loss: 0.2678 - accuracy: 0.6069 - val_loss: 0.0867 - val_accuracy: 1.0000\n",
            "Epoch 19/100\n",
            "28/28 [==============================] - 10s 353ms/step - loss: 0.2711 - accuracy: 0.6069 - val_loss: 0.1387 - val_accuracy: 0.9630\n",
            "Epoch 20/100\n",
            "28/28 [==============================] - 10s 351ms/step - loss: 0.2778 - accuracy: 0.6069 - val_loss: 0.0967 - val_accuracy: 1.0000\n",
            "Epoch 21/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2663 - accuracy: 0.6069 - val_loss: 0.0805 - val_accuracy: 1.0000\n",
            "Epoch 22/100\n",
            "28/28 [==============================] - 10s 351ms/step - loss: 0.2711 - accuracy: 0.6069 - val_loss: 0.1435 - val_accuracy: 0.9259\n",
            "Epoch 23/100\n",
            "28/28 [==============================] - 10s 352ms/step - loss: 0.2632 - accuracy: 0.6057 - val_loss: 0.1212 - val_accuracy: 0.9630\n",
            "Epoch 24/100\n",
            "28/28 [==============================] - 10s 352ms/step - loss: 0.2714 - accuracy: 0.6057 - val_loss: 0.1905 - val_accuracy: 0.9259\n",
            "Epoch 25/100\n",
            "28/28 [==============================] - 10s 352ms/step - loss: 0.2591 - accuracy: 0.6069 - val_loss: 0.0894 - val_accuracy: 1.0000\n",
            "Epoch 26/100\n",
            "28/28 [==============================] - 10s 353ms/step - loss: 0.2567 - accuracy: 0.6069 - val_loss: 0.1031 - val_accuracy: 0.9630\n",
            "Epoch 27/100\n",
            "28/28 [==============================] - 10s 351ms/step - loss: 0.2633 - accuracy: 0.6069 - val_loss: 0.0972 - val_accuracy: 0.9630\n",
            "Epoch 28/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2631 - accuracy: 0.6034 - val_loss: 0.0987 - val_accuracy: 0.9630\n",
            "Epoch 29/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2574 - accuracy: 0.6069 - val_loss: 0.0763 - val_accuracy: 1.0000\n",
            "Epoch 30/100\n",
            "28/28 [==============================] - 10s 352ms/step - loss: 0.2590 - accuracy: 0.6069 - val_loss: 0.0889 - val_accuracy: 0.9630\n",
            "Epoch 31/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2546 - accuracy: 0.6069 - val_loss: 0.0595 - val_accuracy: 1.0000\n",
            "Epoch 32/100\n",
            "28/28 [==============================] - 10s 352ms/step - loss: 0.2559 - accuracy: 0.6069 - val_loss: 0.0904 - val_accuracy: 1.0000\n",
            "Epoch 33/100\n",
            "28/28 [==============================] - 10s 352ms/step - loss: 0.2533 - accuracy: 0.6069 - val_loss: 0.0830 - val_accuracy: 1.0000\n",
            "Epoch 34/100\n",
            "28/28 [==============================] - 10s 352ms/step - loss: 0.2512 - accuracy: 0.6069 - val_loss: 0.0972 - val_accuracy: 1.0000\n",
            "Epoch 35/100\n",
            "28/28 [==============================] - 10s 351ms/step - loss: 0.2578 - accuracy: 0.6057 - val_loss: 0.1003 - val_accuracy: 0.9630\n",
            "Epoch 36/100\n",
            "28/28 [==============================] - 10s 352ms/step - loss: 0.2581 - accuracy: 0.6057 - val_loss: 0.0935 - val_accuracy: 0.9630\n",
            "Epoch 37/100\n",
            "28/28 [==============================] - 10s 352ms/step - loss: 0.2472 - accuracy: 0.6069 - val_loss: 0.0831 - val_accuracy: 0.9630\n",
            "Epoch 38/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2520 - accuracy: 0.6069 - val_loss: 0.0808 - val_accuracy: 1.0000\n",
            "Epoch 39/100\n",
            "28/28 [==============================] - 10s 352ms/step - loss: 0.2564 - accuracy: 0.6069 - val_loss: 0.1267 - val_accuracy: 0.9259\n",
            "Epoch 40/100\n",
            "28/28 [==============================] - 10s 352ms/step - loss: 0.2557 - accuracy: 0.6046 - val_loss: 0.1202 - val_accuracy: 0.9259\n",
            "Epoch 41/100\n",
            "28/28 [==============================] - 10s 351ms/step - loss: 0.2668 - accuracy: 0.6046 - val_loss: 0.0595 - val_accuracy: 1.0000\n",
            "Epoch 42/100\n",
            "28/28 [==============================] - 10s 352ms/step - loss: 0.2552 - accuracy: 0.6069 - val_loss: 0.1039 - val_accuracy: 0.9630\n",
            "Epoch 43/100\n",
            "28/28 [==============================] - 10s 352ms/step - loss: 0.2532 - accuracy: 0.6069 - val_loss: 0.1076 - val_accuracy: 0.9259\n",
            "Epoch 44/100\n",
            "28/28 [==============================] - 10s 352ms/step - loss: 0.2515 - accuracy: 0.6069 - val_loss: 0.0993 - val_accuracy: 0.9630\n",
            "Epoch 45/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2590 - accuracy: 0.6057 - val_loss: 0.1088 - val_accuracy: 0.9630\n",
            "Epoch 46/100\n",
            "28/28 [==============================] - 10s 353ms/step - loss: 0.2515 - accuracy: 0.6069 - val_loss: 0.0916 - val_accuracy: 1.0000\n",
            "2/2 [==============================] - 2s 146ms/step - loss: 0.0910 - accuracy: 0.9706\n",
            "Epoch 1/100\n",
            "27/27 [==============================] - 17s 411ms/step - loss: 0.4761 - accuracy: 0.5317 - val_loss: 0.2968 - val_accuracy: 0.8148\n",
            "Epoch 2/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.3830 - accuracy: 0.5646 - val_loss: 0.5488 - val_accuracy: 0.6296\n",
            "Epoch 3/100\n",
            "27/27 [==============================] - 10s 359ms/step - loss: 0.3623 - accuracy: 0.5692 - val_loss: 0.3570 - val_accuracy: 0.8148\n",
            "Epoch 4/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.3436 - accuracy: 0.5786 - val_loss: 0.1753 - val_accuracy: 0.9630\n",
            "Epoch 5/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.3146 - accuracy: 0.5904 - val_loss: 0.1800 - val_accuracy: 1.0000\n",
            "Epoch 6/100\n",
            "27/27 [==============================] - 10s 354ms/step - loss: 0.3062 - accuracy: 0.5869 - val_loss: 0.1887 - val_accuracy: 0.8889\n",
            "Epoch 7/100\n",
            "27/27 [==============================] - 10s 354ms/step - loss: 0.2979 - accuracy: 0.5915 - val_loss: 0.1971 - val_accuracy: 0.9259\n",
            "Epoch 8/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.3037 - accuracy: 0.5904 - val_loss: 0.2275 - val_accuracy: 0.8889\n",
            "Epoch 9/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.2875 - accuracy: 0.5939 - val_loss: 0.1746 - val_accuracy: 0.9259\n",
            "Epoch 10/100\n",
            "27/27 [==============================] - 10s 354ms/step - loss: 0.2961 - accuracy: 0.5927 - val_loss: 0.1771 - val_accuracy: 0.9259\n",
            "Epoch 11/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.2892 - accuracy: 0.5927 - val_loss: 0.1881 - val_accuracy: 0.9259\n",
            "Epoch 12/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2858 - accuracy: 0.5939 - val_loss: 0.1785 - val_accuracy: 0.9259\n",
            "Epoch 13/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.2806 - accuracy: 0.5939 - val_loss: 0.1546 - val_accuracy: 0.9259\n",
            "Epoch 14/100\n",
            "27/27 [==============================] - 10s 354ms/step - loss: 0.2753 - accuracy: 0.5951 - val_loss: 0.1905 - val_accuracy: 0.9259\n",
            "Epoch 15/100\n",
            "27/27 [==============================] - 10s 352ms/step - loss: 0.2711 - accuracy: 0.5939 - val_loss: 0.1266 - val_accuracy: 0.9259\n",
            "Epoch 16/100\n",
            "27/27 [==============================] - 9s 351ms/step - loss: 0.2690 - accuracy: 0.5962 - val_loss: 0.1651 - val_accuracy: 0.9259\n",
            "Epoch 17/100\n",
            "27/27 [==============================] - 9s 350ms/step - loss: 0.2750 - accuracy: 0.5951 - val_loss: 0.1444 - val_accuracy: 0.9259\n",
            "Epoch 18/100\n",
            "27/27 [==============================] - 10s 354ms/step - loss: 0.2704 - accuracy: 0.5962 - val_loss: 0.0841 - val_accuracy: 1.0000\n",
            "Epoch 19/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.2615 - accuracy: 0.5951 - val_loss: 0.0788 - val_accuracy: 0.9630\n",
            "Epoch 20/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.2611 - accuracy: 0.5962 - val_loss: 0.0875 - val_accuracy: 0.9259\n",
            "Epoch 21/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2703 - accuracy: 0.5962 - val_loss: 0.0743 - val_accuracy: 0.9630\n",
            "Epoch 22/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2575 - accuracy: 0.5962 - val_loss: 0.1102 - val_accuracy: 0.9259\n",
            "Epoch 23/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2609 - accuracy: 0.5962 - val_loss: 0.0908 - val_accuracy: 1.0000\n",
            "Epoch 24/100\n",
            "27/27 [==============================] - 10s 354ms/step - loss: 0.2555 - accuracy: 0.5962 - val_loss: 0.0854 - val_accuracy: 1.0000\n",
            "Epoch 25/100\n",
            "27/27 [==============================] - 10s 354ms/step - loss: 0.2575 - accuracy: 0.5962 - val_loss: 0.1220 - val_accuracy: 0.9259\n",
            "Epoch 26/100\n",
            "27/27 [==============================] - 10s 354ms/step - loss: 0.2571 - accuracy: 0.5951 - val_loss: 0.0645 - val_accuracy: 1.0000\n",
            "Epoch 27/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.2574 - accuracy: 0.5962 - val_loss: 0.0973 - val_accuracy: 0.9259\n",
            "Epoch 28/100\n",
            "27/27 [==============================] - 10s 353ms/step - loss: 0.2564 - accuracy: 0.5962 - val_loss: 0.1055 - val_accuracy: 0.9259\n",
            "Epoch 29/100\n",
            "27/27 [==============================] - 10s 352ms/step - loss: 0.2526 - accuracy: 0.5962 - val_loss: 0.1397 - val_accuracy: 0.9259\n",
            "Epoch 30/100\n",
            "27/27 [==============================] - 10s 353ms/step - loss: 0.2514 - accuracy: 0.5962 - val_loss: 0.1219 - val_accuracy: 0.9630\n",
            "Epoch 31/100\n",
            "27/27 [==============================] - 10s 354ms/step - loss: 0.2540 - accuracy: 0.5962 - val_loss: 0.0815 - val_accuracy: 0.9630\n",
            "Epoch 32/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.2623 - accuracy: 0.5962 - val_loss: 0.1116 - val_accuracy: 0.9259\n",
            "Epoch 33/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2558 - accuracy: 0.5962 - val_loss: 0.0473 - val_accuracy: 1.0000\n",
            "Epoch 34/100\n",
            "27/27 [==============================] - 9s 352ms/step - loss: 0.2716 - accuracy: 0.5951 - val_loss: 0.0710 - val_accuracy: 0.9630\n",
            "Epoch 35/100\n",
            "27/27 [==============================] - 10s 353ms/step - loss: 0.2527 - accuracy: 0.5962 - val_loss: 0.0816 - val_accuracy: 0.9630\n",
            "Epoch 36/100\n",
            "27/27 [==============================] - 10s 354ms/step - loss: 0.2496 - accuracy: 0.5962 - val_loss: 0.1273 - val_accuracy: 0.9259\n",
            "Epoch 37/100\n",
            "27/27 [==============================] - 10s 354ms/step - loss: 0.2514 - accuracy: 0.5962 - val_loss: 0.2016 - val_accuracy: 0.9259\n",
            "Epoch 38/100\n",
            "27/27 [==============================] - 9s 352ms/step - loss: 0.2553 - accuracy: 0.5951 - val_loss: 0.1400 - val_accuracy: 0.9259\n",
            "Epoch 39/100\n",
            "27/27 [==============================] - 10s 354ms/step - loss: 0.2455 - accuracy: 0.5962 - val_loss: 0.1012 - val_accuracy: 0.9630\n",
            "Epoch 40/100\n",
            "27/27 [==============================] - 10s 353ms/step - loss: 0.2497 - accuracy: 0.5962 - val_loss: 0.0992 - val_accuracy: 0.9259\n",
            "Epoch 41/100\n",
            "27/27 [==============================] - 10s 353ms/step - loss: 0.2413 - accuracy: 0.5962 - val_loss: 0.1023 - val_accuracy: 0.9630\n",
            "Epoch 42/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.2509 - accuracy: 0.5962 - val_loss: 0.1206 - val_accuracy: 0.9259\n",
            "Epoch 43/100\n",
            "27/27 [==============================] - 10s 354ms/step - loss: 0.2488 - accuracy: 0.5962 - val_loss: 0.1276 - val_accuracy: 0.9259\n",
            "Epoch 44/100\n",
            "27/27 [==============================] - 9s 352ms/step - loss: 0.2466 - accuracy: 0.5962 - val_loss: 0.1407 - val_accuracy: 0.9259\n",
            "Epoch 45/100\n",
            "27/27 [==============================] - 10s 353ms/step - loss: 0.2427 - accuracy: 0.5962 - val_loss: 0.1328 - val_accuracy: 0.9259\n",
            "Epoch 46/100\n",
            "27/27 [==============================] - 10s 354ms/step - loss: 0.2450 - accuracy: 0.5962 - val_loss: 0.1512 - val_accuracy: 0.9259\n",
            "Epoch 47/100\n",
            "27/27 [==============================] - 10s 354ms/step - loss: 0.2415 - accuracy: 0.5962 - val_loss: 0.1391 - val_accuracy: 0.9259\n",
            "Epoch 48/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2478 - accuracy: 0.5962 - val_loss: 0.1880 - val_accuracy: 0.9259\n",
            "2/2 [==============================] - 2s 119ms/step - loss: 0.1692 - accuracy: 0.9118\n",
            "Epoch 1/100\n",
            "28/28 [==============================] - 18s 406ms/step - loss: 0.5440 - accuracy: 0.4692 - val_loss: 0.7034 - val_accuracy: 0.7037\n",
            "Epoch 2/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.4394 - accuracy: 0.5126 - val_loss: 0.4590 - val_accuracy: 0.7778\n",
            "Epoch 3/100\n",
            "28/28 [==============================] - 10s 356ms/step - loss: 0.3920 - accuracy: 0.5240 - val_loss: 0.2521 - val_accuracy: 0.9259\n",
            "Epoch 4/100\n",
            "28/28 [==============================] - 10s 352ms/step - loss: 0.3852 - accuracy: 0.5194 - val_loss: 0.2951 - val_accuracy: 0.8519\n",
            "Epoch 5/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.3493 - accuracy: 0.5377 - val_loss: 0.2157 - val_accuracy: 0.9259\n",
            "Epoch 6/100\n",
            "28/28 [==============================] - 10s 355ms/step - loss: 0.3343 - accuracy: 0.5400 - val_loss: 0.1739 - val_accuracy: 0.9630\n",
            "Epoch 7/100\n",
            "28/28 [==============================] - 10s 352ms/step - loss: 0.3413 - accuracy: 0.5434 - val_loss: 0.1999 - val_accuracy: 0.9259\n",
            "Epoch 8/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.3223 - accuracy: 0.5422 - val_loss: 0.1550 - val_accuracy: 0.9630\n",
            "Epoch 9/100\n",
            "28/28 [==============================] - 10s 353ms/step - loss: 0.3315 - accuracy: 0.5411 - val_loss: 0.1799 - val_accuracy: 0.9259\n",
            "Epoch 10/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.3099 - accuracy: 0.5445 - val_loss: 0.1113 - val_accuracy: 0.9630\n",
            "Epoch 11/100\n",
            "28/28 [==============================] - 10s 353ms/step - loss: 0.3120 - accuracy: 0.5422 - val_loss: 0.1269 - val_accuracy: 1.0000\n",
            "Epoch 12/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.3009 - accuracy: 0.5457 - val_loss: 0.1335 - val_accuracy: 0.9630\n",
            "Epoch 13/100\n",
            "28/28 [==============================] - 10s 356ms/step - loss: 0.3211 - accuracy: 0.5457 - val_loss: 0.0960 - val_accuracy: 1.0000\n",
            "Epoch 14/100\n",
            "28/28 [==============================] - 10s 353ms/step - loss: 0.3061 - accuracy: 0.5457 - val_loss: 0.1075 - val_accuracy: 1.0000\n",
            "Epoch 15/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.3009 - accuracy: 0.5457 - val_loss: 0.0884 - val_accuracy: 1.0000\n",
            "Epoch 16/100\n",
            "28/28 [==============================] - 10s 351ms/step - loss: 0.2942 - accuracy: 0.5457 - val_loss: 0.0889 - val_accuracy: 1.0000\n",
            "Epoch 17/100\n",
            "28/28 [==============================] - 10s 353ms/step - loss: 0.3001 - accuracy: 0.5434 - val_loss: 0.0980 - val_accuracy: 1.0000\n",
            "Epoch 18/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2920 - accuracy: 0.5457 - val_loss: 0.0916 - val_accuracy: 1.0000\n",
            "Epoch 19/100\n",
            "28/28 [==============================] - 10s 352ms/step - loss: 0.2900 - accuracy: 0.5445 - val_loss: 0.1159 - val_accuracy: 1.0000\n",
            "Epoch 20/100\n",
            "28/28 [==============================] - 10s 353ms/step - loss: 0.2913 - accuracy: 0.5445 - val_loss: 0.1392 - val_accuracy: 0.9630\n",
            "Epoch 21/100\n",
            "28/28 [==============================] - 10s 351ms/step - loss: 0.2885 - accuracy: 0.5445 - val_loss: 0.0920 - val_accuracy: 1.0000\n",
            "Epoch 22/100\n",
            "28/28 [==============================] - 10s 355ms/step - loss: 0.2844 - accuracy: 0.5457 - val_loss: 0.0875 - val_accuracy: 0.9630\n",
            "Epoch 23/100\n",
            "28/28 [==============================] - 10s 349ms/step - loss: 0.2900 - accuracy: 0.5445 - val_loss: 0.1097 - val_accuracy: 0.9630\n",
            "Epoch 24/100\n",
            "28/28 [==============================] - 10s 351ms/step - loss: 0.2868 - accuracy: 0.5457 - val_loss: 0.0798 - val_accuracy: 1.0000\n",
            "Epoch 25/100\n",
            "28/28 [==============================] - 10s 352ms/step - loss: 0.2838 - accuracy: 0.5457 - val_loss: 0.0648 - val_accuracy: 1.0000\n",
            "Epoch 26/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2832 - accuracy: 0.5457 - val_loss: 0.0864 - val_accuracy: 1.0000\n",
            "Epoch 27/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2871 - accuracy: 0.5457 - val_loss: 0.0684 - val_accuracy: 1.0000\n",
            "Epoch 28/100\n",
            "28/28 [==============================] - 10s 356ms/step - loss: 0.2847 - accuracy: 0.5457 - val_loss: 0.0900 - val_accuracy: 0.9630\n",
            "Epoch 29/100\n",
            "28/28 [==============================] - 10s 355ms/step - loss: 0.2845 - accuracy: 0.5457 - val_loss: 0.1138 - val_accuracy: 1.0000\n",
            "Epoch 30/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2831 - accuracy: 0.5445 - val_loss: 0.0913 - val_accuracy: 0.9630\n",
            "Epoch 31/100\n",
            "28/28 [==============================] - 10s 353ms/step - loss: 0.2742 - accuracy: 0.5457 - val_loss: 0.0820 - val_accuracy: 1.0000\n",
            "Epoch 32/100\n",
            "28/28 [==============================] - 10s 354ms/step - loss: 0.2859 - accuracy: 0.5457 - val_loss: 0.0918 - val_accuracy: 1.0000\n",
            "Epoch 33/100\n",
            "28/28 [==============================] - 10s 350ms/step - loss: 0.2748 - accuracy: 0.5457 - val_loss: 0.0847 - val_accuracy: 0.9630\n",
            "Epoch 34/100\n",
            "28/28 [==============================] - 10s 353ms/step - loss: 0.2827 - accuracy: 0.5445 - val_loss: 0.0846 - val_accuracy: 0.9630\n",
            "Epoch 35/100\n",
            "28/28 [==============================] - 10s 352ms/step - loss: 0.2854 - accuracy: 0.5457 - val_loss: 0.0763 - val_accuracy: 1.0000\n",
            "Epoch 36/100\n",
            "28/28 [==============================] - 10s 350ms/step - loss: 0.2788 - accuracy: 0.5457 - val_loss: 0.0725 - val_accuracy: 0.9630\n",
            "Epoch 37/100\n",
            "28/28 [==============================] - 10s 351ms/step - loss: 0.2814 - accuracy: 0.5457 - val_loss: 0.1361 - val_accuracy: 0.9630\n",
            "Epoch 38/100\n",
            "28/28 [==============================] - 10s 351ms/step - loss: 0.2758 - accuracy: 0.5457 - val_loss: 0.1212 - val_accuracy: 0.9630\n",
            "Epoch 39/100\n",
            "28/28 [==============================] - 10s 352ms/step - loss: 0.2764 - accuracy: 0.5457 - val_loss: 0.0840 - val_accuracy: 0.9630\n",
            "Epoch 40/100\n",
            "28/28 [==============================] - 10s 350ms/step - loss: 0.2710 - accuracy: 0.5457 - val_loss: 0.1253 - val_accuracy: 0.9630\n",
            "2/2 [==============================] - 2s 124ms/step - loss: 0.2537 - accuracy: 0.9118\n",
            "Epoch 1/100\n",
            "27/27 [==============================] - 17s 427ms/step - loss: 0.5112 - accuracy: 0.4931 - val_loss: 0.4104 - val_accuracy: 0.7778\n",
            "Epoch 2/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.4246 - accuracy: 0.5312 - val_loss: 0.4412 - val_accuracy: 0.7407\n",
            "Epoch 3/100\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.3763 - accuracy: 0.5451 - val_loss: 0.3433 - val_accuracy: 0.8889\n",
            "Epoch 4/100\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.3485 - accuracy: 0.5532 - val_loss: 0.2608 - val_accuracy: 0.9630\n",
            "Epoch 5/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.3392 - accuracy: 0.5544 - val_loss: 0.2035 - val_accuracy: 0.8889\n",
            "Epoch 6/100\n",
            "27/27 [==============================] - 10s 358ms/step - loss: 0.3287 - accuracy: 0.5532 - val_loss: 0.1924 - val_accuracy: 0.8889\n",
            "Epoch 7/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.3325 - accuracy: 0.5590 - val_loss: 0.2207 - val_accuracy: 0.8519\n",
            "Epoch 8/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.3143 - accuracy: 0.5602 - val_loss: 0.1628 - val_accuracy: 0.9630\n",
            "Epoch 9/100\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.3170 - accuracy: 0.5613 - val_loss: 0.1826 - val_accuracy: 0.9259\n",
            "Epoch 10/100\n",
            "27/27 [==============================] - 10s 359ms/step - loss: 0.3153 - accuracy: 0.5579 - val_loss: 0.1481 - val_accuracy: 0.9259\n",
            "Epoch 11/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.2962 - accuracy: 0.5637 - val_loss: 0.1558 - val_accuracy: 0.9630\n",
            "Epoch 12/100\n",
            "27/27 [==============================] - 10s 363ms/step - loss: 0.3090 - accuracy: 0.5613 - val_loss: 0.1374 - val_accuracy: 0.9630\n",
            "Epoch 13/100\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.2949 - accuracy: 0.5637 - val_loss: 0.1428 - val_accuracy: 0.8889\n",
            "Epoch 14/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.3016 - accuracy: 0.5637 - val_loss: 0.1212 - val_accuracy: 0.9630\n",
            "Epoch 15/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.2944 - accuracy: 0.5625 - val_loss: 0.1250 - val_accuracy: 0.9630\n",
            "Epoch 16/100\n",
            "27/27 [==============================] - 10s 354ms/step - loss: 0.2966 - accuracy: 0.5637 - val_loss: 0.1342 - val_accuracy: 0.8889\n",
            "Epoch 17/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.2860 - accuracy: 0.5637 - val_loss: 0.1454 - val_accuracy: 0.9259\n",
            "Epoch 18/100\n",
            "27/27 [==============================] - 10s 354ms/step - loss: 0.2924 - accuracy: 0.5625 - val_loss: 0.1500 - val_accuracy: 0.9630\n",
            "Epoch 19/100\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.2919 - accuracy: 0.5637 - val_loss: 0.1088 - val_accuracy: 0.9630\n",
            "Epoch 20/100\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.2883 - accuracy: 0.5637 - val_loss: 0.1503 - val_accuracy: 0.9259\n",
            "Epoch 21/100\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.2874 - accuracy: 0.5625 - val_loss: 0.1276 - val_accuracy: 0.9259\n",
            "Epoch 22/100\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.2909 - accuracy: 0.5637 - val_loss: 0.1432 - val_accuracy: 0.9630\n",
            "Epoch 23/100\n",
            "27/27 [==============================] - 10s 360ms/step - loss: 0.2905 - accuracy: 0.5648 - val_loss: 0.1359 - val_accuracy: 0.9630\n",
            "Epoch 24/100\n",
            "27/27 [==============================] - 10s 359ms/step - loss: 0.2770 - accuracy: 0.5648 - val_loss: 0.1138 - val_accuracy: 0.9630\n",
            "Epoch 25/100\n",
            "27/27 [==============================] - 10s 360ms/step - loss: 0.2877 - accuracy: 0.5648 - val_loss: 0.1439 - val_accuracy: 0.9259\n",
            "Epoch 26/100\n",
            "27/27 [==============================] - 10s 360ms/step - loss: 0.2855 - accuracy: 0.5637 - val_loss: 0.1181 - val_accuracy: 1.0000\n",
            "Epoch 27/100\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.2809 - accuracy: 0.5648 - val_loss: 0.1481 - val_accuracy: 1.0000\n",
            "Epoch 28/100\n",
            "27/27 [==============================] - 10s 360ms/step - loss: 0.2810 - accuracy: 0.5648 - val_loss: 0.1257 - val_accuracy: 0.9630\n",
            "Epoch 29/100\n",
            "27/27 [==============================] - 10s 358ms/step - loss: 0.2777 - accuracy: 0.5648 - val_loss: 0.1252 - val_accuracy: 0.9630\n",
            "Epoch 30/100\n",
            "27/27 [==============================] - 10s 359ms/step - loss: 0.2729 - accuracy: 0.5648 - val_loss: 0.1290 - val_accuracy: 0.9630\n",
            "Epoch 31/100\n",
            "27/27 [==============================] - 10s 359ms/step - loss: 0.2720 - accuracy: 0.5648 - val_loss: 0.1136 - val_accuracy: 0.9630\n",
            "Epoch 32/100\n",
            "27/27 [==============================] - 10s 360ms/step - loss: 0.2745 - accuracy: 0.5637 - val_loss: 0.1253 - val_accuracy: 0.9630\n",
            "Epoch 33/100\n",
            "27/27 [==============================] - 10s 358ms/step - loss: 0.2719 - accuracy: 0.5648 - val_loss: 0.1336 - val_accuracy: 1.0000\n",
            "Epoch 34/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2769 - accuracy: 0.5637 - val_loss: 0.0971 - val_accuracy: 1.0000\n",
            "Epoch 35/100\n",
            "27/27 [==============================] - 10s 358ms/step - loss: 0.2711 - accuracy: 0.5648 - val_loss: 0.1168 - val_accuracy: 0.9630\n",
            "Epoch 36/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.2708 - accuracy: 0.5648 - val_loss: 0.1436 - val_accuracy: 0.9630\n",
            "Epoch 37/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2722 - accuracy: 0.5648 - val_loss: 0.1271 - val_accuracy: 0.9630\n",
            "Epoch 38/100\n",
            "27/27 [==============================] - 10s 353ms/step - loss: 0.2678 - accuracy: 0.5648 - val_loss: 0.1404 - val_accuracy: 0.9630\n",
            "Epoch 39/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2717 - accuracy: 0.5648 - val_loss: 0.1415 - val_accuracy: 0.9630\n",
            "Epoch 40/100\n",
            "27/27 [==============================] - 10s 359ms/step - loss: 0.2681 - accuracy: 0.5648 - val_loss: 0.1690 - val_accuracy: 0.9259\n",
            "Epoch 41/100\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2790 - accuracy: 0.5648 - val_loss: 0.1179 - val_accuracy: 0.9630\n",
            "Epoch 42/100\n",
            "27/27 [==============================] - 10s 358ms/step - loss: 0.2773 - accuracy: 0.5637 - val_loss: 0.1311 - val_accuracy: 0.9630\n",
            "Epoch 43/100\n",
            "27/27 [==============================] - 10s 360ms/step - loss: 0.2669 - accuracy: 0.5648 - val_loss: 0.1280 - val_accuracy: 0.9630\n",
            "Epoch 44/100\n",
            "27/27 [==============================] - 10s 358ms/step - loss: 0.2626 - accuracy: 0.5648 - val_loss: 0.1581 - val_accuracy: 0.9259\n",
            "Epoch 45/100\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.2671 - accuracy: 0.5648 - val_loss: 0.1646 - val_accuracy: 0.9259\n",
            "Epoch 46/100\n",
            "27/27 [==============================] - 10s 358ms/step - loss: 0.2636 - accuracy: 0.5648 - val_loss: 0.1405 - val_accuracy: 0.9259\n",
            "Epoch 47/100\n",
            "27/27 [==============================] - 10s 358ms/step - loss: 0.2676 - accuracy: 0.5648 - val_loss: 0.1228 - val_accuracy: 1.0000\n",
            "Epoch 48/100\n",
            "27/27 [==============================] - 10s 359ms/step - loss: 0.2661 - accuracy: 0.5648 - val_loss: 0.1337 - val_accuracy: 0.9259\n",
            "Epoch 49/100\n",
            "27/27 [==============================] - 10s 359ms/step - loss: 0.2609 - accuracy: 0.5648 - val_loss: 0.1515 - val_accuracy: 0.9630\n",
            "2/2 [==============================] - 2s 130ms/step - loss: 0.0504 - accuracy: 1.0000\n",
            "[0.9470588088035583, 0.9529411673545838, 0.9058823466300965, 0.970588219165802, 0.9588235139846801]\n",
            "[0.9386747079624046, 0.9458003581442472, 0.8964876214112817, 0.964872931604476, 0.9518078840994827]\n",
            "Mean test accuracy is 0.947, mean test f1 score is 0.940, max test accuracy is 0.971, max test f1 score is 0.965, min test accuracy is 0.906, min test f1 score is 0.896, std of test accuracy is 0.022, std of test f1 score is 0.023\n",
            "Time elapsed through all process: 10350.717, sec\n"
          ]
        }
      ],
      "source": [
        "t = time.time()\n",
        "# ---------- Parameters ----------------\n",
        "augmentation_enable = True\n",
        "normalize_inputs_enable = True\n",
        "num_folds = 5\n",
        "kfold = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state = None) # random_state = 1 ile split run'dan run'a sabit.\n",
        "test_accuracy_per_run = []\n",
        "f1_score_per_run = []\n",
        "epoch_number = 100\n",
        "batch_size = 32\n",
        "dense_size = 64\n",
        "dropout_prob_dense = 0.5 # 0.\n",
        "repeat_of_mixup = 5\n",
        "number_of_repeat = 5\n",
        "unit_number_of_lstm = 8 #8 32\n",
        "dense_unit_of_range_doppler_function = 256 #128 512\n",
        "dense_unit_of_spectrogram_function = 8\n",
        "decoder_dense_unit = 256\n",
        "for repeat_run_number in range(number_of_repeat):\n",
        "  test_accuracy_per_fold = []\n",
        "  f1_score_per_fold = []\n",
        "  if repeat_run_number > 0:\n",
        "    del range_doppler_concat_shuffle_test\n",
        "    del spectrogram_concat_shuffle_test\n",
        "    del range_doppler_augmented_image\n",
        "    del range_doppler_concat_shuffle_train\n",
        "    del spectrogram_concat_shuffle_train\n",
        "    del spectrogram_augmented_image\n",
        "   \n",
        "  for randomlist_for_train_indx, randomlist_for_test_indx in kfold.split(range_doppler_concat_shuffle,range_doppler_concat_label_shuffle):   \n",
        "    gc.collect()\n",
        "    K.clear_session()\n",
        "    \n",
        "    # test data\n",
        "    range_doppler_concat_shuffle_test = range_doppler_concat_shuffle[randomlist_for_test_indx,:,:,:]\n",
        "    spectrogram_concat_shuffle_test = spectrogram_concat_shuffle[randomlist_for_test_indx,:,:,:]\n",
        "    range_doppler_concat_label_shuffle_test = range_doppler_concat_label_shuffle[randomlist_for_test_indx,:]\n",
        "    #train data\n",
        "    range_doppler_concat_shuffle_train = range_doppler_concat_shuffle[randomlist_for_train_indx,:,:,:]\n",
        "    spectrogram_concat_shuffle_train = spectrogram_concat_shuffle[randomlist_for_train_indx,:,:,:]\n",
        "    spectrogram_concat_label_shuffle_train = spectrogram_concat_label_shuffle[randomlist_for_train_indx,:]\n",
        "      # ---------------- MixUp Augmentation ----------------\n",
        "    (spectrogram_augmented_image,range_doppler_augmented_image,spectrogram_concat_label_shuffle_concat,\\\n",
        "     validation_spectrogram,validation_range_doppler, spectrogram_validation_labels)  =\\\n",
        "      split_and_augmentation_of_training(spectrogram_concat_shuffle_train,range_doppler_concat_shuffle_train,\\\n",
        "                                         spectrogram_concat_label_shuffle_train,\\\n",
        "                                         repeat_of_mixup, augmentation_enable)\n",
        "    \n",
        "    # ---------------- Neural Network Architecture ----------------\n",
        "\n",
        "\n",
        "\n",
        "    def lstm_encoder_network_1(input_shape):\n",
        "        input = Input(shape=input_shape)\n",
        "        x = Bidirectional(LSTM(unit_number_of_lstm, return_sequences=True, dropout = 0.5))(input)\n",
        "        x = Flatten()(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Dropout(0.5)(x)\n",
        "        x = Dense(dense_unit_of_range_doppler_function)(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Activation('LeakyReLU')(x)\n",
        "        x = Dropout(dropout_prob_dense)(x)\n",
        "        return Model(input, x)\n",
        "\n",
        "    def lstm_encoder_network_2(input_shape):\n",
        "        input = Input(shape=input_shape)\n",
        "        x = Bidirectional(LSTM(unit_number_of_lstm, return_sequences=True, dropout = 0.5))(input)\n",
        "        x = Flatten()(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Dropout(0.5)(x)\n",
        "        x = Dense(dense_unit_of_spectrogram_function)(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Activation('LeakyReLU')(x)\n",
        "        x = Dropout(dropout_prob_dense)(x)\n",
        "        return Model(input, x)\n",
        "\n",
        "    def decoder_for_concat(input_shape):\n",
        "      input = Input(shape=input_shape)\n",
        "      x = Dense(decoder_dense_unit)(input)\n",
        "      x = BatchNormalization()(x)\n",
        "      x = Activation('LeakyReLU')(x)\n",
        "      x = Dropout(0.3)(x)\n",
        "      x = Dense(dense_size)(x)\n",
        "      # x = BatchNormalization()(x)\n",
        "      x = Activation('LeakyReLU')(x)\n",
        "      x = Dropout(dropout_prob_dense)(x)\n",
        "      x = Dense(1, activation=\"sigmoid\")(x)\n",
        "      return Model(input, x)\n",
        "\n",
        "    input_shape = range_doppler_concat_shuffle.shape[1:3]\n",
        "    base_network_lstm = lstm_encoder_network_1(input_shape)\n",
        "    range_doppler_input  = Input(shape=input_shape)\n",
        "    processed_range_doppler  = base_network_lstm(range_doppler_input)\n",
        "\n",
        "    input_shape = spectrogram_concat_shuffle_train.shape[1:3]\n",
        "    base_network_lstm_2 = lstm_encoder_network_2(input_shape)\n",
        "    spectrogram_input  = Input(shape=input_shape)\n",
        "    processed_spectrogram  = base_network_lstm_2(spectrogram_input)\n",
        "\n",
        "    concat_layer = Concatenate()([processed_range_doppler, processed_spectrogram])\n",
        "\n",
        "    base_decoder_network = decoder_for_concat((concat_layer.shape[1]))\n",
        "    out = base_decoder_network(concat_layer)\n",
        "\n",
        "    model = Model(inputs=[range_doppler_input, spectrogram_input], outputs=[out]) \n",
        "    if repeat_run_number == 0:\n",
        "      print(base_network_lstm.summary())\n",
        "      print(base_network_lstm_2.summary())\n",
        "      print(base_decoder_network.summary())\n",
        "    # ---------------- Compile and Fit ----------------\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    earlyStopping = EarlyStopping(monitor='val_loss', patience=15, verbose=0,restore_best_weights=True, mode='min')\n",
        "    history = model.fit((range_doppler_augmented_image, spectrogram_augmented_image),(spectrogram_concat_label_shuffle_concat),\n",
        "                    epochs=epoch_number,\n",
        "                    batch_size=batch_size,\n",
        "                    shuffle = True,\n",
        "                    callbacks=[earlyStopping],\n",
        "                    validation_data = ((validation_range_doppler, validation_spectrogram) , (spectrogram_validation_labels)))\n",
        "    test_loss, test_accuracy  = model.evaluate([range_doppler_concat_shuffle_test, spectrogram_concat_shuffle_test],\\\n",
        "                                               [range_doppler_concat_label_shuffle_test],\n",
        "                  batch_size=batch_size)\n",
        "    gc.collect()\n",
        "    # ---------------- Get Test Results ----------------\n",
        "    y_test_predicted = model.predict((range_doppler_concat_shuffle_test, spectrogram_concat_shuffle_test), batch_size=batch_size)\n",
        "    # ----- Binarize y_test_predicted values -----\n",
        "    y_test_predicted_binary = np.zeros(y_test_predicted.size)\n",
        "    for ii in range(y_test_predicted.size):\n",
        "      if y_test_predicted[ii] < 0.5:\n",
        "        y_test_predicted_binary[ii] = 0\n",
        "      else:\n",
        "        y_test_predicted_binary[ii] = 1\n",
        "    \n",
        "    test_precision, test_recall, test_f1_score, support = precision_recall_fscore_support(range_doppler_concat_label_shuffle_test, y_test_predicted_binary, average='macro')\n",
        "\n",
        "    test_accuracy_per_fold.append(test_accuracy)\n",
        "    f1_score_per_fold.append(test_f1_score)\n",
        "    del model\n",
        "  test_accuracy_per_run.append(sum(test_accuracy_per_fold)/num_folds)\n",
        "  f1_score_per_run.append(sum(f1_score_per_fold)/num_folds)\n",
        "  print(test_accuracy_per_run)\n",
        "  print(f1_score_per_run)\n",
        "print(f'Mean test accuracy is {\"{:.3f}\".format(sum(test_accuracy_per_run)/number_of_repeat)}, mean test f1 score is {\"{:.3f}\".format(sum(f1_score_per_run)/number_of_repeat)}, \\\n",
        "max test accuracy is {\"{:.3f}\".format(max(test_accuracy_per_run))}, max test f1 score is {\"{:.3f}\".format(max(f1_score_per_run))}, \\\n",
        "min test accuracy is {\"{:.3f}\".format(min(test_accuracy_per_run))}, min test f1 score is {\"{:.3f}\".format(min(f1_score_per_run))}, \\\n",
        "std of test accuracy is {\"{:.3f}\".format(np.std(test_accuracy_per_run, axis=0))}, std of test f1 score is {\"{:.3f}\".format(np.std(f1_score_per_run, axis=0))}')\n",
        "elapsed = time.time() - t\n",
        "print(f'Time elapsed through all process: {\"{:.3f}\".format(elapsed)}, sec')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0N7v4PDP4Dv2",
        "outputId": "a0eabf0d-75e9-453e-c6b5-e462447197b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean test accuracy is 0.947, mean test f1 score is 0.940, max test accuracy is 0.971, max test f1 score is 0.965, min test accuracy is 0.906, min test f1 score is 0.896, std of test accuracy is 0.022, std of test f1 score is 0.023\n",
            "Time elapsed through all process: 10350.717, sec\n"
          ]
        }
      ],
      "source": [
        "print(f'Mean test accuracy is {\"{:.3f}\".format(sum(test_accuracy_per_run)/number_of_repeat)}, mean test f1 score is {\"{:.3f}\".format(sum(f1_score_per_run)/number_of_repeat)}, \\\n",
        "max test accuracy is {\"{:.3f}\".format(max(test_accuracy_per_run))}, max test f1 score is {\"{:.3f}\".format(max(f1_score_per_run))}, \\\n",
        "min test accuracy is {\"{:.3f}\".format(min(test_accuracy_per_run))}, min test f1 score is {\"{:.3f}\".format(min(f1_score_per_run))}, \\\n",
        "std of test accuracy is {\"{:.3f}\".format(np.std(test_accuracy_per_run, axis=0))}, std of test f1 score is {\"{:.3f}\".format(np.std(f1_score_per_run, axis=0))}')\n",
        "print(f'Time elapsed through all process: {\"{:.3f}\".format(elapsed)}, sec')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "def createList(n):\n",
        "    lst = []\n",
        "    for i in range(n+1):\n",
        "        lst.append(i)\n",
        "    return(lst)\n",
        "\n",
        "\n",
        "folds = createList(4)\n",
        "values = [element * 100 for element in test_accuracy_per_fold]\n",
        "\n",
        "fig = plt.figure(figsize = (10, 5))\n",
        " \n",
        "# creating the bar plot\n",
        "plt.bar(folds, values, color ='black',\n",
        "        width = 0.4)\n",
        "plt.xlabel(\"Accuracy vs k-run\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.show()\n",
        "\n",
        "fig = plt.figure(figsize = (10, 5))\n",
        " \n",
        "# creating the bar plot\n",
        "plt.bar(folds, f1_score_per_fold, color ='black',\n",
        "        width = 0.4)\n",
        "plt.xlabel(\"F1 Score vs k-run\")\n",
        "plt.ylabel(\"F1 Score\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "id": "xz7CY0DhWKJV",
        "outputId": "87974b20-330e-4973-99fc-d27b1e27fe5c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "RD_SP_LSTM_8hiddenunitnumberoflstm.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}